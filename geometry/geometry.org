#+TODO: X 0 1 2 | 3
#+LANGUAGE: ru
#+LaTeX_HEADER: \usepackage[a4paper, left=2.5cm,right=2cm,top=2cm,bottom=2cm]{geometry}
#+LaTeX_HEADER: \usepackage[russian]{babel}             % Russian translations
#+LaTeX_HEADER: \usepackage{amssymb,amsmath,amsthm}     % Mathematic symbols, theorems, etc.
#+LaTeX_HEADER: \usepackage[boxed]{algorithm2e} % Algorithm listings
#+LaTeX_HEADER: \usepackage{styling}                    % Styling for theorems (local)
#+TITLE:  Конспект по вычислительной геометрии (Ковалёв)
#+AUTHOR: Volkhov M., Mukhutdinov D., Belyy A.

* Как пользоваться этим документом
  1. Писать билетики параллельно
  2. Все формулы оформлять в латехе.
     * http://www.math.uiuc.edu/~hildebr/tex/course/intro2.html
     * https://en.wikibooks.org/wiki/LaTeX/Mathematics
     * https://en.wikibooks.org/wiki/LaTeX/Advanced_Mathematics
     * Рекомендуется смотреть конспект Сугака [[https://github.com/sugakandrey/Functional-analysis/blob/master/hahnbanach.tex][тут]].
  3. Можно пользоваться ~(org-toggle-pretty-entities)~ чтобы latex
     отображался юникодом в emacs'е.
  4. *TODO* обозначают степень написанности материала. Положительное
     значение интерпретируется как процент. X -- метка для "тут нифига
     не ясно и проблемы".
  5. Смотреть превью формул с помощью ~C-c C-x C-l~.
  6. Экспортить с помощью ~C-c C-e l p~. Если не работает -- сначала в
     `tex`, а потом уже экспортировать `pdflatex`'ом. Экспорт
     игнорирует ошибки, поэтому сделать это руками и пофиксить их --
     не так плохо.
  7. Если что-то не собирается, писать ~@volhovm~.
  8. Синтаксис теха смотреть хз где, но есть
     http://detexify.kirelabs.org/classify.html для непонятных
     символов.
  9. Синтаксис орга -- это тут:
     * http://orgmode.org/manual/Emphasis-and-monospace.html
     * http://orgmode.org/manual/LaTeX-and-PDF-export.html#LaTeX-and-PDF-export
     * http://orgmode.org/tmp/worg/org-tutorials/org-latex-export.html
     * http://orgmode.org/manual/Embedded-LaTeX.html#Embedded-LaTeX
     * Остальное (списки, хедеры, блабла) очевидно.
* Tickets
|----+----+--------------------------------------------------------------------------------------|
|  4 |  1 | Принадлежность точки выпуклому и невыпуклому многоугольникам                         |
| 21 |  1 | Триангуляция Делоне.                                                                 |
|    |    | Алгоритм и доказательство его корректности.                                          |
|  5 |  2 | Статические выпуклые оболочки на плоскости.                                          |
|    |    | Джарвис, Грэм, Эндрю, Чен, QuickHull. Оболочка многоугольника, оболочка полилинии.   |
| 20 |  2 | Триангуляция Делоне.                                                                 |
|    |    | - существование;                                                                     |
|    |    | - приводимость любой триангуляции флипами к ТД;                                      |
|    |    | - эквивалентность критерия Делоне для треугольников критерию для ребер.              |
|  8 |  3 | Триангуляция многоугольника.                                                         |
|    |    | Существование, ушная триангуляция.                                                   |
| 17 |  3 | Сумма Минковского (определение, вычисление)                                          |
| 12 |  4 | ППЛГ и РСДС (PSLG и DCEL): определение, построение РСДС множества прямых             |
| 15 |  4 | Трапецоидная карта.                                                                  |
| 10 |  5 | Пересечение полуплоскостей, связь с выпуклыми оболочками                             |
| 13 |  5 | Пересечение многоугольников (PSLG overlaying)                                        |
|  7 |  6 | Выпуклая оболочка в n-мерном пространстве. Quick-hull и вероятностный алгоритм.      |
| 11 |  6 | Пересечение множества отрезков.                                                      |
|  9 |  7 | Триангуляция многоугольника заметающей прямой                                        |
| 14 |  7 | Локализация в ППЛГ.                                                                  |
|    |    | - методом полос (персистентные деревья);                                             |
|    |    | - Киркпатрик.                                                                        |
|  6 |  8 | Динамическая выпуклая оболочка (достаточно log^2 на добавление/удаление)             |
| 19 |  8 | Граф видимости и планирование движения.                                              |
|    |    | - построение графа видимости заметающим лучом;                                       |
|    |    | - сокращение графа видимости;                                                        |
|    |    | - построение навигационного графа на трапецоидной карте;                             |
|    |    | - планирование маршрута невыпуклого тела с вращением (без суммы Минковского).        |
|  3 |  9 | Пересечение отрезков и поворот: определение, свойства, вычисление                    |
| 22 |  9 | Диаграмма Вороного.                                                                  |
|    |    | - определение и свойства;                                                            |
|    |    | - диаграмма Вороного высших порядков, построение;                                    |
|    |    | - связь с подразбиением Делоне (ближайший и дальнейший);                             |
|    |    | - алгоритм построения ДВ.                                                            |
|  1 | 10 | Skip quadtree: определение, время работы                                             |
| 18 | 10 | Минимальная охватывающая окружность множества точек. Вероятностный алгоритм.         |
|  2 | 11 | Пересечение прямоугольника с множеством прямоугольников и непересекающихся отрезков: |
|    |    | - range tree + fractional cascading;                                                 |
|    |    | - interval tree;                                                                     |
|    |    | - segment tree;                                                                      |
|    |    | - priority search tree;                                                              |
|    |    | - k-d tree.        van Kreveld, de Berg, Overmars, Cheong                            |
| 16 | 11 | Диаметр множества точек (вращающиеся калиперы)                                       |
|----+----+--------------------------------------------------------------------------------------|
* 2 1:  Skip quadtree
  Сперва поймем, что такое [[http://neerc.ifmo.ru/wiki/index.php?title=Квадродеревья][квадродерево]] и [[http://neerc.ifmo.ru/wiki/index.php?title=Квадродеревья#.D0.A1.D0.B6.D0.B0.D1.82.D0.BE.D0.B5_.D0.BA.D0.B2.D0.B0.D0.B4.D1.80.D0.BE.D0.B4.D0.B5.D1.80.D0.B5.D0.B2.D0.BE][сжатое квадродерево]].

  #+LATEX_OPTIONS: :option [Квадродерево]
  #+BEGIN_defn
    Дерево, каждая внутренняя (не листовая) вершина которого содержит 4
    ребёнка.
  #+END_defn

  Построение квадродерева по множеству точек $P$ \--- пусть дан
  квадрат $S$, содержащий все точки $P$. Если $|P|=1$, то квадродерево
  состоит из одного листа, соответствующего квадрату $S$. Если $|P|>1$,
  то поделим S на 4 маленьких квадрата и рекурсивно запускаемся от
  подмножеств P, соответствующих разным четвертям.

  [[http://neerc.ifmo.ru/wiki/images/a/a7/Quadtree.png][Картинка]].

  #+LATEX_OPTIONS: :option [Интересный квадрат]
  #+BEGIN_defn
  Квадрат, в котором содержится хотя бы одна точка из $P$. [[http://neerc.ifmo.ru/wiki/images/e/ea/Compressed_Quadtree.png][Пример]].
  #+END_defn

  #+LATEX_OPTIONS: :option [Сжатое квадродерево]
  #+BEGIN_defn
  Квадродерево, внутренним вершинам которого соответствуют только
  интересные квадраты.
  #+END_defn

  Построение сжатого квадродерева - строим по обычному квадродереву
  следующим образом: у внутренней вершины заводим по 4 указателя для
  4 четвертей. Если в четверти 2 и более точки $P$ - указатель
  ссылается на наибольший интересный квадрат этих точек, если одна -
  ссылается на неё саму, если 0 - указатель ~NULL~.

  Время работы операций в сжатом квадродереве: $O(n)$ на локализацию,
  вставку и удаление. Могли бы просто завести список точек, в
  общем. Самое время узнать про skip quadtree.

  #+LATEX_OPTIONS: :option [Randomized skip quadtree]
  #+BEGIN_defn
  Последовательность сжатых квадродеревьев над подмножествами точек
  $P: {P_0, P_1, ..., P_k}$, где $P_0 = P$ \--- исходное множество
  точек, $P_i \in P_{i-1}$ и каждый элемент $P_{i-1}$ входит в $P_i$ с
  вероятностью $p \in (0,1)$. Skip quadree \--- это последовательность
  "уровней" ${Q_i}$, где "уровень" $Q_i$ - сжатое квадродерево над
  точками $P_i$.
  #+END_defn

  * Время работы операций в skip quadtree \--- $O(\log{n})$. Сначала
    опишем, как проходят операции, а потом докажем их время работы.
  * Общая операция подъем
    По вершине с уровня $i$ нужно получить эту же вершину на уровне
    $i - 1$. За $O(1)$. Как сделать? Проще всего как в skip list:
    "прошить" ссылками на вершину уровня выше каждую внутреннюю
    вершину каждого квадродерева.
  * Локализация
    Локализуемся на уровне $k$, далее сделаем подъем, окажемся в
    квадродереве уровня ниже и локализуемся в нем, но уже не от корня,
    а с того квадрата, который нашли на предыдущем уровне. Повторим это
    $k$ раз. В результате локализуемся на нулевом уровне.
  * Вставка
    Локализуемся на всех уровнях, запоминая ссылки. Сделаем вставку в
    квадродерево нулевого уровня, далее с вероятностью p сделаем
    вставку на 1 уровне и так далее до первого недобавления.
    Количество уровней при этом увеличится максимум на 1 (с
    вероятностью $p^k$).
  * Удаление
    Локализуемся на всех уровнях, удалим квадрат везде и обновим
    ссылки. Если уровень стал пустым \--- удалим его.
  * Лемма (о количестве шагов на одном уровне)
    На каждом уровне в среднем совершается O(1) шагов для поиска точки
    x.

    [[http://neerc.ifmo.ru/wiki/index.php?title=Skip_quadtree:_определение,_время_работы#.D0.92.D1.80.D0.B5.D0.BC.D1.8F_.D1.80.D0.B0.D0.B1.D0.BE.D1.82.D1.8B_.D0.B8_.D0.BF.D0.B0.D0.BC.D1.8F.D1.82.D1.8C][Доказательство]]
  * Лемма (о количестве уровней)
    Математическое ожидание количества уровней составляет $O(\log{n})$.

    [[http://neerc.ifmo.ru/wiki/index.php?title=Skip_quadtree:_определение,_время_работы#.D0.92.D1.80.D0.B5.D0.BC.D1.8F_.D1.80.D0.B0.D0.B1.D0.BE.D1.82.D1.8B_.D0.B8_.D0.BF.D0.B0.D0.BC.D1.8F.D1.82.D1.8C][Доказательство]]
  * Теорема (о времени работы)
    Локализация, вставка и удаление работают в среднем за $O(\log{n})$.

    Доказательство: следует из двух предыдущих лемм.
* 2 2:  Пересечение прямоугольника с множеством прямоугольников/отрезков
** 2 Пересечение прямоугольника запроса $q$ с множеством прямоугольников $P$
   Задача: существует множество прямоугольников $P$. Стороны
   прямоугольников параллельны осям координат. Задается прямоугольник
   запроса $q$, такой же. Нужно быстро определить множество
   прямоугольников, пересекающихся с $q$.

   Формально: нужно найти множество $S = \{ p \in P : p \cap q \neq
   \emptyset \}$

   Разобьем это множество на три множества-подзадачи:
   \begin{align*}
   S &= A \cup B \cup C \\
   A &= \{ p \in P : \exists i: p_i \in corners(p), p_i \in q \} \\
   B &= \{ p \in P : \exists i: s_i \in sides(p), s_i \cap q \neq \emptyset \} \\
   C &= \{ p \in P : \exists i: p_i \in corners(q), p_i \in p \} \\
   \end{align*}

   Иначе говоря, $A$ -- это случай, когда $p$ целиком лежит в $q$, $B$
   -- когда $p$ и $q$ пересекаются, $C$ -- когда $q$ целиком лежит в
   $p$. Разберем все три случая отдельно.
*** 2 Нахождение множества точек, попадающих в прямоугольник запроса.

    Для начала быстро рассмотрим одномерный случай. Быстро выдавать
    множество точек, попадающих в отрезок, можно с помощью
    сбалансированного дерева поиска. (*Примечание:* можно и с помощью
    отсортированного массива и бинпоиска, но в такую структуру данных
    нельзя эффективно вставить новую точку).

    Как это делать - очевидно: идем вглубь дерева, пока не встретим
    узел, разделяющий концы отрезка. После этого ищем каждый конец
    отрезка в отдельности и добавляем к ответу все поддеревья, лежащие
    справа (для левого конца) и слева (для правого конца) от пути.

    Такое дерево можно построить за $O(n \log n)$, она будет занимать
    $O(n)$ памяти, запрос будет обработан за $O(\log n + k)$, где
    $k$ - величина ответа. Как расширить эту структуру на двумерный
    случай и добиться сопоставимых результатов?

**** *Способ 1. Range trees*

     Рассмотрим обработку двумерного запроса как обработку 2 одномерных
     запросов по отдельности: по $x$ -координате и по $y$ -координате. То
     есть, сначала мы отсеиваем все точки, попадающие в запрос по $x$,
     а потом из них выбираем точки, попадающие в этот запрос по $y$.

     Мы делаем это, на самом деле, очень просто: строим для всего
     множества точек бинарное дерево поиска по $x$, а в каждом узле
     этого дерева дополнительно строим дерево поиска по $y$ для
     соответствующего поддерева.

     #+CAPTION: Иллюстрация к Range-tree
     [[./figures/RANGE_TREES.png]]

     #+BEGIN_lemma
     Такая структура данных, несмотря на кажущуюся громоздкость,
     занимает $O(n \log n)$ памяти
     #+END_lemma

     #+BEGIN_proof
     Рассмотрим некую точку $p$. В дереве первого уровня путь от корня
     до нее занимает $O(\log n)$ узлов. Значит, она содержится в каждом
     дереве 2-го уровня, встретившемся на пути, но не встречается
     больше ни в каких деревьях 2-го уровня. Таким образом, количество
     копий каждой точки во всей структуре данных оценивается в $O(\log
     n)$. Всего точек $n$, значит, структура занимает $O(n \log n)$
     памяти.
     #+END_proof

     #+BEGIN_lemma
     Такую структуру данных можно построить за $O(n \log n)$
     #+END_lemma

     #+BEGIN_proof
     Если строить каждое дерево второго уровня втупую за $O(n \log n)$,
     то это, конечно, будет долго. Однако, если мы сначала отсортируем
     список вершин по $y$, то деревья второго уровня можно будет
     строить за $O(n)$ снизу вверх. Таким образом, каждый узел
     основного дерева будет строиться за $O(m)$, где $m$ - количество
     точек в поддереве узла. Значит, узел строится за такое время,
     сколько памяти занимает, а вся структура занимает $O(n \log n)$
     памяти. Поэтому за столько же по времени произойдет построение дерева.
     #+END_proof

     #+BEGIN_lemma
     Двумерный запрос в таком дереве займет $O(\log^2 n + k)$ времени.
     #+END_lemma

     #+BEGIN_proof
     Запрос в дереве 1 уровня пройдет за $O(\log n)$. При этом во время
     выполнения запроса вызовутся запросы по $y$ для всех деревьев
     поиска 2 уровня, встретившихся по пути - таких $O(\log n)$. В
     дереве поиска 2 уровня ситуация аналогична одномерной + нужно
     время на вывод результата. Итого: $O(\log^2 n + k)$
     #+END_proof

     *Замечание* Легко видеть, что Range tree легко обобщается на
     высшие размерности - достаточно просто понапихать деревьев низших
     уровней. В таком случае на построение и память уйдет $O(n
     \log^{d-1} n)$, а на запрос - $O(n \log^d + k)$. Доказательство
     этих фактов оставим читателю (это легко, мне лень, Ковалев не
     спросит).

     *Fractional cascading*

     Время запроса $O(n \log^2 n + k)$ - казалось бы, не так уж плохо,
     но на серьезных $n$ этот квадрат у логарифма даст серьезный
     прирост во времени. Можно ли от него избавиться? Оказывается, да!
     Для этого существует техника, называемая fractional cascading.

     *Идея*: Мы делаем $O(\log n)$ запросов по деревьям второго уровня
     для одного и того же ренджа по $y$ - координате. Может быть, мы
     можем как-то использовать результаты запросов в старших
     поддеревьях для младших?

     Проиллюстрируем идею fractional cascading на более простом
     примере. Предположим, у нас есть 2 массива объектов - $A_1, A_2$ -
     отсортированных по ключу, причем $A_2 \subset A_1$. Приходит
     запрос -  выдать все объекты из обоих массивов с ключом, лежащим в
     отрезке $(l, r)$. Можно втупую сделать бинпоиск на обоих
     массивах. А можно делать бинпоиск только в большем массиве $A_1$,
     а во втором массиве выдать ответ сразу, воспользовавшись ссылками,
     ведущими из каждого объекта в $A_1$ в первый объект в $A_2$,
     больший или равный данному. (см. иллюстрацию)

     #+CAPTION: Иллюстрация к Fractional Cascading
     [[./figures/FRAC_CASC.png]]

     Так вот! Теперь заметим, что каждое дерево 2-го уровня в
     Range-tree содержится в своем предке. А давайте тогда не будем
     делать деревья 2 уровня, а вместо них сделаем вот такие каскадные
     массивы. Причем в каждом элементе такого массива есть 2 ссылки -
     на upper-bound в левом и правом сыне.

     Такая структура данных называется layered range-tree. Она
     занимает столько же памяти, сколько и обычный range-tree
     (очевидно). Докажем пару других фактов.

     #+BEGIN_lemma
     Layered range-tree строится за $O(n \log n)$
     #+END_lemma

     #+BEGIN_proof
     Корневой массив строим, просто отсортировав точки по $y$ за $O(n
     \log n)$. Покажем способ построить из массива длины $n$ два
     дочерних массива с каскадными ссылками за $O(n)$.

     Разделить отсортированный массив по некоему $x$ на два можно за
     $O(n)$ легко - идем по элементам по порядку и в зависимости от их
     $x$ координаты кладем их в конец левого или правого
     массивов. Проставить ссылки же можно с помощью трех указателей.

     Ставим указатели $i, j, k$ в начало корневого массива, левого и
     правого сына соответственно. Перебираем $A[i]$, смотрим в
     $A_l[j]$ и увеличиваем $j$ до тех пор, пока $A_l[j] <
     A[i]$. Аналогично делаем с $A_r$. Проставляем в $A[i]$ ссылки на
     $A_l[j]$ и $A_r[k]$ и увеличиваем $i$. Эта процедура, очевидно,
     занимает линейное время.
     #+END_proof

     #+BEGIN_lemma
     Запрос в layered range-tree занимает $O(\log n + k)$ времени
     #+END_lemma

     #+BEGIN_proof
     Запрос по 1 уровню занимает $O(\log n)$, на выходе мы получаем
     $O(\log n)$ каскадных массивчиков, в которых нужно провести
     запрос по $y$. Но мы за $O(\log n)$ делаем этот запрос только в
     корне, и за этот же $O(\log n)$ спускаемся вниз по каскадным
     ссылкам, зацепляя все найденные массивы. Итого - $O(\log n + k)$
     #+END_proof

     *Замечание* Fractional cascading, вообще говоря, снижает время
     запроса по range-tree в d-мерном пространстве до $O(\log^{d-1} +
     k)$ (доказывать не буду, я заебался уже)

**** *Способ 2. k-d trees*

     Идея: давайте поиск по $y$ - координате будем делать не после
     того, как завершили поиск по $x$ - координате, а как бы
     вперемешку. Строим "слоеное" дерево: сначала поделим множество
     точек примерно пополам по $x$, потом по $y$, потом снова по $x$ и
     так далее.

     #+CAPTION: K-d tree
     [[./figures/KD_TREE.png]]

     #+BEGIN_lemma
     K-d tree построится за $O(n \log n)$ и будет занимать $O(n)$ места.
     #+END_lemma

     #+BEGIN_proof
     Дерево строится рекурсивно, множество, по которому строятся
     правое и левое поддерево, примерно одинаковы - для этого ищется
     медиана. Таким образом, глубина дерева - $O(\log n)$. Медиану
     можно найти за $O(n)$ (сложно, но можно, проще посортить все
     заранее), разделить множество по медиане - тоже за $O(n)$. Итого,
     каждый вызов без учета рекурсии занимает $O(n)$, всего вызовов
     $O(\log n)$, итого $O(n \log n)$

     Что касается места: k-d tree имеет вид обычного сбанансированного
     бинарного дерева с $n$ листьями, в котором каждый узел занимает
     $O(1)$ памяти. Значит, всего памяти $O(n)$
     #+END_proof

     Пусть нам теперь нам прилетел прямоугольный запрос. Рекурсивно
     спускаемся с ним по дереву, "нарезая" его медианами. Если в
     запрос какая-то область попала целиком - возвращаем все
     поддерево.

     \begin{algorithm}[H]
      \SetKwFunction{QueryKDT}{QueryKDT}%
      \func{\QueryKDT{v, R}}{
        \KwData{Корень дерева $v$, и прямоугольник $R$}
        \KwResult{Множество точек, попавших в прямоугольник}
        \eIf{$v$ -- лист}{
          \If{$point(v) \in R$}{report $point(v)$}
        }{
          \eIf{область узла $v$ полностью содержится в $R$}{
            report-all($v$)
          }{
            \If{область $v_l$ пересекается с $R$}{
              \QueryKDT{$v_l$, $R$}
            }
            \If{область $v_r$ пересекается с $R$}{
              \QueryKDT{$v_r$, $R$}
            }
          }
        }
      }
      \caption{Алгоритм построения PST}
    \end{algorithm}

    #+BEGIN_lemma
    Запрос в k-d tree занимает $O(\sqrt{n} + k)$ времени.
    #+END_lemma

    #+BEGIN_proof
    Без учета рекурсивных вызовов и вывода ответа, \QueryKDT
    выполняется за $O(1)$. С выводом ответа все понятно, но сколько
    будет рекурсивных вызовов? Их будет столько, сколько на пути
    попадется областей, пересекаемых границей прямоугольника. Границы
    прямоугольника могут быть сколь угодно длинными. Поэтому верхней
    оценкой на количество областей, пересекаемый 1 гранью
    многоугольника, можно считать количество областей, пересекаемых
    случайной вертикальной прямой (с горизонтальной гранью -- симметрично).

    Обозначим количество таких областей в k-d tree для n точек как
    $Q(n)$, пересекающую прямую -- $l$. Пусть разделяющая прямая в
    корне -- вертикальная. Тогда прямая $l$ пересечет область в корне
    и ровно одного из сыновей - 2 пересечения. Но в сыне разделяющая
    прямая будет горизонтальной! То есть, прямая точно пересечет обоих
    внуков. А вот во внуках ситуация уже будет аналогична корню. В
    каждом внуке примерно $n/4$ точек. Теперь мы можем записать
    рекуррентную формулу:

    $Q(n) = \begin{cases}
      O(1), & \mbox{if } n = 1 \\
      2 + 2Q(n/4), & \mbox{otherwise}
    \end{cases}$

    Тут надо сделать какой-то шмяк-шмяк и сказать, что эта рекурсия
    имеет решение $Q(n) = O(\sqrt{n})$. На самом деле, так и есть.
    #+END_proof

    Итого: k-d tree отвечает на запросы явно помедленнее range tree
    (даже не layered), однако занимает меньше памяти и явно проще в исполнении.

*** 2 Нахождение множества отрезков, пересекающих прямоугольник запроса (но не лежащих концом внутри)
    Пусть есть множество отрезков $S$, таких, что каждый отрезок
    параллелен либо оси $x$, либо оси $y$. Дан прямоугольник запроса
    $q$. Нужно найти все отрезки, пересекающие $q$. Утверждается, что
    не существует отрезков, лежащих в нем концом. (типа, все такие
    отрезки мы можем найти, рассмотрев только их концы в предыдущей
    задаче).

    Пусть найден такой отрезок $s$. Тогда, если он горизонтальный, он
    пересекает обе вертикальные грани $q$, а если вертикальный - обе
    горизонтальные. Значит, достаточно найти отрезки, что пересекают
    левую или нижнюю грани прямоугольника.

    Следовательно, задача свелась к нахождению множества
    горизонтальных отрезков, пересекающихся с данным вертикальным
    отрезком (с горизонтальным случай симметричный).

    Сначала решим более простую задачу: найдем все горизонтальные
    отрезки, пересекающие вертикальную прямую с координатой $q_x$.

**** *Interval tree*

     Эта задача, на самом деле, одномерная, $y$ - координаты не
     важны. Давайте попробуем построить эдакое бинарное дерево на
     отрезках. Найдем медиану $x_{mid}$ всех середин отрезков и разобъем отрезки
     на 3 множества, $I_{mid}, I_l, I_r$ - отрезки, пересекающие
     медиану, и лежащие целиком слева и справа соответственно. Для
     $I_l$ и $I_r$ рекурсивно построим поддеревья. А вот что делать с
     $I_{mid}$?

     У $I_{mid}$ есть одно хорошее свойство - все отрезки оттуда
     пересекают $x_{mid}$. Это значит, что если $q_x > x_mid$, то $q_x
     \in [l, r] \in I_{mid} \ \ \mathrm{iff} \ \ q_x \leq r$. Слева ситуация
     симметричная.

     Тогда, чтобы искать все отрезки из $I_{mid}$, входящие в ответ, за
     $O(k_{\nu})$ (где $k_{\nu}$ - это количество таких отрезков),
     достаточно хранить $I_{mid}$ в виде двух отсортированных
     списков. Первый список отсортирован по убыванию координаты правого
     конца отрезка, левый - по возрастанию координаты левого
     конца. Тогда, если $q_x \geq x_{mid}$, мы идем по правому списку
     до тех пор, пока координата очередного конца не станет меньше
     $q_x$. В обратном случае поступаем симметрично с левым списком.

     #+CAPTION: Устройство interval tree
     [[./figures/INT_TREES.png]]

     #+BEGIN_lemma
     Interval tree имеет глубину $O(\log n)$ и размер $O(n)$
     #+END_lemma

     #+BEGIN_proof
     Глубина: медиана на то и медиана, чтобы делить отрезки примерно
     пополам, поэтому дерево выходит сбалансированным.
     Размер: каждый отрезок входит только в один из $I_{mid}$, и в этом
     $I_{mid}$ он хранится дважды - в левом и правом списках. Итого
     $O(n)$ места.
     #+END_proof

     #+BEGIN_lemma
     Interval tree строится за $O(n \log n)$
     #+END_lemma

     #+BEGIN_proof
     Определим процедуру $\mathrm{buildTree}(I)$ так:
     1) Если $I = \emptyset$, возвращаем пустой лист, иначе
     2) Найдем медиану всех отрезков в $I$ (за $O(n)$)
     3) Разобьем $I$ на $I_{mid}, I_l, I_r$ по медиане
        (своп-своп-фигакс за $O(n)$)
     4) Посортим 2 раза $I_{mid}$ по координатам концов и сформируем
        списки $L_l, L_r$ (за $O(n_{mid} \log n_{mid}))$
     5) $\mathrm{buildTree}(I_l), \ \mathrm{buildTree}(I_r)$

     Всего без учета рекурсивных вызовов - $O(n + n_{mid} \log
     n_{mid})$

     Рекурсивных вызовов будет $O(\log n)$, поэтому с их учетом $O(n)$
     составляющая даст $O(n \log n)$. Суммарное время на сортировку
     всех списков также $O(n \log n)$, так как их суммарная длина $O(n)$.
     #+END_proof

     #+BEGIN_lemma
     Запрос в interval tree занимает $O(\log n + k)$ времени.
     #+END_lemma

     #+BEGIN_proof
     В каждом узле мы тратим $O(k_{\nu})$ на вывод всех подходящих
     отрезков в нем и делаем рекурсивный вызов. Так как рекурсивных
     вызовов будет $O(\log n)$, суммарное время работы $O(\log n) +
     \sum {O(k_{\nu})} = O(\log n + k)$
     #+END_proof

     Мы научились находить все горизонтальные отрезки, пересекающие
     прямую запроса. Но нужен-то нам отрезок, то есть нам надо как-то
     включить $y$ - координаты в игру. Внезапно мы можем это сделать
     достаточно просто - давайте в нашем interval tree $I_{mid}$
     хранить не как два отсортированных списка, а как range tree! В
     этом range tree мы будет делать запросы по бесконечному с одной
     стороны прямоугольнику: $(-\infty, q_x] \times [q_y,
     q_y']$, если $q_x < x_{mid}$, и $[q_x, \infty) \times [q_y,
     q_y']$ иначе.

     #+CAPTION: Вид запроса к range tree
     [[./figures/STAKAN.png]]

     #+BEGIN_lemma
     Interval tree c range tree вместо списков будет занимать $O(n \log
     n)$ памяти, построится за $O(n \log n)$, и будет отвечать на
     запрос за $O(\log^2 n + k)$
     #+END_lemma

     #+BEGIN_proof

     Память: каждый $I_{mid}$ занимает $O(n_{mid} \log n_{mid})$
     памяти, $\sum {n_{mid}} = n$, значит, $\sum {|I_{mid}|} = O(n \log
     n)$.

     Время построения: range tree строится за $O(n \log n)$, как и 2
     отсортированных списка, поэтому предыдущая оценка работает.

     Время запроса: запрос в range tree (с fractional cascading)
     занимает $O(\log n + k)$, всего таких range tree $O(\log n)$,
     поэтому суммарное время запроса $O(\log^2 n + k)$
     #+END_proof

**** *Priority search trees*

     Использовать range trees как подструктуру для interval trees - на
     самом деле громоздко и overkill. Сделаем структуру, которая
     специально заточена на обработку запросов в виде бесконечных
     стаканов.

     Priority search tree - это такой heap, очень похожий на
     декартку. Точки в нем упорядочены по приоритету -- $x$ -
     координате. Однако оно не является корректным деревом бинпоиска
     по $y$ - координате. Декартка нам не подходит, потому что в
     случае неравномерного разброса точек декартка получится очень
     несбалансированной. А в priority search tree мы при построении
     сыновей для текущего узла мы делим поддерево по медиане по $y$ -
     координате, поэтому дерево всегда получается сбалансированным.

     #+CAPTION: Priority-seacrh tree
     [[./figures/PS_TREES.png]]

     Приведем алгоритм построения priority-search tree.

     \begin{algorithm}[H]
      \SetKwFunction{BuildPST}{BuildPST}%
      \func{\BuildPST{P}}{
        \KwData{Набор точек $\{p_i\}$, отсортированный по $x$ - координате}
        \KwResult{Корректное PST на точках}
        $V_p \longleftarrow p_1$\;
        $y_{mid} \longleftarrow$ медиана $\{ p_2, ... , p_n \}$\;
        $P_l \longleftarrow \{ p \in P \setminus \{p_1\} \ | \ p_y < y_{mid} \}$\;
        $P_r \longleftarrow \{ p \in P \setminus \{p_1\} \ | \ p_y \geqslant y_{mid} \}$\;
        $V_l \longleftarrow \ $ \BuildPST{$P_l$}\;
        $V_r \longleftarrow \ $ \BuildPST{$P_r$}\;
        return $V$\;
     }
     \caption{Алгоритм построения PST}
    \end{algorithm}

    #+BEGIN_lemma
    Этот алгоритм работает за $O(n \log n)$
    #+END_lemma

    #+BEGIN_proof
    Сортировка по иксу работает $O(n \log n)$. Шаг алгоритма без учета
    рекурсивных вызовов работает за $O(n)$, а глубина рекурсии $O(\log
    n)$. Итого $O(n \log n)$
    #+END_proof

    *Замечание*: Если отсортировать массив не по $x$, а по $y$, то
    можно будет построить PST как декартку снизу вверх за $O(n)$.

    Очевидно, что PST занимает $O(n)$ памяти.

    В таком дереве мы можем выдать все точки, лежащие левее некоего
    $q_x$, за $O(k)$. Действительно - просто спускаемся вглубь и
    выдаем все подходящие точки, пока они подходят. Если не подходит
    какая-то точка - не подходит и все ее поддерево.

    Зато теперь мы понимаем, как отвечать на "стаканные"
    запросы. Приведем алгоритм:

    \begin{algorithm}[H]
      \SetKwFunction{QueryPST}{QueryPST}%
      \func{\QueryPST{$v$, $(-\infty, q_x] \times [q_y, q_y']$}}{
        \KwData{Корень PST и область запроса ('стакан')}
        \KwResult{Набор всех точек из дерева, удовлетворяющих запросу}
        Идем вниз дерева, ищем $q_y$ и $q_y'$. Обозначим как $v_{split}$ узел, на котором пути поиска разделятся\;
        \For{$u$ -- узел на пути поиска $q_y$ или $q_y'$}{
          \If{$u_p \in (-\infty, q_x] \times [q_y, q_y']$}{report $u_p$}
        }
        \For{$u$ -- узел на пути поиска $q_y$ в левом поддереве $v_{split}$}{
          \If{путь поиска поворачивает влево}{report-all($u_r$, $q_x$)}
        }
        \For{$u$ -- узел на пути поиска $q_y'$ в правом поддереве $v_{split}$}{
          \If{путь поиска поворачивает вправо}{report-all($u_l$, $q_x$)}
        }
      }
     \caption{Алгоритм запроса в PST}
    \end{algorithm}

    #+CAPTION: Иллюстрация к алгоритму запроса в PST
    [[./figures/PS_QUERY.png]]

    #+BEGIN_lemma
    Запрос в PST работает за $O(\log n + k)$
    #+END_lemma

    #+BEGIN_proof
    Длина пути поиска в дереве -- $O(\log n)$, а кроме спуска по этому
    пути мы только выводим вершины, попавшие в ответ. Итого $O(\log
    n + k)$
    #+END_proof

    #+BEGIN_lemma
    Interval tree c двумя PST вместо списков будет занимать $O(n)$ памяти,
    построится за $O(n \log n)$, и будет отвечать на запрос за
    $O(\log^2 n + k)$
    #+END_lemma

    #+BEGIN_proof
    PST занимает столько же места ($O(n)$) и строится такое же время,
    как списки ($O(n \log n)$), поэтому оценки на память и
    препроцессинг такие же. Время ответа на запрос такое же, как у
    layered range tree, поэтому и оценка времени ответа аналогичная
    ($O(\log^2 n + k)$)
    #+END_proof

*** 2 Нахождение всех прямоугольников, в которые попадает точка.
    Каждый axis-aligned прямоугольник можно задать 2 отрезками - его
    проекциями на оси $x$ и $y$. Задача проверки попадания точки в
    прямоугольник сводится к проверке того, что проекции точки
    попадают в соответствующие проекции прямоугольника.

    Сделаем двухуровневый interval tree: дерево верхнего уровня будет
    построено по $x$ - проекциям прямоугольников. $I_{mid}$ в этом
    дереве будем хранить в виде обычного interval tree, но построенного
    уже по $y$ - проекциям прямоугольников, попавших в $I_{mid}$.

    Очевидно, что такая структура сохранит размер и время построения
    обычного interval tree (так как обычное interval tree строится за
    $O(n \log n)$ и занимает $O(n)$ места, ровно как два сортированных
    списка). И запрос в такой структуре будет выполняться за $O(\log^2
    n + k)$, аналогично interval tree с PST.
** 2 Пересечение прямоугольника с множеством непересекающихся отрезков.
   Если мы хотим пересекать прямоугольник с рандомно повернутыми
   отрезками, идея interval tree не работает. Сделаем другую
   структуру, она будет опираться не на факт axis-aligned'ности
   отрезков, а на факт их непересекаемости.

*** 2 Segment tree
    Это не то дерево отрезков, к которому мы привыкли.

    Посмотрим на одномерный случай (та же задача, что решалась с
    пом. interval tree). Пусть $I = \{[x_1 : x_{1}'], [x_2 : x_{2}'],
    ..., [x_n : x_{n}']\}$ -- множество отрезков в $\R$. Возьмем концы
    этих отрезков и отсортируем их, получим точки $p_1, p_2, ...,
    p_m$. Назовем множеством элементарных интервалов $E = \{
    (-\infty : p_1), [p_1 : p_1], (p_1 : p_2), ..., (p_m : +\infty)
    \}$.

    Построим на множесте $E$ сбалансированное дерево поиска. Листьями
    этого дерева являются сами элементарные интервалы, а внутренними
    узлами -- их объединения. Обозначим интервал, сопоставленный узлу
    $v$ как $Int(v)$.

    Если мы для каждого узла -- элементарного интервала -- будем
    хранить список отрезков из $I$, в которые он входит, мы сможем
    легко найти все отрезки, содержащие точку запроса $q_x$. Но это
    супер-неэффективно по памяти, если у нас есть куча перекрывающихся
    отрезков (будет $O(n^2)$). Но это можно исправить! В уже
    построенное дерево на элементарных интервалах будем вставлять
    очередной отрезок сверху вниз, оставляя его в тех узлах, которые
    он полностью покрывает.

    #+CAPTION: Структура Segment tree
    [[./figures/SEG_TREE.png]]

    Обозначим множество отрезков из $I$, хранящихся в узле $v$, как $I(v)$

    \begin{algorithm}[H]
      \SetKwFunction{InsertSegment}{InsertSegment}%
      \func{\InsertSegment{v, $[x, x']$}}{
        \KwData{Корень дерева и вставляемый отрезок}
        \KwResult{Дерево, в которое вставлен отрезок}
        \eIf{$Int(v) \subset [x, x']$}{
          $I(v) = I(v) \cup \{[x, x']\}$
        }{
          \If{$Int(v_l) \cap [x, x'] \neq \emptyset$}{
            \InsertSegment{$v_l$, $[x, Int(v_l)_r]$}
          }
          \If{$Int(v_r) \cap [x, x'] \neq \emptyset$}{
            \InsertSegment{$v_r$, $[x, Int(v_r)_l]$}
          }
        }
      }
      \caption{Вставка отрезка в дерево}
      \end{algorithm}

    #+BEGIN_lemma
    1) Такое дерево строится за $O(n \log n)$
    2) Оно занимается $O(n \log n)$ памяти
    #+END_lemma

    #+BEGIN_proof
    1) *Время построения*: Само дерево строится, как любое дерево
       бинпоиска $O(n \log n)$. Вставка отрезка -- по алгоритму выше
       -- занимает $O(\log n)$, всего отрезков $O(n)$, итого $O(n \log
       n)$.

    2) *Память*: Посмотрим, в каких из узлов дерева может содержаться
       некий отрезок $[x, x']$. Заметим, что на одной и той же глубине
       в дереве отрезок может содержаться не более, чем в 2 узлах --
       по построению алгоритма. Сдедовательно, дерево содержит $O(\log
       n)$ копий каждого отрезка. Итого $O(n \log n)$ памяти.
    #+END_proof

    *Возвращаемся к двумерному случаю*

    \begin{wrapfigure}{l}{0.3\textwidth}
    \centering
    \includegraphics[width=0.3\textwidth]{./figures/SEG_SUBTREE.png}
    \caption{Структура данных 2-го уровня: дерево поиска}
    \end{wrapfigure}

    Пусть мы хотим пересечь множество непересекающихся отрезков с
    вертикальным отрезком ${q_x} \times [q_y, q_y']$. Построим segment
    tree для проекций отрезков на ось $x$ -- сможем находить все
    отрезки, пересекающие вертикальную прямую $q_x$. Заметим, что так
    как отрезки непересекающиеся, то в пределах одного элементарного
    интервала они не меняют своего порядка по $y$. Значит, мы можем
    хранить $I(v)$ для каждого узла как дерево поиска по отрезкам, в
    котором сможем делать запросы по точке пересечения (как статус
    Бентли-Оттмана)

    Так как запрос в дереве поиска выполняется за $O(\log n)$ без
    учета вывода ответа, и таких деревьев поиска надо проверить
    $O(\log n)$, время ответа на запрос в segment tree составляет
    $O(\log^2 n + k)$

** 0 Пересечение прямоугольника с множеством случайных отрезков.
* 1 3:  Пересечение отрезков и поворот                              :volhovm:
  Рассмотрим задачу проверить пересечение отрезков.

  Вот есть у нас \(S_{1}=(p_{11},p_{12}), S_{2}=(p_{21},p_{22})\).

  В общем случае с Евклидовым пространством возникакуют какие-то
  проблемы, поэтому рассмотрим следующее определение Афинного
  пространства:

  A -- аффинное пространство, если A -- такой набор точек, что:
  1. В пространстве существует хотя бы одна точка.
  2. \(A, B, \leftrightarrow v = \vect{A B}\), причем \(B = A + v\).
  3. Точка + вектор = точка.
  4. ... и еще 40 аксиом векторного пространства

  Аффинное пространство отличается от стандартного евклидового тем,
  что в нем все точки равноправны, то есть ноль не зафиксирован. Типа
  у нас в этом пространстве есть точки, а векторы строятся из них.

  Рассмотрим гиперплоскость в n-мерном аффинном пространстве. Она,
  очевидно, задается $n-1$ вектором, или как минимум $n$ точками.

  Рассмотрим произвольную точку $A$ и набор векторов: $AP_1 \cdots
  AP_n$. Тогда если точка $A$ принадлежит гиперплоскости, то такой
  набор, очевидно, линейно зависим.

  Возьмем другую случайную точку $B$ и посмотрим, как меняются
  координаты при переходе из системы координат, связанной с $A$ в
  систему, связанную с $B$ (очевидно, что такой набор векторов может
  задавать базис, если он ЛНЗ).

  \begin{thm}[О повороте]
  Тут должно быть какое-то утверждение о повороте.
  \end{thm}

  \begin{proof}

  Рассмотрим точку $X$ в базисах из векторов $\{\vect{AP_i}\}_i$ и
  $\{\vect{BP_i}\}_i$. Тут точки ${P_i}$ задают гиперплоскость, то есть
  принадлежат ей и не линейно зависимы друг относительно друга в ней.

  \[
  X = X_A^1\vect{A P_1} +
      X_A^2\vect{A P_2} +
      \cdots +
      X_A^n\vect{A P_n}
    = X_B^1\vect{B P_1} +
      X_B^2\vect{B P_2} +
      \cdots +
      X_B^n\vect{B P_n}
  \]

  Для каждого вектора $\vect{AP_i}$ выразим его в базисе векторов
  ${\vect{BP_i}}$.

  \begin{align*}
  &\vect{AP_1} =
         \alpha_1^1\vect{B P_1} +
         \cdots +
         \alpha_1^n\vect{B P_n}\\
  &\cdots \\
  &\vect{AP_n} =
         \alpha_n^1\vect{B P_1} +
         \cdots +
         \alpha_n^n\vect{B P_n}
  \end{align*}

  Подставим выраженные $AP_i$ в первое уравнение.

  \begin{align*}
  X &= X_A^1\left(\sum\alpha_1^i\vect{BP_i}\right) +
       X_A^2\left(\sum\alpha_2^i\vect{BP_i}\right) +
       \cdots +
       X_A^n\left(\sum\alpha_n^i\vect{B P_i}\right) \\
    &= \vect{BP_1} \left(\sum\alpha_i^1X_A^i\right) +
       \vect{BP_2} \left(\sum\alpha_i^2X^i_A\right) +
       \cdots +
       \vect{BP_n} \left(\sum\alpha_i^nX_A^i\right)
  \end{align*}

  Сопоставив это с $X$, выраженным через $\{\vect{BP_i}\}_i$,
  получим следующую зависимость:

  \begin{align*}
    \left(X_B^1,X_B^2,\cdots,X_B^n\right)
  = \left(X_A^1,X_A^2,\cdots,X_A^n\right)
    \times
    \begin{pmatrix}
     \alpha_1^1 & \cdots & \alpha_1^n \\
     \vdots     & \ddots & \vdots     \\
     \alpha_n^1 & \cdots & \alpha_n^n
    \end{pmatrix}
  + \left(\vect{BA}^1,\cdots,\vect{BA}^n\right)
  \end{align*}

  Последнее --- вектор перехода из точки $B$ в $A$.
  Пусть дана точка $O$, которая воспринимается как ноль координат. Пусть
  также дана точка $O'$, которая выражается через $O$.
  Тогда матрица $A$ записывается следующим образом:
  \[
  A =
  \begin{pmatrix}
    P_1 - O' \\
    P_2 - O' \\
    \cdots  \\
    P_n - O'
  \end{pmatrix}
  \]

  Тут $P_i$ и $O'$ -- это точки, координаты которых записаны отнсительно базиса
  $O\{e_1,\cdots,e_n\}$.

  Заметим, что мы можем разбить все пространство на три класса согласно того,
  какой знак перехода из $O$ в $O'$. $A$ \--- матрица перехода от $O$ к $O'$,

  Ориентация \--- свойство точки относительно базиса $O\{e_1,\cdots,e_n\}$ и
  гиперплоскости, заданной точками $\{P_i\}_{i=1}^n$.

  Известный факт из линейной алгебры:
  \[
   \begin{vmatrix}
    \vect{P_1} & 1      \\
    \vect{P_2} & 1      \\
    \vdots     & \vdots \\
    \vect{P_n} & 1      \\
    \vect{A}   & 1
   \end{vmatrix}
  =
   \begin{vmatrix}
    P_1 - A \\
    P_2 - A \\
    \vdots  \\
    P_n - A
   \end{vmatrix}
  \]

  Покажем, что знак детерминанта матрицы $A$ действительно зависит от положения
  точки относительно гиперплоскости. Возьмем $A$, $B$, рассмотрим множество
  точек $\{\vect{A}t + \vect{B}(1-t)\}$.

  ~тут какая-то магия, TODO~

  \end{proof}
* 3 4:  Локализация в многоугольнике
   Есть многоугольник P и вершина q. Задача локализации qрешается
   по-разному в зависимости от вида P.
** P - выпуклый
   Время работы O(log(n)).  Зафиксируем направление обхода точек
   P. Если q лежит левее грани [p_0, p_1] или правее грани [p_0,
   p_n-1], точка снаружи. Иначе бинпоиском найдем ребро [p_i, p_i+1]
   такое, что повороты [p_0, p_i, q] и [p_0, p_i+1, q] имеют разный
   знак.  Проверим поворот [p_i, p_i+1, q]. Если левый - точка внутри,
   если правый - снаружи.
** P - невыпуклый
   Время работы O(n). Пустим луч из точки куда-нибудь (например, по
   иксу), посчитаем количество пересечений с границей.  Если луч
   пересекается по точке P, будем учитывать только верхнюю точку. Если
   луч пересекается по прямой, забьем на такое пересечение. А если
   точки целочисленные, можно просто пускать косой луч.

* 2 5:  Статические выпуклые оболочки в $\R$
** 3 Джарвис (заворачивание подарка)
   CLOSED: [2016-01-07 Thu 17:12]
   1. Берем самую нижнюю левую точку $p_0$.
   2. За $O(n)$ перебираем все точки, берем минимальную точку по углу относительно $p_0$.

      *Пояснение*: Пусть мы хотим сравнить по этому параметру точки $p_i$ и $p_j$.
      Тогда $p_i < p_j \Leftrightarrow turn(p_0, p_i, p_j) < 0$.
   3. Добавляем выбранную точку в оболочку, проделываем то же самое с ней и т. д.

   Общее время работы, очевидно, $O(n^2)$

   *Доказательство корректности*

   Пусть после завершения Джарвиса осталась точка $P$, не лежащая внутри
   полученной оболочки. Это значит, что она лежит справа от некоторого ребра $AB$
   (считаем, что ребра оболочки упорядочены против часовой стрелки, так что все внутренние
   точки лежат слева от них).

   Но тогда $P$ меньше по повороту относительно $A$ чем $B$.
   Значит, мы должны были выбрать ее, а не $B$, для построения очередного ребра оболочки,
   когда мы рассматривали точку $A$. *Противоречие*. Следовательно, такой точки $P$ не существует.
** 3 Грэм
   CLOSED: [2016-01-07 Thu 17:12]
   Возьмем самую левую нижнюю точку p. Отсортируем все остальные точки по повороту,
   который они образуют с этой каким-нибудь нормальным алгоритмом (за $O(n \log n)$).
   Если все три точки лежат на одной прямой, то меньшей считается та точка, которая ближе к p.

   Положим в стек точку p и первую точку из отсортированного списка остальных. Далее идем
   по всем точкам из списка и делаем следующее:

   1. Обозначим рассматриваемую точку как a, а последние 2 точки, лежащие на стеке - как b и c.
   2. Если $turn(c, b, a) \geq 0 (правый)$, то скидываем со стека точку b и возвращаемся к пункту 1
   3. Иначе кладем a на стек и рассматриваем следующую вершину по списку.

   В конце в стеке будут лежать вершины выпуклой оболочки.

   *Корректность*

   Докажем корректность алгоритма по индукции.

   * *База*
     На третьем шаге алгоритм, очевидно, построит корректную выпуклую оболочку для первых 3 точек
     (просто потому, что невыпуклую построить нельзя))) )
   * *Переход*
     Пусть на k - 1 шаге построена корректная выпуклая оболочка для первых k - 1 точек.
     Докажем, что на k-ом шаге будет построена корректная выпуклая оболочка для k точек.
     1) В силу отсортированности точек по повороту, точки $p_1 .. p_{k-1}$ лежат слева от ребра
        $p_k p_0$ (возможно, $p_{k-1}$ лежит на ребре)
     2) На шаге 2 алгоритма из прошлой оболочки будут выброшены все вершины, видные из $p_k$,
        то есть, ни с каким из оставшихся в оболочке ребер $p_k$ не будет образовывать правый поворот.
     3) Следовательно, все ребра новой оболочки будут образовывать со всеми остальными вершинами левый (или нулевой)
        поворот, что нам и нужно.

    *Асимптотика*

    Сортировка точек за $O(n \log n)$. Проход по точкам за $O(n)$, так как каждая точка может 1 раз быть
    добавлена в стек и 1 раз из него удалена, всего точек $n$. Итого $O(n \log n)$.

** 3 Эндрю
   CLOSED: [2016-01-07 Thu 17:12]
   Эндрю - это почти в точности Грэм.
   1. Возьмем самую левую и самую правую точки - $p_0$ и $p_n$
   2. Разделим все множество точек на "верхние" и "нижние" - выше прямой $p_0 p_n$ и ниже ее, соответственно.
   3. Для "верхних" и "нижних" точек построим верхнюю и нижнюю оболочку соответственно.
      Строить будет Грэмом, но представляя, что точка $p_0$ лежит в $\inf$ и $-\inf$ соответственно.
      Тогда мы можем сказать, что обычная сортировка точек по координате $x$ эквивалентна сортировке по
      повороту относительно бесконечно удаленной точки. Значит, отсортируем на самом деле точки каждой
      из половин по $x$-координате и запустим Грэма.
   4. Объединим верхнюю и нижнюю оболочки.

   *Корректность*

   Грэм корректен, а значит, верхняя и нижняя оболочки будут корректны. Тогда и вся оболочка корректна.

   *Асимптотика*

   Ровно такая же как у Грэма. Но на практике Эндрю чуть быстрее лишь потому, что сортировка идет
   по $x$-координате, а не по повороту, и это быстрее.
** 3 Чен
   CLOSED: [2016-01-07 Thu 17:12]
   Чен - это продукт классической методики улучшения каких-то алгоритмов:
   возьмем 2 известных алгоритма - один просто хороший, а другой - обладающий
   неким нужным свойством. Разобьем задачу на подзадачи, подзадачи решим одним
   алгоритмом, а объединим решения другим. Останется подобрать константу посерединке.

   Так и здесь - Чен объединяет просто хороший алгоритм Грэма с output-sensitive
   алгоритмом Джарвиса, получая хороший output-sensitive алгоритм с временем работы $O(n \log k)$,
   где $k$ - количество вершин выпуклой оболочки.

   *Алгоритм*

   Разобьем все точки на произвольные группы по $m$ (или меньше) штук в каждой.
   Тогда всего групп будет $r = \frac{n}{m}$

   1. Для каждой группы в отдельности найдем ее выпуклую оболочку Грэмом за $O(m \log m)$.
      Значит, всего на этот шаг уйдет
      $O(r) \cdot O(m \log m) = O(\frac{n}{m}) \cdot O(m \log m) = O(n \log m)$ времени.
   2. Теперь запустим на всех точках Джарвиса. Однако заметим, что среди точек, входящих в одну
      группу, мы можем выбрать самую левую по повороту бинпоиском - так как для группы построена
      выпуклая оболочка. (Бинпоиск - это вот эта прекольная тема с вложенными выпуклыми оболочками, например)

      Значит, на одном шаге Джарвисанам нужно перебрать все группы, среди которых подходящую точку мы ищем за $O(\log m)$.
      Итого - $O(r \log m) = O(\frac{n}{m} \log m)$. Всю выпуклую оболочку мы найдем за $O(\frac{kn}{m} \log m)$.

   Сложив асимптотики двух шагов, видим, что полное время работы - $O(n (1 + \frac{k}{m}) \log m)$. Из этого
   получится желанная асимптотика $O(n \log k)$, если мы с самого начала выберем $m = k$. Но как нам это сделать?

   Давайте просто перебирать m, начиная с маленького. Если вдруг во время выполнения на m + 1 шаге Джарвис
   еще не построил выпуклую оболочку, значит, $m < k$ и нам надо взять его побольше.

   Но как перебрать $m$ достаточно быстро, и при этом не переборщить на последнем шаге?
   Давайте возьмем начальный $m = 2$ и на каждом шаге перебора будем возводить его в квадрат.
   Иными словами, $m = 2^{2^t}$, и $t$ перебирается от 0 до $\lceil \log\log k \rceil$

   Докажем, что такой перебор не замедлит общее время работы:

   $\sum\limits_{t=0}^{\lceil \log\log k \rceil} O\left(n \log(2^{2^t})\right) = O(n) \sum\limits_{t=0}^{\lceil \log\log k \rceil} O(2^t) = O\left(n \cdot 2^{1+\lceil \log\log k \rceil}\right) = O(n \log k)$

   Итак, мы получили алгоритм с гарантированным временем работы $O(n \log k)$.

** 2 QuickHull
   Как QuickSort, только QuickHull.

   1. Возьмем крайние по иксу точки (они точно войдут в оболочку), обозначим их как $p_0$ и $p_1$
   2. Разобьем множество на точки, лежащие ниже и выше прямой $p_0 p_1$ (посвопаем 2 указателями, как в квиксорте)
   3. Для верхнего множества найдем самую удаленную от $p_0 p_1$ точку - $q_1$
   4. Выкинем все точки, лежащие внутри треугольника $p_0 p_1 q_1$
   5. Разделим оставшиеся точки на $S_1$ - лежащие выше $p_0 q_1$, и $S_2$ - лежащие выше $q_1 p_1$.
   6. Рекурсивно повторим пункт 3 для $S_1$ и $S_2$.
   7. Повторим пункт 3 для нижнего множества.
   8. Объединим верхнюю и нижнюю оболочки

   Утверждается, что для случайного набора точек этот алгоритм отработает за $O(n \log n)$
   Понятно, что в худшем случае алгоритм отработает за $O(n^2)$ - мы можем построить такой
   выпуклый многоугольник, что на шаге 4 никогда ничего не будет выкинуто, а на шаге 5
   в $S_1$ будут входить все оставшиеся точки.

   Докажем, что для случайно разбросанных точек алгоритм отработает за $O(n \log n)$

   *WARNING: ЭТО ГОВНО Я ПРИДУМЫВАЛ САМ (почти)*

   Пусть время, необходимое для нахождения оболочки над некой прямой и множеством точек
   $S$ есть $T(S)$
   Тогда $T(S) = O(|S|) + T(S_1 \in S) + T(S_2 \in S)$, где $S_1$ и $S_2$ из пункта 5.

   За $O(|S|)$ мы находим самую удаленную от прямой точку $q_1$. Заметим, что вообще все рассматриваемые точки
   находятся в прямоугольнике, ограниченном прямой $p_0 p_1$ снизу, и вершиной $q_1$ сверху.
   Заметим также, что треугольник $p_0 q_1 p_1$ занимает половину площади этого прямоугольника.
   Это значит, что при равномерном распределении точек внутрь треугольника попадет примерно половина всех точек.
   А значит, количество рассматриваемых точек на следующем шаге рекурсии будет меньше в 2 раза.
   Значит, всего шагов рекурсии будет $O(\log n)$, что в итоге дает оценку $O(n \log n)$.

** 0 Оболочка многоугольника
** 0 Оболочка полилинии
* 3 6:  Динамическая выпуклая оболочка                              :volhovm:
  CLOSED: [2016-01-09 Sat 01:23]
  #+CAPTION: Иллюстрации к динамической выпуклой оболочке
  [[./figures/CH_DYN.jpg]]

** 3 Задача объединения двух верхних $CH$
   CLOSED: [2016-01-09 Sat 01:07]
   Начнем с подзадачи: пусть у нас есть две каких-то верхних оболочки в
   $\mathbb{R}^2$ , разделенных по иксу (~CH_DYN_1~). Мы хотим
   объединить эти верхних оболочки, проведя касательную сверху. Как
   такую касательную построить? (inb4 такая существует, потому что
   "палка сверху падает на холмики"). Как искать такую касательную за
   логарифм?

   Очевидно, что касательная не проходит по экстремальным точкам
   (нарисуем большой холмик и рядом маленький).

   Как добиться асимптотики $O(\log{n})$? Предположим, что есть пара
   точек на холмах. Будем типа пользоваться некоторым подобием
   бинпоиска на двух холмах сразу -- держать четыре границы
   одновременно. Ну, два массива -- это два множества точек для двух
   оболочек, отсортированных по иксу (См. ~CH_DYN_2~).

   (~CH_DYN_3~) описывает классификацию всех попаданий касательной к
   кускам выпуклой оболочки для левой и правой кучи. Эта классификация
   важна, так как по ней мы будем определять текущее состояние
   бинпоиска. Как эти состояния отличать, понятно -- считаем повороты
   касательной с ребром, куда она попала. Случаи с двумя точками по
   одну сторону классифицируются поворотом.Проверка на два случая
   делается за $2\times2 = 4$ поворота.

   Рассмотрим случай $A$ в ~CH_DYN_2~. Случай $A$ распознается так: это
   случай слева a), а справа г). Рассмотрим прямую $l$ и какую-то
   касательную к левой куче. Утверждается, что если мы будем
   поворачивать касательную вокруг точки касания, поворачивать вниз, то
   пересечение касательной и $l$ как точка, будет опускаться вниз
   (~CH_DYN_4~). Из этого следует, что можно отрезать нижние куски
   выпуклых оболочек.

   Рассмотрим остальные случаи, например $B$ в ~CH_DYN_2~. В этом
   случае мы можем откинуть нижнюю часть правой оболочки. Симметричный
   случай тоже очевиден.

   Случай с двумя касательными (случаи в), e) в диаграмме) тоже
   распознается однозначно и есть ответом бинпоиска.

   Пусть на правом холме у нас касательная, а на левом точка из случая
   a) -- случай $A$ в ~CH_DYN_5~. Тогда на левом холме мы можем
   откусить нижний кусок, а на правом -- левый нижний от
   касательной. Симметрично тоже. $B$ тоже так решается, то есть можно
   слева откусить нижний, а справа нижний левее точки касания.

   Теперь рассмотрим самый нетривиальный случай (~CH_DYN_6~): пусть
   слева б), а справа д). Рассмотрим пересечение прямых $l_1$ и
   $l_2$. Прямые проведем через текущие вершины и следующие
   выше. Проверим точку $L$ пересечения $l_2$ и $l_2$. Тогда если
   прямая $L$ лежит полностью в интервале между холмами, то можем
   выкинуть и у левого и у правого нижние куски. Если точка $L$ лежит в
   левом холме (левее самой правой точки левого холма), то мы
   выкидываем весь нижний кусок только левого холма вместе с этой
   точкой. Аналогично с правым холмом.

   Теперь мы умеем решать задачу найти касательную двух верхних
   полуоболочек.

   Задача поиска всех четырех касательных для двух выпуклых множеств
   сводится к этой: разобьем на несколько подмножеств (верхние и
   нижние) и решим алгоритмом выше.

   В реализации алгоритма удобно хранить две оболочки skip-листами и
   вместо бинпоиска просто спускаться на нижний уровень и продолжать
   алгоритм на нем. Вот мы идем по какому-то уровню, выбираем
   вершину. Пусть мы определили, что нам необходимо отрезать какую-то
   часть оболочки, к примеру, левую -- просто пойдем вправо по
   текущему уровню, пометив "отрезанную" вершину флагом. Спуск на
   нижний уровень будет происходить, если нужно пойти в какую-то
   сторону, а та вершина уже "отрезана".
** 3 Итеративный алгоритм
   CLOSED: [2016-01-09 Sat 01:23]
   Теперь мы хотим честного итеративного построения: есть некоторая
   структура, в которой мы храним верхнюю оболочку, и мы хотим ее
   быстро изменять (добавлять или удалять точки).

   Для начала вспомним, как мерджить skip-листы. Лист мы держим сверху
   за вершину самого высокого уровня, на каждом уровне мы можем
   распознать первую и терминальную вершины.
   * Сплит: дали нам вершинку, мы нашли ее в самом нижнем
     уровне. Запускаемся для левой стороны: удаляем вершину,
     обрезаем. Идем влево, пока не можем подняться наверх,
     поднимаемся, делаем вершинку терминальной на этом уровне, и так
     до верхнего уровня. Аналогично для правой стороны помечаем
     вершину первой, идем вправо, поднимаемся если можем, и так до
     самого высокого уровня.
   * Мердж делается так же, про доказательство асимптотики думать не
     надо (бернуллевость не испортится).

   Пусть есть оболочка, являющаяся общей частью двух оболочек
   подмножеств точек (~CH_DYN_7~). Есть также указатель на точку, по
   которой нужно разделиться. Причем у нас есть синяя и красная
   (карандашом) части. Тогда мы можем разделить нашу оболочку на две
   за $2*\log{n}$ на объединение двух скиплистов.

   ОБщая структура для хранения оболочки итеративно наивно
   представляется так: дерево, в котором листья -- наши точки, а
   другие узлы -- это верхняя оболочка сыновей. Это O(n\log{n})
   памяти. Такая структура имеет два недостатка -- памяти много и
   неочевидно, как делать удаление. Добавление реализуется
   прокидыванием вершины вниз и перестраиванием все оболочки вверх во
   время просеивания. Если дерево нужно балансировать, то во время
   поворотов нужно будет перестраивать узлы.

   Более удобная структура выглядит следующим образом: в самом верхнем
   узле будет храниться честная выпуклая оболочка всех точек. Не
   верхнем, будем хранить только ту часть выпуклой оболочки, которая
   не является общей с родителем. На ~CH_DYN_7~ "не общие части" как
   раз обозначены синим и серым цветом. Продавливание точки вниз
   становится существенно понятнее и проще: разбиваем текущую выпуклую
   оболочку (сначала корневую), объединяем за $\log{n}$ с
   детьми. Определяем, куда кидать точку -- влево или вправо. Ту
   часть, в которую не нужно добавлять, не трогаем. Так проходим вниз
   и добавляем вершинку. Заметим, что теперь уже не нужно хранить
   ничего в листах, так как два соседних листа однозначно определяются
   оболочкой в их родителе. Дальше строим оболочку и просеиваем
   вверх. При просеивании вверх берем двух детей, объединяем, отдаем
   родителю оболочку, себе оставляем только те части, которые не
   входят в парента. Удаление происходит аналогично.

   Итого конечный алгоритм поддерживает оболочку с удалением и
   добавлением за $\log^2{n}$.
* 0 7:  Трехмерные выпуклые оболочки (CHN)                          :volhovm:
  Немножко модифицируем quickhull на плоскости, чтобы можно было
  очевидно его перенести в n-мерное пространство. Quickhull не
  работает хорошо с детерменированной прямой.

  Давайте выберем прямую $L_1L_2$. Зафиксируем в надмножестве случайную
  точку $A$. Все точки, которые попали в $L_1AL_2$
  выкидываем. Рассмотрим все точки, которые не попали
  внутрь. Подразобьем их лучами $L_1A$ и $L_2A$. Типа будем выбирать
  случайные точки вверху и продолжать выпуклую оболочку.

  Для каждого разбиения мы перебираем все точки и для каждой мы
  запоминаем грани, которые видно.

  Че делать в $n$-мерном пространстве? Возьмем произвольный
  тетраэдр. На самом деле лучше брать максимально большой
  тетраэдр. Потом для каждой новой случайной точки мы понимаем, к
  какой гране он принадлежит, какие грани эта точка видит.
* 3 8:  Триангуляция (существование и ушная триангуляция)
  Читать на [[http://neerc.ifmo.ru/wiki/index.php?title=Триангуляция_полигонов_(ушная_%2B_монотонная)#.D0.A2.D0.B5.D0.BE.D1.80.D0.B5.D0.BC.D0.B0_.D0.BE_.D1.81.D1.83.D1.89.D0.B5.D1.81.D1.82.D0.B2.D0.BE.D0.B2.D0.B0.D0.BD.D0.B8.D0.B8_.D1.82.D1.80.D0.B8.D0.B0.D0.BD.D0.B3.D1.83.D0.BB.D1.8F.D1.86.D0.B8.D0.B8][вики]].

  #+ATTR_LATEX: :options [триангуляция]
  #+BEGIN_defn
  Разбиение многоугольника на множество
  треугольников, внутренние области которых попарно не
  пересекаются.
  #+END_defn

  #+ATTR_LATEX: :options [простой многоугольник]
  #+BEGIN_defn
  Многоугольник без самопересечений.
  #+END_defn

  #+ATTR_LATEX: :options [О существовании триангуляции многоугольника]
  #+BEGIN_thm
  У любого простого многоугольника $P$ с $n$ вершинами всегда
  существует триангуляция, причем количество треугольников в ней
  равно $n-2$.
  #+END_thm

  #+BEGIN_proof
  По индукции. Для $n=3$ все понятно. Для больших $n$ берем самую
  левую вершину $v$. Тогда либо ребро между ее соседями, либо между
  ней самой и самой дальней вершины от соседей \--- диагональ. Она
  поделит исходный $n$-угольник на два меньшего размера
  $(|P_1| + |P_2| = n + 2)$, у которых по индукции существует
  триангуляция. По индукции $P_1$ и $P_2$ поделятся на $m_1 - 2$ и
  $m_2 - 2$ треугольников соответственно, так что в исходном
  $n$-угольнике будет $(m_1 - 2) + (m_2 - 2) = n - 2$ треугольника.
  #+END_proof

  Алгоритм примитивной триангуляция за $O(n^4)$: переберем $O(n^2)$
  возможных диагоналей, за $O(n)$ проверим, пересекает ли она
  внутренние ребра. Повторим это $n-3$ раза. Итого $O(n^4)$.

  #+ATTR_LATEX: :options [ухо]
  #+BEGIN_defn
  Вершина многоуольника $v_i$ называется ухом, если диагональ
  $v_{i-1}v_{i+1}$ лежит строго во внутренней области многоугольника.
  #+END_defn

  #+ATTR_LATEX: :options [о существовании двух ушей в многоугольнике]
  #+BEGIN_thm
  У любого простого многоугольника $P$ с $n$ вершинами всегда
  существует два не пересекающихся между собой уха.
  #+END_thm

  #+BEGIN_proof
  Индукции. Для $n=4$ все понятно. Для больших $n$
  возьмем произвольную вершину $v$. Два случая:
  * $v$ \--- ухо. Отрежем его, получим $n-1$-угольник, в котором, по
    индукции, есть два непересекающихся уха. Они также являются ушами
    исходного $n$-угольника, поэтому теорема верна.
  * $v$ \--- не ухо. Значит, треугольник $prev(v); v; next(v)$ содержит
    вершины $P$. Как и в теореме о существовании триангуляции,
    выберем наиболее ближнюю к $v$ вершину, поделим $P$ на $P_1$ и
    $P_2$ по диагонали, у $P_1$ и $P_2$ по индукции есть два уха \--- все
    хорошо.
  #+END_proof

  Алгоритм (ушная триангуляция за $O(n^2)$): как в лабе писали
  короче: пройдемся по всем вершинам и за $O(n)$ проверим их на
  уховость. Если ухо - отрежем.  На уховость проверяем за $O(n)$ по
  определению. Итого $O(n^2)$.
* 1 9:  Триангуляция с заметающей прямой
  Также известен как монотонный метод. Читать на [[http://neerc.ifmo.ru/wiki/index.php?title=Триангуляция_полигонов_(ушная_%2B_монотонная)#.D0.9C.D0.BE.D0.BD.D0.BE.D1.82.D0.BE.D0.BD.D0.BD.D1.8B.D0.B9_.D0.BC.D0.B5.D1.82.D0.BE.D0.B4][вики]].

** Определение (монотонный многоугольник)
   Многоугольник P называется монотонным относительно прямой l, если любая l' _|_ l пересекает стороны P
   не более двух раз.
** Определение (y-монотонный многоугольник)
   Многоугольник, монотонный относительно оси Y.
** Определение (start, end, split, merge и regular---вершины)
   Пусть \phi \--- внутренний угол при вершине. Тогда назовем вершину:
   * Start \--- если два ее соседа лежат ниже ее самой и \phi < \pi
   * Split \--- если два ее соседа лежат ниже ее самой и \phi > \pi
   * End \--- если два ее соседа лежат выше ее самой и \phi < \pi
   * Merge \--- если два ее соседа лежат выше ее самой и \phi > \pi
   * Regular \--- если один сосед лежит выше, а другой ниже ее самой
** Лемма (достаточное условие y-монотонности)
   Если в многоугольнике нет split- и merge-вершин, то он y-монотонен.

   Доказательство: контрапозиция. Покажем, что не y-монотонный многоугольник содержит либо merge, либо split вершину.
   Дальше на викиконспектах все понятно.
** Алгоритм (разбиение на монотонные части)
   Будем избавляться от split- и merge-вершин, проводя из них диагонали.
   Пойдем горизонтальной заметающей прямой сверху вниз и, встречая split/merge-вершину, будем проводить диагонали до ближайшей от прямой вершины.
   TODO : разобраться подробнее + корректность
** Алгоритм (триангуляция монотонного многоугольника)
   KW : стек нетриангулированных вершин, свойство перевернутой воронки
   Разобраться в остальном.
* 0 10: Полуплоскости и выпуклые оболочки
* 0 11: Пересечение множества отрезков
* 1 12: PSLG и DCEL: определение, построение PSLG множества отрезков.
  #+LATEX_OPTIONS: :option [PSLG]
  #+BEGIN_defn
  Planar straight line graph (ППЛГ -- планарный прямолинейный
  граф) -- плоская укладка планарного графа, в которой все ребра
  представлены отрезками прямой.
  #+END_defn

  #+LATEX_OPTIONS: :option [Фейс PSLG]
  #+BEGIN_defn
  Face (грань) PSLG - это максимальное связное подмножество плоскости,
  не содержащее точек ребер или вершин PSLG
  #+END_defn

  #+LATEX_OPTIONS: :option [DCEL]
  #+BEGIN_defn
  Doubly-connected edge list (РСДС -- реберный список с двойными
  связями) -- структура данных для представления PSLG. Состоит из
  записей трех типов: вершина, фейс и полуребро.
  #+END_defn

  #+CAPTION: Наглядная иллюстрация структуры DCEL
  [[./figures/DCEL4.png]]

  #+LATEX_OPTIONS: :option [Вершина]
  #+BEGIN_defn
  Вершина (в смысле DCEL) -- это структурка данных, представляющая
  собой вершину PSLG в DCEL. Хранит в себе координаты точки ($v.x$ и $v.y$)
  и указатель на инцидентное (исходящее из этой вершины) полуребро $v.incEdge$
  #+END_defn

  #+LATEX_OPTIONS: :option [Фейс]
  #+BEGIN_defn
  Фейс (в смысле DCEL) -- это структурка данных, представляющая
  собой фейс PSLG в DCEL. Хранит в себе указатель на какое-либо из
  своих внутренних полуребер $face.edge$, а так же список указателей на
  внешние полуребра 'дырок' (фейсов, лежащих целиком внутри данного и
  не связанных с остальными), если таковые имеются ($face.holes$).
  #+END_defn

  #+LATEX_OPTIONS: :option [Полуребро]
  #+BEGIN_defn
  Полуребро (в смысле DCEL) -- это структурка данных, представляющая
  собой направленное ребро PSLG в DCEL. Полу -- потому что для каждого
  неориентированного ребра в PSGL мы храним 2 разнонаправленных
  полуребра. Полуребра ориентированы так, чтобы каждый фейс обходился
  по ним против часовой стрелки.

  Полуребро содержит следующие поля:
  1) Указатель на следующее полуребро $e.next$
  2) Указатель на предыдущее полуребро $e.prev$
  3) Указатель на ребро-"близнеца" (полуребро соседнего фейса,
     направленное в другую сторону и соответствующее тому же ребру)
     $e.twin$
  4) Указатель на вершину, из которой исходит ребро $e.origin$
  5) Указатель на фейс, которому инцидентно ребро $e.face$
  #+END_defn

  Насчет восстановления DCEL из прямых -- см. в бонусных задачах (внезапно)

* 0 13: PSLG overlaying
* 1 14: Локализация в PSLG
  Весь билет супер-подробно в одной статье:
  [[http://www.link.cs.cmu.edu/15859-f07/papers/point-location.pdf]]
  (скорее всего, не нужно)

  У нас есть PSLG (представленная как DCEL). Идут запросы в виде
  точек. Нужно уметь быстро определять, в какой фейс (ребро?) попала
  точка.

  #+CAPTION: Разбиение PSLG на slabs
  [[./figures/SLABS.png]]

  Идея старая: давайте локализоваться сначала по $x$, потом по
  $y$. Как? Проведем через каждую вершину PSLG прямую, разбив ее на
  полоски (slabs), как на рисунке.

  Отсортируем теперь эти полоски по $x$ - координате левой
  границы. Теперь бинпоиском мы легко можем находить полоску, в
  которую попала наша точка. Заметим, что по построению ребра могут
  пересекаться только на границах полосок, а значит, в рамках 1
  полоски все ребра вертикально упорядочены. Давайте в каждой полоске
  построим на на ребрах дерево поиска по $y$ и будем радостно
  локализовать точку между ними за $O(\log n)$. Ура!

  Не так быстро. Такая структура данных в худшем случае занимает
  $O(n^2)$ памяти, что очень плохо. Однако, ее можно улучшить!

** Персистентные деревья
   Давайте рассмотрим $x$ - координату как *время*. Двигаясь вправо по
   $x$, мы двигаемся во времени. Пусть у нас есть дерево бинпоиска,
   изначально пустое. Когда мы встречаем начало отрезка, мы добавляем
   в его в дерево с текущей $y$ - координатой. Когда мы встречаем
   конец отрезка, удаляем его из дерева. (*NB*: если отрезок(ки)
   лежит(ат) на вертикальной прямой, события начала/конца сортируются
   по $y$, а если один отрезок заканчивается, а другой начинается в
   одной и той же точке, событие начала идет раньше (ну как в
   Бентли-Оттмане, понятно))

   #+CAPTION: Персистентное дерево с копированием путей
   [[./figures/PERS_TREE1.png]]

   Так как отрезков $n$, то всего событий (а значит, операций
   изменения дерева) всего $2n$. Вернемся к первоначальной
   задаче. Применяя к slabs метафору времени, один slab - это отрезок
   времени, когда ничего не происходило. То есть, на один slab
   приходится одна версия персистентного дерева (а не отдельное дерево
   бинпоиска, как раньше). С точки зрения операции поиска ничего не
   изменилось, а вот потребление памяти уменьшилось до $O(n \log n)$ -
   так как в персистентном дереве а-ля Хаскель при операции
   добавления/удаления прибавляется/освобождается $O(\log n)$ памяти
   (узлы на пути от корня до вставленной/удаленной вершины + $O(1)$ на
   перебалансировку), а всего таких операций $O(n)$

** Очень классные персистентные деревья!
   Можно сделать персистентные деревья, которые занимают $O(n)$
   памяти, невероятно! Только хер проссышь как их строить, попробуем
   сначала сделать что-нибудь попроще, но такое же модное -
   персистентный список, например.



* 0 15: Трапецоидная карта
* 3 16: Вращающиеся калиперы                                        :volhovm:
  CLOSED: [2016-01-09 Sat 14:23]
  Вращающиеся калиперы -- это несложный паттерн проектирования
  различных алгоритмом, требующих последовательного обхождения
  выпуклых многоугольников в $\R^2$. Рассмотрим применение метода
  сразу на практической задаче.

  Пусть дано некоторое множество точек. Определим его диаметр как
  максимальное расстояние между какими-либо двумя точками. Покажем,
  как можно найти диаметр этого множества.

  #+BEGIN_lemma
  Диаметр множества лежит на выпуклой оболочке этого множества
  #+END_lemma
  #+BEGIN_proof
  Очевидно от противного: пусть мы нашли диаметр множства $P$ -- $ab$,
  причем, не теряя общности, $b \notin CH(P)$. Тогда утверждается, что
  можно пустить луч $ab$ и посмотреть, в какой точке он пересечет
  выпуклую оболочку. Легко показать, что как минимум одна точка,
  формирующая ребро выпуклой оболочки, пересеченное лучем, имеет
  дистанцию до $a$ больше $dist(a,b)$.
  #+END_proof

  # очень жаль, что нельзя сделать этого с помощью org-тегов
  \begin{wrapfigure}{l}{0.3\textwidth}
  \centering
  \includegraphics[width=0.3\textwidth]{./figures/CALIPERS_DIAMETER.png}
  \caption{Поиск диаметра множества точек с помощью вращающихся калиперов}
  \end{wrapfigure}

  Алгоритм поиска таков: для начала найдем минимальную и максимальную
  точку среди точек выпуклой оболочки (лексикографически) $A$ и
  $B$. Мысленно создадим две вертикальных параллельных прямых,
  проходящих через соответствующие точки -- $l_1$, $l_2$. Будем
  заворачивать калиперы по часовой стрелке, поэтому условимся, что
  $l_1$ смотрит вверх, а $l_2$ вниз. Добавим текущие точки, на которых
  стоят параллельные прямые, в список ребер ответа ($\langle A,
  B\rangle$). Сравним угол между $l_1$ и $AC$ с углом между $l_2$ и
  $BD$. Выберем меньший и перейдем к следующей точке относительно
  выбранной, повернув при этом соответствующую прямую на величину
  углу, так, чтобы прямая теперь совпадала с $AC$. Будем всегда
  поддерживать параллельность калиперов (прямых), поэтому вторую
  прямую тоже мысленно повернем. Получим две новые прямые $l_3$,
  $l_4$. Перейдем в начало процесса, добавив $\langle C, B\rangle$ в
  список ребер ответа. Когда алгоритм придет в начальное положение, на
  выходе получим список ребер, среди которых будет искомое. Переберем
  их за линию и найдем максимальное (можно делать это in-place во
  время алгоритма, формируя один большой fold).

  В реализации углы сравниваются поворотами, и функция хранит только
  одно доминирующее ребро, на котором калипер "лежит" полностью, а
  второй калипер параллелен первому и соответствует некоторой
  точке. Исключение составляет первый шаг, на котором калиперы могут
  лежать исключительно на точках -- можно добавить фиктивное ребро с
  координатами $(x, y+1)$ относительно минимальной или максимальной
  точки.

  #+BEGIN_lemma
  Алгоритм поиска диаметра работает корректно, среди найденных ребер
  найдется диаметр.
  #+END_lemma
  #+BEGIN_proof
  Докажем от противного. Пусть среди всех пар точек, формирующих
  ребра, нет нужной. Отметим, что метод выдает все ребра, для которых
  верно, что сущетствует пара параллельных прямых, не пересекающих
  многоугольник, проходящих через эти точки. Очевидно, что если для
  двух точек такие прямые не построить, то и диаметр на них лежать не
  может -- легко показать, что взяв соседнюю, мы увеличим расстояние
  между ними (следует из непараллельности, надо аккуратно посмотреть
  углы).

  Отсюда диаметр лежит в классе пар точек, на которых прямые
  строятся. Поскольку алгоритм просматривает все такие (несложно
  показать), то диаметр будет лежать среди ребер ответа.
  #+END_proof

  Кроме уже рассмотренной, метод вращающихся калиперов может быть
  использован для решения следующих задач:
  1. Поиск расстояния между двумя многоугольниками. Абсолютно
     аналогично проводим алгоритм для поиска диаметра (в инициализации
     у более левого/нижнего берем минимальную точку, а у другого
     максимальную), но добавляем в список ответа пару
     $\langle доминирующее ребро, вершина \rangle$.
  2. Поиск двух общих касательных у выпуклых многоугольников. В
     инициализации у обоих полигонов берем минимальные точки, калиперы
     сонаправлены. В момент, когда калиперы меняются местами (один
     становится выше другого), мы проходим точку касания.

     #+ATTR_LATEX: :width 0.7\textwidth
     #+CAPTION: Момент смены положения калиперов в поиске общих касательных
     [[./figures/CALIPERS_BRIDGE.png]]
  3. Поиск суммы Минковского двух объектов.
* 2 17: Сумма Минковского                                           :volhovm:
  Для решения проблемы планирования движения для неточечного объекта
  (скажем, выпуклого полигона) используется подход расширения
  препятствий. Более формально: пусть $A$ -- агент с выделенной точкой
  внутри, а $C$ -- препятствие. Пусть $A(x,y)$ -- это многоугольник,
  полученный параллельным переносом агента так, чтобы его центр
  находился в $(x,y)$. Тогда расширенное препятствие формализуется
  так: \[\{(x,y) : A(x, y) \cap C \neq \emptyset\}\]

  #+ATTR_LATEX: :options [Сумма Минковского]
  #+BEGIN_defn
  Сумма Минковского двух многоугольников $A$ и $B$ есть \[ A \oplus B
  \equiv \{p + q : p \in A, q \in B\} \], где сумма точек в привычном
  понимании покоординатна.
  #+END_defn

  #+BEGIN_lemma
  Пусть $A$ -- агент (выпуклый многоугольник), $P$ --
  препятствие. Тогда раздутое препятствие для $P$ есть $P \oplus
  (-A(0,0))$
  #+END_lemma
  #+BEGIN_proof
  Покажем, что $A(x,y) \cap P \neq \emptyset \Leftrightarrow (x, y)
  \in P \oplus (-A(0,0))$.

  Пусть $A(x,y) \cap P \neq \emptyset$, рассмотрим точку $q$ в
  пересечении. По определению пересечения, $q \in A(x,y)$, а значит
  $(q_x - x, q_y - y) \in A(0,0)$, что эквивалентно $(x - q_x, y -
  q_y) \in -A(0,0)$. Также из пересечения следует $q \in P$, а значит
  следствие вправо доказано.

  Обратно: пусть $(x, y) \in P \oplus (-A(0,0))$. Тогда существуют
  такие точки $(r_x, r_y) \in A(0,0)$, $(p_x, p_y) \in P$, что $(x,y)
  = (p_x - r_x, p_y - r_y)$. Тогда по определению есть пересечение.
  #+END_proof

  #+ATTR_LATEX: :options [Свойства суммы Минковского выпуклых многоугольников]
  #+BEGIN_thm
  Пусть $P$, $Q$ -- выпуклые полигоны, имеющие $n$ и $m$ ребер
  соответственно. Тогда многоугольник $P \oplus Q$ выпуклый и имеет
  максимум $n+m$ ребер.
  #+END_thm
  #+BEGIN_proof
  Выпуклость доказывается напрямую из определения. Для любого отрезка
  $seg \in P \oplus Q$, для каждой точки $s = (x,y)$, которая ему
  принадлежит, верно, что $s = p + q$, где $p \in P$, $q \in
  Q$. Найдем точки $p_1, q_1 : p_1 + q_1 = seg.start$, и $p_2, q_2 :
  p_2 + q_2 = seg.end$ (они найдутся по определению). Заметим, что
  сумма Минковского двух сегментов есть сегмент, а значит из того, что
  $[p_1,p_2] \in P$ и $[q_1, q_2] \in Q$ следует $[seg.start,seg.end]
  = seg \in P \oplus Q$.

  Для доказательства линейности суммы рассмотрим произвольное ребро $e
  \in P \oplus Q$. У него есть внешняя нормаль $\vect{n}$, и из
  выпуклости $P$ следует, что ребро $e$ экстремально в направлении
  $\vect{n}$. Значит, оно должно быть сгенерировано какими-то точками
  из $P$ и $Q$, которые тоже экстремальны в этом же направлении. Более
  того, как минимум один многоугольник из $P$, $Q$ должен иметь ребро
  $e'$, которое экстремально в этом направлении (потому что получить
  ребро нельзя из двух точек). Установим соответствие $e
  \Leftrightarrow e$, и такое соответствие для каждого ребра
  единственно в силу единственности нормали. Итого, имеем максимум
  $n+m$ ребер в сумме Минковского (ровно, если у двух многоугольников
  нету параллельных ребер).
  #+END_proof

  #+ATTR_LATEX: :options [Псевдодиск]
  #+BEGIN_defn
  Будем говорить, что пара планарных объектов (в частности полигонов)
  $(A, B)$ называется парой псевдодисков, если $A \ B$ связно и $B \
  A$ связно.
  #+END_defn

  #+ATTR_LATEX: :options [Набор псевдодисков]
  #+BEGIN_defn
  Будем называть набором псевдодисков такое множетсво планарных
  объектов $\{P_i\}$, что каждая пара элементов в нем является
  псевдодисками.
  #+END_defn

  К примеру, любые два прямоугольника со сторонами, параллельными
  осям, являются псевдодисками.

  #+BEGIN_note
  Границы двух псевдодисков могут пересекаться максимум в двух точках.
  #+END_note

  Немного расшарим также понятие экстремальности точки или ребра,
  перенеся его на многоугольник в общем.
  #+ATTR_LATEX: :option [Экстремальность многоугольника]
  #+BEGIN_defn
  Будем говорить, что многоугольник $A$ более экстремален, чем
  многоугольник $B$ в направлении $\vect{n}$, если для движущейся
  прямой, перпендикулярной $\vect{n}$, движущейся в направлении
  $\vect{n}$, последняя точка, которую она пересекает при движении,
  принадлежит $A$.

  Если в последний момент, когда прямая что-то пересекает, она
  пересекает оба многоугольника сразу, то будем говорить что в этом
  направлении экстремальность многоугольников равна.
  #+END_defn

  Поскольку экстремальность характеризуется вектором, то будем
  говорить, что $P$ более экстремален $Q$ в направлениях от
  $\vect{n_1}$ до $\vect{n_2}$, если это верно для любого направления от
  $angle(\vect{n_1})$ до $angle(\vect{n_2})$ (против часовой стрелки).

  #+BEGIN_note
  #+ATTR_LATEX: :width 0.8\textwidth
  #+CAPTION: Иллюстрация к замечанию о промежутках экстремальности полигонов
  [[./figures/MINKOWSKI_EXTREME.png]]

  Пусть $P_1$ и $P_2$ -- выпуклые многоугольники с непересекающимися
  внутренностями, причем $P$ более экстремален чем $Q$ в направлениях
  $\vect{n_1}$ и $\vect{n_2}$. Тогда $P$ экстремальнее $Q$ во всех
  направлениях либо от $\vect{n_1}$ до $\vect{n_2}$, либо от $\vect{n_2}$
  до $\vect{n_1}$.

  Другими словами, сектор угла, соответствующий экстремальности
  многоугольника, единственен и непрерывен.
  #+END_note

  #+BEGIN_thm
  Пусть $P$ и $Q$ -- два непересекающихся выпуклых многоугольника, а
  $A$ -- другой выпуклый полигон. Тогда суммы Минковского $P \oplus A$
  и $Q \oplus A$ являются псевдодисками.
  #+END_thm
  #+BEGIN_proof
  Обозначим $CP := P \oplus A$, $CQ := Q \oplus A$. Докажем из
  определения псевдодисков, что $CP \ CQ$ связно (достаточно только
  этого, из симметричности).

  #+ATTR_LATEX: :width 0.6\textwidth
  #+CAPTION: Первая пара не являются псевдодисками, вторая -- является
  [[./figures/MINKOWSKI_PSEUDODISCS.png]]

  По выше доказанной теореме $CP$ и $CQ$ -- выпуклые полигоны. Докажем
  от противного: пускай $CP \ CQ$ несвязно. Заметим, что для выпуклых
  многоугольников есть только один возможный вариант пересекаться и не
  быть псевдодисками -- это иметь 4 точки пересечения на границе
  (см. иллюстрацию).

  Заметим, что по выпуклости $CP$ должен иметь две точки на границе
  выпуклой оболочки $CP \cup CQ$. Также он должен иметь два
  направления $\vect{n_1}$, $\vect{n_2}$, в которых он более экстремален
  чем $CP$. По замечанию выше полигон не может иметь два разрывных
  промежутка экстремальности, значит компонента связности
  одна. Протворечие с предположением.
  #+END_proof

  #+ATTR_LATEX: :width 0.3\textwidth
  #+CAPTION: Иллюстрация к теореме об объединении набора псевдодисков
  [[./figures/MINKOWSKI_THM0.png]]

  #+BEGIN_thm
  Пусть $S$ -- набор псевдодисков, имеющий суммарно $n$ ребер. Тогда
  объединение элементов из $S$ имеет $O(n)$ ребер.
  #+END_thm

  #+BEGIN_proof
  Поскольку объединение полигонов -- полигон, то мы можем доказать
  теорему, используя стандартный метод амортизационного анализа:
  раздадим каждой вершине из набора по 2 монеты и покажем, что для
  каждой вершины объединения за нее кто-то заплатит. Таким образом мы
  ограничим количество вершин величиной $2n$.

  В объединии будет 2 вида вершин -- вершины, которые принадлежат
  границе какого-то псевдодиска и вершины, образованные пересечением
  двух псевдодисков.

  За каждую вершину первого типа заплатим одной монетой из нее самой
  же.

  Вторые вершины из объединения делятся на две категории. Рассмотрим
  точку $v$, являющуюся пересечением ребер $e_1 \in S_1$ и $e_2 \in
  S_2$. Ребро $e_1$ может пересечь псевдодиск $S_2$ либо единажды,
  либо два раза (в этом случае выйдет, что весь полигон $P_2$ проходит
  через это ребро и заканчивается внутри полигона $P_1$).

  В первом случае заплатим за вершину пересечения точкой ребра $e_1$,
  лежащей внутри $P_2$.

  Во втором случае есть вторая точка на границе $P_2$, в которой
  граница $P_2$ пересекается с $e_1$. Очевидно, что ребро $e_2$ имеет
  точку внутри $P_1$, иначе у нас полигоны пересекаются в 4х точках,
  что портит свойство псевдодиска. Тогда заплатим за пересечение $v$
  точкой на конце $e_2$, лежащей внутри $P_1$. Если так оказалось, что
  внутри $P_1$ лежит всего одна точка из $P_2$, то у нас на ней две
  монетки -- мы можем покрыть оплату обоих пересечений $e_1$ с $P_2$.
  #+END_proof

  Покажем два алгоритма для получения суммы Минковского двух
  полигонов.

  \begin{algorithm}[H]
  \KwData{Два выпуклых полигона $P$, $Q$}
  \KwResult{$P \oplus Q$}
  $points \gets$ new vector of points\;
  \For{$p_1 \gets P$}{
    \For{$p_2 \gets P$}{
      $points.insert(p_1 + p_2)$\;
    }
  }
  return $ConvexHull(points)$\;
  \caption{Наивный алгоритм нахождения суммы Минковского двух многоугольников}
  \end{algorithm}

  \begin{algorithm}[H]
  \KwData{Выпуклый полигон $P$ с точками $p_1$,...,$p_n$ \\
          выпуклый полигон $Q$ с точками $q_1$,...,$q_m$ }
  \KwResult{$P \oplus Q$}
  $i \gets 1; j \gets 1$\;
  $p_{n+1} \gets p_1$\;
  $q_{m+1} \gets q_1$\;
  \Repeat{$i = n+1$ and $j = m+1$}{
    Добавить $p_i + q_j$ в сумму $P \oplus Q$\;
    $bool_1 \gets angle(p_ip_{i+1}) < angle(q_jq_{j+1})$\;
    $bool_2 \gets angle(p_ip_{i+1}) > angle(q_jq_{j+1})$\;
    \If{$\neg bool_1$ and $\neg bool_2$}{
      $i++; j++$\;
    }
    \If{$bool_1$ and $\neg bool_2$}{
      $i++$\;
    }
    \If{$\neg bool_1$ and $bool_2$}{
      $j++$\;
    }
  }
  \caption{Поиск суммы Минковского методом вращающихся калиперов}
  \end{algorithm}

  Первый алгоритм работает достаточно плохо на больших множествах
  (нужно перебирать все пары точек), а второй за линейное время, так
  как используется метод калиперов.

  #+BEGIN_thm
  Сумма Минковского двух выпуклых тел с $n$ и $m$ вершинами
  соответственно, считается за $O(n+m)$ времени.
  #+END_thm
  #+BEGIN_proof
  Алгоритм подсчета калиперами представлен выше.
  #+END_proof

  #+BEGIN_thm
  Пусть $P$ -- невыпуклый многоугольник с $n$ вершинами, а $Q$ --
  выпуклый с $m$. Тогда количество вершин в $P \oplus Q$ есть $O(nm)$.
  #+END_thm
  #+BEGIN_proof
  Заметим, что следующее равенство верно: \[ S_1 \oplus (S_2 \cup S_3)
  = (S_1 \oplus S_2) \cup (S_1 \oplus S_3) \]

  Возьмем триангуляцию $P$, для каждого $P_i$ посчитаем его сумму и
  объединим. Более формально: \[ P \oplus Q = \bigcup_{i=1}^{n-2}{P_i
  \oplus Q} \]

  Исходя из оценки сложности суммы двух выпуклых полигонов, каждое
  объединение $P_i \oplus Q$ будет иметь максимум $m + 3$
  ребер. Поскольку треугольники триангуляции не пересекаются, то ${P_i
  \oplus Q}$ есть набор псевдодисков. Объединение псевдодисков линейно
  по вершинам/ребрам, значит общая сложность $P \oplus Q$ есть
  $O(nm)$.
  #+END_proof

  #+BEGIN_thm
  Пусть $P$ и Q$ -- невыпуклые многоугольники с $n$ и $m$ вершинами
  соответственно. Тогда сложность $P \oplus Q$ есть $O(n^2m^2)$.
  #+END_thm
  #+BEGIN_proof
  Найдем триангуляции данных многоугольников $\{P_i\}$ и $\{Q_i\}$.
  Сложность каждого объединения $P_j \cup Q_i$ константна, а значит $P
  \oplus Q$ есть объединение $(n-2)(m-2)$ многоугольников константной
  сложности (каждой пары). Отсюда следует, что сложность объединения
  есть $O(n^2m^2)$ (обычная оценка, нет свойства псевдодисков).
  #+END_proof
* 2 18: Вероятностный алгоритм мин. охва. окружности множества точек
  Рассмотрим задачу: у нас есть множество $P = \{p_1, ..., p_n\}$
  точек на плоскости. Нужно построить окружность такую, чтобы все
  точки из $P$ лежали бы внутри нее или на границе, причем из таких
  окружностей надо выбрать минимальную.

  *Идея*: строим окружность итеративно, рассматривая точки по одной. В
  этом нам очень поможет следующая лемма.

  #+ATTR_LATEX: :options [О добавлении точки в минимальную окружность]
  #+BEGIN_lemma
  Определим $P_i = \{p_1, ..., p_i\}$, а $D_i$ -
  мин. охват. окружность для $P_i$. Рассмотрим точку $p_i$. Верно
  следующее:
  1) Если $p_i \in D_{i-1}$, то $D_i = D_{i-1}$
  2) Иначе $p_i$ лежит на границе $D_i$
  #+END_lemma

  #+BEGIN_proof
  Докажем эту лемму, как следствие следующей (по сути, следующая --
  это переформулировка этой)
  #+END_proof

  #+ATTR_LATEX: :options [О точках, лежащих внутри и на границе]
  #+BEGIN_lemma
  Пусть $P$ -- множество точек на плоскости, $R$ -- тоже (возможно,
  пустое) Обозначим как $md(P, R)$ наименьшую окружность, охватывающую
  $P$ и имеющую все точки $R$ на границе.  Пусть $p \in P$. Тогда:
  1) Если $md(P, R)$ существует, то он единственен.
  2) Если $p \in md(P \setminus \{p\}, R)$, то $md(P, R) = md(P
     \setminus \{p\}, R)$
  3) Если $p \notin md(P \setminus \{p\}, R)$, то $md(P, R) = md(P
     \setminus \{p\}, R \cup \{p\})$
  #+END_lemma

  #+BEGIN_proof
  1) Если $|R| > 2$, то это очевидно невозможно -- потому что по 3
     точкам окружность строится единственным образом. Пусть тогда $|R|
     > 2$ и существуют 2 минимальные окружности $D_0$ и $D_1$ с
     радиусом $r$ и центрами $x_0$ и $x_1$ соответственно.

     Тогда $P \subset D_0 \cap D_1$, $q_0$ и $q_1$ -- точки
     пересечения $D_0$ и $D_1$, и $R \subset \{q_0, q_1\}$.  Но если
     мы построим окружность с центром точно посередине $q_0$ и $q_1$,
     она будет включать в себя $D_0 \cap D_1$ и на ее границе будет
     лежать $R$ И по построению ее радиус будет меньше, чем
     $r$. Значит, $D_0$ и $D_1$ не являются минимальными охватывающими
     окружностями.
  2) Очевидно.
  3) Обозначим $D_0 = md(P \setminus \{p\}, R)$ и $D_1 = md(P,
     R)$. Это две окружности, очевидно, гомотопически эквивалентны.
     Обозначим их центры и радиусы как $x_0$, $r_0$, $x_1$ и $r_1$
     соответственно.

     Построим между ними кратчайшую гомотопию следующим образом:
     \begin{align*}
     D(\lambda) &= \{x(\lambda), r(\lambda)\}\\
     x(\lambda) &= (1 - \lambda)x_0 + \lambda x_1\\
     r(\lambda) &= \|z - x(\lambda)\|
     \end{align*}
     Тут $z$ -- одна из точек пересечения $D_0$ с $D_1$.

     Замечание: точки пересечения всегда есть, когда $R$ непусто, а
     если оно пусто, то они должны быть из соображений минимальности.

     Очевидно, что $\forall \lambda \in [0, 1] : P \subset D(\lambda),
     R \subset \partial D(\lambda)$, ведь это верно для пересечения
     $D_0$ и $D_1$, которое по построению в себя включает каждая из
     $D(\lambda)$. Тогда существует некая $\lambda*$, $0 < \lambda*
     \leqslant 1$, такая, что $p \in \partial D(\lambda)$ Но по
     построению $r(\lambda) \leqslant r_1$, и если $\lambda* < 1$, то
     $D_1$ не является $md(P, R)$, так как ей является
     $D(\lambda)$. Противоречие! Значит, $\lambda* = 1$, из чего
     следует, что $p \in \partial D_1$, что и требовалось доказать.
  #+END_proof

  \begin{algorithm}[H]
  \SetKwFunction{makeA}{make0}%
  \SetKwFunction{makeB}{make1}%
  \SetKwFunction{makeC}{make2}%
  \func{\makeA{$n$}}{
    \KwResult{Возвращает минимальную охватывающую окружность множстева точек}
    $D_2 \gets $ окружность на диаметре между точками $p_1$ и $p_2$\;
    Перебираем точки с $p_3$ по $p_n$\;
    \eIf{$p_i \in D_{i-1}$}{
      $D_i = D_{i-1}$\;
    }{
      $D_i = make1(i, p_i)$\;
    }
  }
  \func{\makeB{$k$, $p$}}{
    \KwResult{$md(\{p_1, ..., p_k\}, \{p\})$}
    $D_1 \gets $ окружность на диаметре между точками $p_1$ и $p$\;
    Перебираем точки с $p_2$ по $p_k$\;
    \eIf{$p_i \in D_{i-1}$}{
      $D_i = D_{i-1}$\;
    }{
      $D_i = make2(i, p, p_i)$\;
    }
  }
  \func{\makeC{$k$, $p$, $q$}}{
    \KwResult{$md(\{p_1, ..., p_k\}, \{p, q\})$}
    $D_0 \gets $ окружность на диаметре между точками $p$ и $q$\;
    Перебираем точки с $p_1$ по $p_k$\;
    \eIf{$p_i \in D_{i-1}$}{
      $D_i = D_{i-1}$\;
    }{
      $D_i$ строится единственным образом по трем точкам -- $p$, $q$ и $p_i$\;
    }
  }
  \caption{Алгоритм поиска минимальной охватывающей окружности}
  \end{algorithm}

  *Корректность*

  Доказанная лемма гарантирует, что окружность, которая ищется при
  вызове $make1$ и $make2$, всегда существует. Кроме того, она
  показывает, что построенная на каждом шаге $make0$ окружность
  является корректной. Значит, и весь алгоритмм корректен.

  *Асимптотика*

  $make2(n, p, q)$ всегда работает за $O(n)$.

  $make0(n)$ и $make1(n, p)$ работают тоже за $O(n)$, если не
  учитывать вызовы нижележащих функций. Но их нужно учитывать! Из
  этого можно заключить, что верхней оценкой на время выполнения
  является $O(n^3)$. На практике же (на случайных точках) алгоритм
  работает существенно быстрее.

  Разберемся, почему. Для этого рассмотрим работу алгоритма "задом
  наперед". Сначала рассмотрим функцию $make1(n, p)$

  Пусть у нас есть результирующая окружность. Начнем удалять из
  множества точки в обратном порядке и сжимать окружность, когда это
  возможно.

  Вероятность того, что на каком-то шаге окружность сожмется, равна
  вероятности того, что на этом шаге при обычном исполнении будет
  вызвана $make2(i, p, p_i)$. Какова эта вероятность? Окружность может
  "опираться" на 2, 3 или более точек, одна из которых всегда $q$
  (которую мы удалить не можем) В первом случае удаление только 1
  точки может спровоцировать сжатие окружности, во втором - одной из
  2, в третьем - окружность не сожмется в любом случае. Итого, на
  каждом шаге есть не более 2 точек, удаление одной из которых
  приведет к вызову $make2$. Вероятность удаления одной из этих
  точек - $\frac{2}{i}$.

  Итого, ожидаемое время работы функции $make1(n, p)$:

  $O(n) + \sum\limits_{i=2}^n {O(i) \frac{2}{i}} = O(n)$

  Применив аналогичные рассуждения, докажем линейное ожидаемое время
  работы для функции $make0$.
* 2 19: Граф видимости и планирование движения                      :volhovm:
  Задача поставлена следующим образом: есть объект, точечный или нет,
  нужно провести его через полигональные препятствия (все в
  $\R^2$). Известность карты -- тоже входной параметр.

  #+CAPTION: Иллюстрации к теме про Motion Planning
  [[./figures/MOT_PL.jpg]]
** 2 Точечный объект
   Решим задачу для точечных объектов. Пусть у нас есть поле, точки $A$
   и $B$. Нужно попасть из первой во вторую, оптимально.
*** 2 Граф видимости
    Первая тривиальная идея, которая приходит в голову -- это построить
    граф, в котором узлы -- это вершины полигонов, составляющих карту,
    а ребра между двумя вершинами $u$, $v$ строим в том случае, если
    $uv$ не пересекается ни с одним полигоном из данных. Такой граф
    называется картой видимости. Можно его обойти дейкстрой. Получаем
    $O(n^2)$ и памяти и времени на запрос (если использовать дейкстру
    без кучи). Предподсчет будет занимать втупую $O(n^3)$, то есть для
    каждой пары точек проверить пересечение со всеми отрезками
    полигонов (их $n$ штук).

    Подумаем, что с этим можно сделать:
    * Не хранить ребра, а создавать их только когда мы пришли в вершину.
    * Оптимальный путь -- ломаная (доказательство от противного, пусть
      есть какая-то кривая, огибающая препятствие, тогда спрямим ее,
      получим прямую меньшей длины) -- см. ~MOT_PL_1~. Более того,
      кратчайший путь между двумя точками в поле с полигональными
      препятствиями содержит только начало, старт и точки полигонов в
      качестве своих точек.
    * Если рассмотреть вершину полигона $P$, то путь из двух ребер
      (входящее в нее $aP$ и исходящее $Pb$) неоптимален, если угол
      $aPb < 180°$. См. ~MOT_PL_2~. Доказательство простое --
      рассмотрим такой угол. Тогда возьмем две любые точки $c \in aP$, $d
      \in Pb$ (можно взять их как точки пересечения окружности с центром
      в $P$ с прямыми $aP$ и $Pb$, при этом окружность взять радиуса
      меньше чем каждый из отрезков), получим по неравенству
      треугольника что путь $acdb$ короче чем $aPb$. Такие ребра в
      общем можно не добавлять. Алсо такая оптимизация не понижает
      асимптотику, а только уменьшает константу.
    * Препроцессинг можно уменьшить с $O(n^3)$ до $O(n^{?}\log{n})$ с
      помощью алгоритма Бентли-Оттмана (заметающая прямая). Мы будем
      использовать следующую модификацию (см. ~MOT_PL_3~):

      Для очередной точки $P$ найдем, какие отрезки из нее исходят
      вправо (предполагаем, что все отрезки влево уже были добавлены на
      предыдущем шаге). Для этого рассмотрим все ребра, которые
      пересекают прямые, начиная от $P$ и вниз и вправо против часовой
      стрелки вверх на $180°$. Типа рассмотрели зону видимости
      "вправо". Формально мы все отрезки, которые заканчиваются правее
      нашей точки берем, раскладываем на события (стандартные Б-О
      ивенты типа начало отрезка, пересечение, конец отрезка) и сортим
      по углу поворота относительно $P$. Дальше перебираем их всех
      против часовой стрелки и храним стейт всех отрезков, которые
      пересекает наша прямая. Первый отрезок в стейте будет отрезком,
      который "виден" из $P$ -- будем по ходу дела добавлять концы
      видимых отрезков в ответ.

      Сам Б-О работает за $O((n+k)\log{n})$, где $n$ -- количество
      отрезков, а $k$ -- количество пересечений.  Таким образом для всех
      точек оцениваем сверху препроцессинг до $O(n^2\log{n})$.
    * Препроцессинг на самом деле уменьшается до $O(n^2)$, но это
      древняя магия (есть какие-то статьи).
    * Динамически отвечать на запросы, чтобы снизить память. Я так
      понимаю, это когда мы минимум выбираем (за $O(n)$), то ищем
      вершины, потом релаксируем, храним предка чтобы знать путь. Вот
      короче динамически так будем строить граф.
    * Есть много других интересных подходов, в том числе алгоритм
      Митчелла, который снижает память до $O(n\log{n})$, причем на
      запрос времени $O(n + \log^2{n})$, где логарифм от локализации в
      планарном графе. Общая идея там похожа на принцип
      Гюйгенса-Френеля, если я все правильно понимаю: мы запускаем из
      очередной точки сферические волны и смотрим на те точки
      плоскости, где в $\alpha-\varepsilon$ волна остановилась, а в
      $\alpha+\varepsilon$ она идет, типа границы видимости. И запускаемся
      дальше от таких (бесполезное знание)
*** 2 Сомнительной полезности квант знания
    Есть также похожая задача, суть которой состоит в разбиении
    плоскости на зоны возможной скорости объекта. Там закон Снеллиуса
    о преломлении и решение работает за $O(n^8\log{n})$.
*** 1 Приближенное решение с помощью триангуляции
    Можно попробовать сократить память до $O(n)$, триангулировав
    множество вершин полигонов с учетом видимости. Потом рассмотрим
    двоственный триангуляции граф (взяв в качестве точек центры
    треугольников).
    * Путь получается достаточно плохой, необходимо сгладить ребра:
      * Жадным способом их позаменять.
      * На используемых вершинах подобавлять, типа уточнить путь на графе.
      * Подразбивать ребра, добавить вершины и провести их них еще
        какие-нибудь другие ребра.
    * Мы умеем бросать из точки отрезок и смотреть что он пересекает
      (препятствие или нет). Количество пересеченных треугольников
      будет $O(\sqrt{n})$.
    * Добавляем еще сетку и дополнительно триангулируем по ней, это
      уменьшает длины ребер треугольников (это хорошо почему-то)
    * Зная среднюю и максимальную длину ребра, можем кидать отрезки,
      кратные ей и таким образом ограничивать количество
      просматриваемых треугольников.
*** 2 Трапецоидная карта, наивное решение
    Воспользуемся трапецоидной картой для решения этой
    задачи.

    Построим сначала обычную трапецоидную карту для набора точек $S$,
    которые формируют полигоны, а затем удалим те трапецоиды, которые
    лежат внутри полигонов (можно пройтись по DCEL'у, полагаю, и
    удалить). Для каждого трапецоида из результата добавим в набор
    точек пути его центр и для каждого соседнего левого или правого
    трапецоида добавим точку на середине вертикального ребра, которое
    их соединяет (~MOT_PL_4~, × -- середина трапецоида, \cdot --
    середина соединяющего соседние трапецоиды ребра). Для каждого
    трапецоида соединим его середину с серединами соседних
    ребер. Назовем получившийся граф дорожной картой.

    Как реализовывать запросы с трапецоидной картой? Пусть имеются
    точки $A$, $B$:
    1. Принадлежат одному трапецоиду -- проведем прямую между точками.
    2. Иначе определим трапецоиды $\Delta_{A}$, $\Delta_{B}$,
       содержащие точки $A$ и $B$ соответственно, пойдем от $A$ к
       центру $\Delta_{A}$, потом по дорожной карте дойдем до центра
       $\Delta{B}$, а дальше проведем прямую от центра к $B$.

    Корректность пути относительно предиката "нет столкновений"
    очевидна -- для путей внутри трапецоидов это верно по построению,
    для каждого элемента дорожной карты тоже.

    Оценка времени такова: поиск трапецоидов, в которых содержатся $A$
    и $B$ занимает $O(\log{n})$ с помощью структуры точечной
    локализации, но можно проверить и за $O(n)$, так как весь алгоритм
    работает за $O(n)$. Будем находить путь между трапецоидами поиском
    в глубину, что займет $O(n)$ шагов, так как в графе и число
    трапецоидов (а значит и их центров) линейно, и число соединений
    между двумя трапецоидами линейно (следует из планарности). Итого
    $O(n\log{n})$ на препроцессинг, $O(n)$ на запрос и мы не можем
    гарантировать оптимальность. Чтобы это сделать, нам необходимы
    более сложные структуры данных.
*** 2 Слепой жук: точечный объект, нет знания карты
    Задача сформулирована так же, как предыдущие, но в этом случае у
    нас нету возможности заранее что-либо предподсчитать.

    Рассмотрим наивное *нерабочее* решение: ~BUG_FAIL~. Пусть наш жук
    будет обходить препятствие до первого поворота, а дальше
    направляться в сторону конца. Контпример изображен на
    (~MOT_PL_BUG_FAIL~): в этом случае мы зациклимся и не достигнем
    финиша.

    Рассмотрим два несложных решения.
    * ~BUG0~: Зафиксируем прямую из начальной в конечную точку
      $l$. Будем придерживаться этой прямой. При встрече с препятсвием
      фиксируем положение обходим его в одну фиксированную сторону до
      тех пор, пока не окажемся снова на этой линии (~MOT_PL_BUG_0~).
    * ~BUG1~: Пусть зафиксирована прямая движения $l_1$. Будем следовать
      ей, а при встрече с препятствием обойдем и отметим ситуацию,
      когда мы находимся ближе всего к точке $B$. В этот момент
      сформируем прямую $l_2 = pB$, где $p$ -- текущее положение
      жука, и пойдем по l_2 дальше, следуя алгоритму (~MOT_PL_BUG_1~).

    В некоторых случаях ~BUG1~ значительно лучше ~BUG0~: представим
    себе спираль, в центре которой финиш. Начав вне спирали с
    алгоритмом ~BUG1~ мы после первого шага будем идти внутрь спирали,
    уменьшая расстояние до финиша. С ~BUG0~ алгоритм будет часто
    делать лишние шаги по спирали и покажет себя значительно хуже.

    Вот еще забавный алгоритм: ~CBUG~. Выбираем любой алгоритм из
    предыдущих двух и дополняем его таким образом: на старте и на
    финише строим эллипс как на центрах. Добавляем его в список
    преград, то есть. При первом столкновении с какой-либо
    поверхностью запоминаем точку. Может произойти так, что мы
    пройдемся по ограничивающему эллипсу и вернемся назад. Если такое
    произошло, увеличим эллипс в два раза.

    Есть еще уйма классных алго для роботов. К примеру, есть
    модификация для робота со зрением. Это примерно аналогично роботу
    без зрения, только "прощупывание" стены визуальное.
** 1 Неточечный объект
   Для неточечног объекта чаще всего задача сводится к какому-то
   расширению препятствий и сведению к предыдущей задаче с точечным
   объектом.

   В общем случае задача делится на две по критерию "можно ли
   поворачивать объект". Для круга этот вопрос не имеет смысла,
   поэтому он вынесен в отдельную подзадачу.

*** X Задача для круга
    Эта задача делится на две:

    Пусть полигоны выпуклые. Расширим прямые полигонов вовне на
    радиус круга. Свяжем расширенные прямые в узлах разрыва каким-то
    приближением кругов (выставим некоторое количество точек, образовав
    вписанный многоугольник). См. ~MOT_PL_5~. Потом, если не будем
    пользоваться графом видимости, новые полигоны объединим. Если же
    решение с трапец. картой или триангуляцией, то это нужно сделать,
    чтобы не связывать лишние вершины.

    Если полигоны невыпуклые -- тоже хотим расширить, но возникают
    проблемы с самопересечнием (~MOT_PL_6~ -- у нас внутри полигона
    может поместиться круг, хотя туда нельзя его провести извне). Есть
    два варианта -- не учитывать буферную зону пересечения
    (более-менее просто) или строить честный straight-skeleton (уже
    нетривиально, хотя и были лекции, но нет в программе экзамена).
    Утверждается, что первое решается за $O(n^2)$ с помощью priority
    queue, на уровне "добавляем события и аккуратно смотрим за
    пересечениями". Надо еще подумать *!!!*.
*** 2 Задача для полигона без вращения
    Пусть мы проводим через поле невращающийся полигональный выпуклый
    объект. Выберем некоторую точку в полигоне и будем думать в
    сторону построения суммы Минковского полигонов поля относительно
    нашего агента с зафиксированной точкой.

    На этом этапе предполагается, что все рассуждения о том, как нужно
    строить сумму Минковского, относятся к соответствующей теме,
    поэтому просто выпишем некоторые тезисы:

    Для выпуклого многоугольника с $n$ точками построение суммы
    минковского с агентом из $m$ точек занимает $O(nm)$, а если
    пользоваться методом калиперов, то $O(n+m)$.

    Для невыпуклых многоугольников их можно разбить на выпуклые
    (триангулировать), для каждого построить сумму Минковского, а
    затем их объединить.

    Асимптотика объединения невыпуклого полигона с выпуклым $O(nm)$,
    невыпуклого в невыпуклым $O(n^2m^2)$. На триангуляцию
    многоугольника с $m$ вершинами уходит $O(m\log{m})$ сложности
    (можно и за $O(m)$ с очень сложным алгоритмом). Тогда для всех
    многоугольников это можно сделать за $n\log{n}$ (тут надо раскрыть
    сумму).

    Асимптотика мерджа расширенных суммой Минковского агентов с
    треугольниками триангуляции составляет $O(n\log^2{n})$: выбирать
    какие треугольники мерджитьможно с помощью divide-and-conquer (это
    $O(\log{n})$ операций, а один шаг мерджа занимает $O(n\log{n})$ по
    линейности количества треугольников.

    Запрос будет реализовываться все так же за $O(n)$.
*** 2 Задача для полигона с вращенем
    Хорошая практика в этом вопросе решать его неточно (точные решения
    занимают $O(n^4)$ памяти. Определим некоторый дискретный набор
    углов, на которые мы будем поворачивать нашего агента. Построим
    много карт для разных углов.

    Имея некоторое количество карт, хочется понять, как
    локализовываться в них. Для локализации хочется получить какую-то
    общую структуру. Хорошее предложение -- для каждой карты
    нарисовать трапецоидную карту и как-то слинковать каждые соседние
    слои. Делать мы это будем просто: для каждых двух соседних карт
    будем смотреть их пересечение. Для двух пересекающихся трапецоидов
    из разных уровней добавляем в граф еще одну вершину как центр
    пересечения трапецоидов и соединяем ее с центрами двух
    пересекаемых трапецоидов. Так прошивая каждые два соседние слоя мы
    получим карту, в которой можно будет локализовываться, как и
    раньше.

    Памяти всего будет $O(n+m)$ на слой если все выпуклое и
    $O(n^2m^2)$, если невыпуклое. Суммарно еще умножить на количество
    слоев по дискретизации угла, которых обычно берут $O(n^2)$.

    Поправка: такой алгоритм не всегда верен, как можно
    догадаться. Можно увеличить количество углов поворота, но и это не
    будет гарантировать корректность. Чтобы превратить все true
    negative в false positive, мы можем считать карту для слоя для
    модифицированного робота: зафиксируем у него точку, повернем его
    на ~+angle~ и ~-angle~, возьмем выпуклую оболочку получившегося
    робота вместо него самого.
* 0 20: Триангуляция Делоне                                         :volhovm:
* 0 21: Доказательство (алгоритм + корректность)                    :volhovm:
* 2 22: Диаграмма Вороного                                          :volhovm:
  [[http://neerc.ifmo.ru/wiki/index.php?title=Диаграмма_Вороного][Статья на викиконспектах]]
** Алгоритм и асимптотика
   Антону больше нравится инкрементальный алгоритм построения диаграммы
   Вороного, так как он похож на Делоне.

   Типа вот есть бакеты, мы там чето меняем, проводим $O(1)$ времени на
   каждом уровне, суммарно получается $O(n)$.

   У нас есть $O(log(n))$ уровней, где есть какие-то сабсеты, для
   каждого мы можем построить за $O(1)$ новую диаграмму.

   Как локализоваться в диаграмме Вороного, где точек $O(1)$? Тупо
   найти ближайшую точку, посчитав метрику.

   ~VOR_0~
   Как с помощью $n+1$ уровня найти ближайшую точку на $n$-м уровне?
   $X$ --- ближайшая точка на $n+1$ уровне. $A$ --- точка, которую мы хотим
   вернуть, то есть ближайшая к $q$ на $n$-м уровне. Проведем отрезок $XA$ и
   проверим все соседние грани точки $X$, выберем ту, которую пересекает
   $XA$. $XA$ также может пересекать какую-то точку триангуляции. Тогда
   нужно перебрать все соседние прямые, исходящие из этой точки и
   выбрать такие две, между которыми проходит $XA$.

   Как достроить диаграмму Вороного, если мы уже локализовались?
   Построим между q и A серединный перпендикуляр, пересечь его с фейсом
   вершины A. Будем дальше идти по соседним DCEL'ам и заворачивать,
   строя серединные перпендикуляры, прямые вокруг $q$. Таким образом,
   построим грань для вершины q.

   Асимптотика (inb4 можно это делать, строя двойственную триангуляцию):
   * Вставка: посчитаем среднюю степень, проведем регрессионный анализ,
     как в алгоритме Делоне.
   * Локализация: пересечем $O(1)$ ребер. Это доказательство тоже
     копируется с Делоне. Можно сказать, что мы пройдем по количеству
     DCEL'ов которые не добавились на более высокий уровень. Поскольку
     слои диаграммы --- это множество Бернулли, то на каждом шаге мы
     добавим не больше чем сколько-то точек, а они экспоненциально
     убывают.
** Удаление из диаграммы Вороного
   ~VOR_2~

   Возьмем сайт, его фейс. Будем строить типа straight skeleton,
   двигая стороны внутрь по серединным перепендикулярам. Тогда в
   какой-то момент схлопнется.
** Построение из триангуляции диаграмму
   ~VOR_1~

   Как построить из триангуляции Делоне диаграмму Вороного?  Возьмем
   диаграмму, выделим какую-то точку $A$. Построим серединные
   перпендикуляры для каждого ребра, исходяшего из $A$, пересечем их
   всех. Поймем, что получившееся пересечение сер. перпендикуляров
   образует ячейку Вороного.

   Покажем, что такая ячейка конечна. Рассмотрим треугольник $ABC$. По
   определению, этот треугольник --- треугольник Делоне, поэтому точка
   пересечение серединных перпендикуляров лежит внутри, и расстояние
   от $S$ до точек прямоугольника минимально, если точка есть
   пересечение серединных перпендикуляров. Более того, по свойству
   Делоне, в окружности не лежит никаких других точек.

   Любой отрезок ячейки Вороного принадлежит ей, потому что ячейки
   диаграммы Вороного выпуклые. Отсюда, поскольку точки отрезка лежат в
   ячейке, отрезок тоже лежит. Типа сама точка A лежит ближе всего к
   себе. Точка пересечения сер. перпендикуляров тоже лежит в ячейке,
   тогда для каждых двух соседних точек прямая между ними тоже лежит,
   т.к. ячейка вороного --- выпуклый многугольник.
** Построение из диаграммы триангуляции
   Возьмем диаграмму Вороного и построим *разбиение* Делоне --- то есть
   могут получиться не треугольники. В этом случае можно показать, что
   любой такой многоугольник можно триангулировать любым образом, при
   этом свойство Делоне останется.

   Почему в общем случае граф, в котором мы соединили сайты соседних
   граней, получится разбиением Делоне? Ну типа, возьмем в DCEL'е
   узел, который соединяет три грани. Берем их сайты, соединяем. Это
   получится треугольник. Прогоним обратное следствие в нужную
   сторону.
** Высшие порядки
   Диаграмма Вороного второго порядка $VD^2$ это: $P_1, P_2 \in
   V_{q_1q_2} \Leftrightarrow d(p_1, q_1) = min_1, d(p_1,q_2) = min_2$.

   Аналогично строим $VD^k$ --- диаграмму Вороного $k$-го порядка.

   Диаграмма Вороного $n-1$-го порядка --- это набор таких сайтов, что
   для каждого есть $n-1$ точка, и для всех точек от них есть какая-то
   одна самая далекая.

   Как строить инеркментально? Нужно проводить алгоритм удаления
   точек, но не удаляя прямые, которые мы двигаем, до самого конца.

   Для каждого фейса мы делаем это за: $klogk$, но \[\sum{k\log{k}}
   \le \sum{k\log{n}} = \log{n}\sum{k} = O(n\log{n})\]

   Сколько будет вершин в диаграмме вороного второго порядка? Столько
   же, сколько и ребер, вернее удвоенное количество.

   *ЧИТАТЬ НА ВИКИ*
** Диаграмма минус первого порядка
   Граф Делоне двойственный диаграмме $-1$ порядка --- это верхняя крышка
   проекции диаграммы на параболоид.

   Типа возьмем треугольник, тогда в окружности должны находиться все
   точки множества. Количество вершин в такой диаграмме Вороного ---
   это количество вершин выпуклой оболочки.
* Бонусные задачи и нетронутые темы
** Из множества прямых произвольных восстановить DCEL
   Можно делать инкрементально. Для трех понятно, как строить. Дальше
   кидаем прямую. Берем первое пересечение, локализуем точку на прямой
   за $O(n)$, дальше обходим соседние фейсы DCEL'а пока не найдем
   точку пересечения нашей прямой с какой-то другой. И так пока все не
   пересечем. Можно показать, что асимптотика будет норм -- $O(n^2)$.

   Рассмотрим ~BON-0~. $l$ -- наша прямая. Утверждается, что от
   пересечения нашей прямой с какой-то другой до следующего
   пересечения нужно пробежать не более чем $O(n)$ ребер.

   В среднем заметим, что у нас $O(n^2)$ ребер и $O(n^2)$ фейсов. Тем не
   менее, из этого не следует, что на каждый фейс приходится $O(1)$
   ребер, может быть так, что какие-то фейсы жирные, а какие-то нет.

   Мы всегда знаем направление, в котором мы будем двигаться от
   точки.

   Рассмотрим все Покрасим точки с положительным наклоном
   относительно прямой синим цветом, а серым -- с
   отрицательным. Будем считать только те ребра, которые лежат в
   DCEL'ах, которые пересекает наша прямая $l$.

   Посчитаем, сколько таких цветных ребер есть (кстати, синих и серых
   ребер будет одинаковое количество).

   Прямая l прйдет через O(n) ребер. Выкинем самую правую прямую,
   которая имеет синий отрезок. Тут типа индукция. Тогда есть
   $\exists{c}$, что прямая пересекает не более $c*(n-1)$. Попробуем ее
   заново добавить. Пусть прямая имеет серый наклон вправо. Тогда
   такая прямая подразобьет не более чем $O(1)$ ребер.
** Поиск касательной точки и многоугольника
   Тут Славик рассказал способ найти касательную точки и
   многоугольника с помощью подразбиения многоугольника на
   подмногоугольники (каждый вложенный берет точки предыдущего через
   одну). Потом он типа ищет для самого вложенного треугольника
   касательную, а потом передвигается к более богатым многоугольникам,
   сдвигая касательную влево или вправо на одну вершину. Тоже алгоритм
   за log(n). Типа на каждом шаге есть step, мы рассматриваем текущего
   кандидата на касательную + step и -step. Выбираем лучшего,
   переходим к нему и делим шаг на два.
** Масшатбирование дорог
   #+CAPTION: Пример решения задачи о масштабировании дороги
   [[./figures/ROAD_SCALING.png]]

   Задача поставлена так: существует некоторый масштаб карты, в
   условиях которого выражена дорога, представляющая собой
   полилинию. Требуется выразить эту дорогу в более мелком масштабе,
   то есть так сократить количество точек, чтобы новая полилиния в
   некотором смысле была похожа на старую. Сглаженность определяется
   рациональным числом \varepsilon: необходимо, чтобы новая прямая не
   выходила из \varepsilon-коридора старой прямой. Пример показан на
   изображении, в нашем случае красная прямая -- решение.

   Предлагается два решения этой задачи:
   1. Будем использовать сумму Минковского и уже разобранные алгоритмы
      планирования движения. С помощью суммы расширим прямую
      правильным многоугольником, выбрав радиус описанной окружности
      соответствующий нужному масштабу, а затем решим задачу об
      оптимальном прохождении роботом коридора, который и представляет
      собой расширение. Напомним, что в этом случае при использовании,
      например, графа видимости, асимптотика решения составит
      $O(n^2\log{n})$ на препроцессинг и $O(n)$ на решение.
   2. Применим стандартную тактику "разделяй и властвуй" и решим
      задачу за амортизированное $O(n\log{n})$ ($O(n^2)$ в худшем
      случае, алгоритм Дугласа-Пекера):

      \begin{algorithm}[H]
      \SetKwFunction{DougPeuck}{Douglas-Peucker}%
      \func{\DougPeuck{points, $\varepsilon$}}{
        \KwData{Набор точек, задающих полилинию $\{p_i\}$\\
                Коэффициент расширения $\varepsilon$}
        \KwResult{Набор точек, задающих решение (полилинию)}
        $range \gets [1, n]$\;
        \While{$range.length > 0$}{
          $segment \gets \langle points[range.start],
                                 points[range.end]
                         \rangle$\;
          $p_{max} \gets min(points[range.start],
            points[range.end],$ компаратор по дистанции до $seg)$\;
          \eIf{$dist(p_{max}, segment) < \varepsilon$}{
            return $(segment.start, segment.end)$\;
          }{
            $p_1 \gets $Douglas-Peucker$(points[0..p_{max}], \varepsilon)$\;
            $p_2 \gets $Douglas-Peucker$(points[p_{max}..n], \varepsilon)$\;
            return $union(p_1, p_2)$\;
          }
        }
      }
      \caption{Алгоритм Дугласа-Пекера для масштабирования полилинии}
      \end{algorithm}
