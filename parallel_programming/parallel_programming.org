# -*- org-src-fontify-natively t -*-
#+TITLE: Конспект по ПП/Распределенные системы от Елизарова (3 курс)

* Параллельное программирование
** Какие-то материалы:
   * https://www.slideshare.net/secret/6dv9wtl1pDOTgu
   * https://www.slideshare.net/secret/h3wT59xRPciKM6
   * https://www.slideshare.net/secret/yDV9vtRs61gEdg
   * https://www.slideshare.net/secret/E1asIyWYNfvkNv
   * https://www.slideshare.net/secret/LnSxMJ7JZ25JFe
   * Консенсус:
     https://www.slideshare.net/secret/LnSxMJ7JZ25JFe
   * Реализация ссылочных структуры:
     https://www.slideshare.net/secret/zrtgOfnRQY6K0Z
   * Массивы, CASN, R/W Locks, STM:
     https://www.slideshare.net/secret/8ZkekdbzRSIjsP
   * Рекомендуемые учебники:
     * The Art of Multiprocessor Programming, Maurice Herlihy, Nir
       Shavit, http://www.amazon.com/The-Multiprocessor-Programming-..
       Это основной учебник для осеннего семестра. Его надо знать и
       любить.
     * Concurrent and Distributed Computing in Java, Vijay K. Garg,
       http://www.amazon.com/Concurrent-Distributed-Computin..  Обзор
       для всех частей курса (пригодится так же и для второго
       семестра).
** Вступление, модели, их свойства, согласованность
   #+DATE: 07.09.2015
   *SMP* (/symmetric multiprocessing/) -- два или больше ядра, на каждом по
   потоку.

   *SMT* (/simultaneous multithreading/) -- два или больше потоков
   исполняются одним ядром.

   *NUMA* (/not uniform memory access/) -- все знают, что это еще с 1
   курса.

   Операционные системы (классификация по параллельности):
   1. Однозадачные
   2. Пакетные задания (/batch processing/)
   3. Многозадачные
      1. Кооперативная (/cooperative/) многозадачность.
         Переход от одной задачи к другой происходит явно, когда
         программа готова передать процессорное время другой.
      2. Вытесняющая (/preemptive/) многозадачность.
         Текущий подвид -- ОС сама расставляет инструкции как ей этого
         хочется.

   Поток и процесс (на практике вперемешку):
   * *Процесс* -- владеет памятью и ресурсами.
   * *Поток* -- контекст исполнения внутри процесса.

   Модели программирования:
   1. Однопоточное/однозадачное.
   2. Многозадачное:
      1. Модель с общей памятью:
         Единственное, что объединяет потоки -- общие объекты.
         Общий объект -- переменная (~read/write~, тип). Иногда зовутся
         регистрами, так как на практике значения лежат как раз в
         регистрах ЦП.
      2. Модель с передачей сообщений.

   Модели исполнения:
   1. Модель чередований
      Строим дерево, в котором описываем все возможные перестановки
      операций над общими объектами. Такая модель не описывает
      появление пары ~(0, 0)~ в следующем примере:

      #+NAME: java no-volatile
      #+BEGIN_SRC text
        thread P {
               x = 1
               r1 = y
        }
        thread Q {
               y = 1
               r2 = x
        }
      #+END_SRC

      Но оно может появиться вследствие того факта, что компилятор
      может переставить инструкции или же просто запись обоих значений
      будет отложена процессором.

      Модель чередования не описывает конкретно физических реалий этого
      мира -- ведь свет за один такт процессора проходит 10см, элементы
      просто физически не могут синхронизоваться.

      Физическая -- это световой конус.
   2. Happens before
      Исполнение системы -- пара $⟨H, →⟩$.
      * $H$ -- множество операций (чтение и запись ячеек памяти)
      * $e → f$ значит, что $e$ произошло раньше $f$ -- частичный строгий
        порядок на \(H\).
      * $a ∥ b$, если $¬(a → b ∨ b → a)$.
   3. Модель глобального времени
      Каждая операция -- интервал $[t_{inv}, t_{resp}]$, и если выражать
      через happens-before, то $a → b ≡ t_{resp}(a) < t_{inv}(b)$.

   Конфликты:
   * *Конфликт* (/data race/) -- ситуация, когда происходит две
     параллельных операции, и одна из них -- запись.
   * Корректно синхронизированная программа -- программа без
     конфликтов.

   Исполнения:
   1. *Последовательное* -- все операции линейно упорядочены отношением
      happens-before (→). В модели глобального времени ничего не
      наслаивается вообще.
   2. *Правильное* -- сужение исполнения на один поток (только
      операции, приналежащие конкретному потоку) последовательно.
      Неправильные исполнения -- вообще какая-то чепуха (параллельность
      в одном потоке). Или "~a = (b++) + (c++)~" -- undefined behavior
      в плюсах.
   3. *Допустимое последовательное* исполнение -- выполнены
      последовательные спецификации всех объектов. Посл. спецификация
      объекта -- последовательность сужения исполнения на конкретный
      объект.

   Условия согласованности:
   1. Последовательная согласованность
      Исполнение посл. согласованно, если можно сопоставить ему
      допустимое последовательное исполнение, причем программный
      порядок (≡ порядок операций на каждом потоке) сохраняется.

      Кстати последовательная согласованность на каждом объекте не
      влечет за собой последовательную согласованность исполнения.
   2. Линеаризуемость
      Исполнение линеаризуемо, если можно сопоставить ему
      допустимое последовательное исполнение, которое сохраняет порядок
      happens-before.

      Линеаризуемость локальна, линеаризуемость на каждом объекте
      влечет линеаризуемость системы.
      Операции над линеаризуемыми объектами называют атомарными.
      Исполнение системы, выполняющее операции над линеаризуемыми
      объектами, можно анализировать в модели чередования.
      Свойство thread-safe объекта есть ровно линеаризуемость.

      Если в примере java-novolatile сделать ~x,y volatile~, то пара
      $(0,0)$ не будет появляться, то есть исполнение действительно
      соответствует модели чередования.

      Реализуется ~volatile~ в java локами памяти (/memory lock/). Тут
      мы немного теряем производительность, но не страшно.
** Блокировки, взаимное исключение, deadlock'и
   #+DATE: 14.09.2015
   *Линеаризуемость* -- суперское свойство.  Даже если в каждом потоке
   все операции атомарны, мы не можем утверждать, что объект
   линеаризуем (ну представьте себе класс очереди с методами
   ~push/pop~).  Мы вот хотим линеаризуемую очередь.

   Самый простой метод сделать так -- это использование блокировок
   (/locks/, /mutex/ (/mutual exclusion/)).

   Идея: заведем в объекте ~member Mutex m~, будем его лочить и
   разлочивать. Этот объект будет гарантировать, что объект будет
   застрявать на ~.lock~, если мьютекс уже залочен и т.д.  Код с
   mutex'ами будет thread-safe, если операции будут защищены одним и
   тем же мьютексом.

   * *Взаимное исключения* -- свойство исполнения, при котором
     критические секции не могут выполняться параллельно -- это
     требование корректности взаимного исключения.

   При этом взаимное исключение имеет ряд условных условий прогресса:
     1. *Свобода взаимной блокировки* (/deadlock-freedom/) -- свойство
        взаимного исключения, при котором если несколько потоков
        пытаются войти в критическую секцию, то хотя бы один сделает
        это за конечное время (при условии что критические секции сами
        по себе конечны).
     2. *Отсутствие голодания* (/starvation-freedom/) -- если какой-то
        поток пытается войти в критическую секцию, он сделает это за
        конечное время (опять-таки, при условии, что крит. секции
        исп. за конечное время).
     3. *Линейное ожидание* -- каждый поток совершает $O(n)$ действий
        перед тем, как войти в критическую секцию (условие аналогично)
     4. *First Come First Served* (/FSFS/) -- свойство сильнее
        линейного ожидания, потоки обслуживаются в порядке утыкания в
        критическую секцию (условие аналогично).

   Как написать mutex, собственно?
   1. *Aлгоритм Петерсона* -- гарантирует взаимное исключение,
      отсутствие взаимной блокировки и отсутствие голодания.

      Преимущество -- самый простой.
      #+BEGIN_SRC text
        threadlocal int id // 0 or 1
        shared boolean want[2]
        shared int     victim

        def lock:
            want[id] = true
            victim = id
            while (want[1-id] and victim == id) {}

        def unlock:
            want[id] = false
      #+END_SRC
   3. *Aлгоритм Петерсона для N потоков* (/filter algorithm/).

      Все то же самое, но может делать $O(N²)$ ожидания.
      #+BEGIN_SRC text
        threadlocal int id
        shared int level[N]
        shared int victim[N]

        def lock:
            for j = 1..N-1:
                level[id] = j
                victim[j] = id
                while exist k: k != id and
                               level[k] >= j and
                               victim[j] == id:
                               {}

        def unlock:
            level[id] = 0
      #+END_SRC
   4. Алгоритм *Лампорта* (булочника -- 1 вариант).  Обладает свойством
      FCFS. Это вариант с бесконечными метками ~label~. Можно сделать с
      конечными.

      Первые две строки ~lock~ называются ~doorway~.
      #+BEGIN_SRC text
        threadlocal int id
        shared boolean want[N]  // init false
        shared int     label[N] // init 0

        def lock:
            want[id] = true
            label[id] = max(label) + 1
            while exists k: k != id and
                            want[k] and
                            (label[k], k) < (label[id], id)
                            {}
      #+END_SRC

   Блокировки бывают грубыми и тонкими.
   * *Грубая* -- блокировать всю операцию целиком.
   * *Тонкая* -- блокировать операции над общими объектами внутри, а не
     вызов, но тогда необходима двухфазовая блокировка.

   Есть проблема deadlock'а. Допустим, что есть два mutex'а, мы лочимся
   в одном треде сначала по ~m1~, потом по ~m2~, в другом треде
   наоборот. Можем задедлочиться тут короче.

   *Закон Амдала* для параллельной работы: \[speedup = \frac{1}{(S +
   \frac{1-S}{N})}\] Это максимальное ускорение при запуске кода в $N$
   потоков, если доля кода $S$ выполнена последовательно.
** Алгоритмы/объекты без блокировок, свободы (lock/wait/obstr)
   #+DATE: 21.09.2015
   Алгоритмы без блокировок.

   Безусловные условия прогресса:
   1. *Obstruction-free* (/отсутствие помех/) -- свойство алгоритма, в
      котором если остановить всe потоки кроме одного (любого) в любом
      месте, один должен завершиться за конечное время. Так должно
      работать для каждого объекта.  Очевидно, что объект с блокировкой
      не имеет такого свойства.
   2. *Lock-freedom* -- если много потоков пытаются сделать операцию,
      то хотя бы один поток должен ее исполнить за конечное
      время. Плохо то, что это условие не исключает голодания.
   3. *Wait-freedom* (самое сильное условие) -- если какой-то поток
      пытается выполнить операцию, то он это сделает (вне зависимости
      от действия/бездействия других потоков).

   Объекты без блокировки. ОБъекты бывают с lock-freedom, но этот
   термин перегружен.
   * Регистры без блокировки
     * Свойства физических регистров:
       1. Неатомарны.
       2. Работают без ожидания.
       3. Предполагают только одного читателя и одного писателя.
       4. Попытка записать и прочитать одновременно -- UB.
       5. Они безопасные (/safe/) -- в смысле, после записи, будет
          прочитано последнее записанное значение.
     * Классификация регистров
       1. По условиям согласованности:
          1. *Безопасные* (/safe/) -- гарантирует получение последнего
             записанного значения, если операция чтения не параллельна
             операции записи.
          2. *Регулярные* (/regular/) -- при чтении выдает последнее
             записанное, или то, что уже пишется.
          3. *Атомарные* (/atomic/) -- линеаризуемое (как регулярный,
             только если уже прочитал новое значение, то старое нельзя
             прочитать).

             Как проверить регистр на атомарность в схеме глобального
             времени -- поставить в каждой полоске точку,
             соответствующую этому конкретному действию. Порядок по
             точкам должен быть атомаррным.
       2. По количеству потоков (~SR~, ~MR~, ~SW~, ~MW~ :
          ~single/multi~ ~reader/writer~).

     * Будем строить более сложные регистры из простых требуя
       wait-free условие.
       Пусть у нас есть Safe SRSW Boolean регистр.
       1. Regular SRSW Boolean.

          #+BEGIN_SRC text
            safe shared boolean r
            threadlocal boolean last

            def write(x):
              if (x != last)
                last = x
                r = x

            def read(): return r
          #+END_SRC
       2. Regular SRSW M-Valued.

          Пусть у нас массив ~r~ хранит булевые значения, и число в нем
          хранится последовательностью единиц, терминированной
          нулем. Тогда это реализуется так:

          #+BEGIN_SRC text
            regular shared boolean[M] r

            def write(x): // Справа налево
              r[x] = 0
              for i = x-1 downto 0: r[i] = 1

            def read(): // Слева направо
              for i = 0 to M-1: if r[i] == 0: return i
          #+END_SRC
       3. Atomic SRSW M-Valued.

          Будем хранить пару -- значение и версию. Версию можно разумно
          ограничить. Есть алгоритм без жульничества с версиями, но он
          на практике плох.

          #+BEGIN_SRC text
            safe shared (int x, int v) r
            threadlocal (int x, int v) lastRead
            threadlocal int lastWriteV

            def write(x):
              lastWriteV++
              r = (x, lastWriteV)

            def read():
              cur = r
              if cur.v > lastRead.v:
                lastRead = cur
              return lastRead.x
          #+END_SRC

          Атомарный регистр: проблемы
          1. *Версии* -- могут хранить пару в регуярном, но версии
             растут неограниченно.
          2. *Блокировки* -- алгоритм Лампорта будет работать на
             регулярных регистрах, но это не дает алгоритм без ожидания.

          * Теорема: не существует алгоритма построения атомарного
            регистра без ожидания, который использует конечное число
            регулярных регистров конечного размера так, чтобы их писал
            только писатель, а читал только читатель
          * Доказательство
            Нужна обратная связь от читателя к писателю.
       4. Atomic MRSW M-Valued.

          Нужно отслеживать версию записанного значения, храня пару
          $(x, v)$ в каждом из $N$ регистров в которые пишет писатель.
          Наивно сделать это нельзя.

          Заведем $N×(N-1)$ регистров для общения между читателями.

          1. Каждый читатель выбирает более позднее значение из
             записанного писателем и из прочитанных значенией других
             читателей
          2. Читатель записывает свое прочитанное значение и версию для
             всех остальных читателей.
       5. Atomic MRMW M-Valued.

          Нужна поддержка $N$ писателей.

          Отслеживаем версию записанного значения:
          1. Каждый читатель выбирает более позднюю версию
          2. Для проставления версий писателями используем doorway
             секцию из алгоритма булочника (Лампорта)
             * Версия состоит из пары номера потока писателя и
               собственно числа
     * Атомарный снимок состояния N регистров.

       Наивная реализация не обеспечивает атомарность.

       Вот этот алгоритм уже lock-free, но достаточно наивный --
       читает, пока массивы не совпадут.
       #+NAME: lock-free implementation of atomic registers snapshot
       #+BEGIN_SRC text
         shared (int x, int v) r[N]

         // wait-free
         def update(i, x):
             r[i] = (x, r[i].v + 1)

         // lock-free
         def scan():
             old = copy()
             loop:
                 cur = copy()
                 if forall i: cur[i].v == old[i].v
                    return cur.x  // we can get starvation here,
                                  // if update is executed too frequent
                 old = cur
       #+END_SRC

       Вот wait-free реализация с костылями.
       #+NAME: wait-free implementation
       #+BEGIN_SRC text
         shared (int x, int v, int[N] s) r[N]

         def update():
             s = scan()
             r[i] = (x, r[i].v + 1, s)

         shared (int x, int v, int[N] s) r[N]

         // wait-free, O(N^2)
         def scan():
             old = copy()
             boolean updated[N]
             loop:
                 cur = copy()
                 for i = 0..N-1:
                     if cur[i].v != old[i].v:
                        if updated[i]: return cur.s
                        else:
                         update[i] = true
                         old = cur
                         continue loop
                 return cur.x
       #+END_SRC
       * Лемма: Если значение поменялось второй раз, значит копия
         снимка $s$ была получена вложенной операцией ~scan~.
** Консенсус
   #+DATE: 05.10.2015

   *Консенсус* -- это объект, который помогает $n$ потокам придти к общему
   мнению.
   #+BEGIN_SRC text
     class Consensus:
           def decide(val):
           ...
           return decision
   #+END_SRC

   Каждый поток использует объект ~Consensus~ один раз.
   Требуются две вещи:
   * *Согласованность* (/consistency/): все потоки должны вернуть одно
     и то же значение из метода decide.
   * *Обоснованность* (/validity/): возвращенное значение было входным
     значением какого-то из потоков.

   #+NAME: Консенсус с блокировкой
   #+BEGIN_SRC text
     shared int decision
     Mutex mutex

     def decide(val):
         mutex.lock()
         if (decision == NA):
            decision = val
         mutex.unlock()
         return decision
   #+END_SRC
   Но мы хотим без ожидания.

   Все не так просто.
   Консенсусное число:
   1. Если с помощью класса атомарных объектов $С$ и атомарных регистров
      можно реализовать консенсусный протокол без ожидания для $N$
      потоков (и не больше), то говорят что у класса $С$ консенсусное
      число равно $N$.
   2. Теорема:
      Атомарные регистры имеют консенсусное число 1.
      * То есть с помощью атомарных регистров даже 2 потока не могут
        придти к консенсусу без ожидания (докажем от противного) для 2х
        возможных значений при $T = \{0, 1\}$
      * С ожиданием задача решается очевидно (с помощью любого
        алгоритма взаимного исключения).
   3. Определения и леммы для любых классов объектов:
      * Определения и концепции
        1. Исходныe объекты атомарны. Любое исполнение можно
           рассматривать как последовательное в каком-то порядке.
        2. Рассматриваем дерево состояния, листья -- конечные состояния
           помеченные 0 или 1 (в зависимости от значения консенсуса).
        3. *x-валентное* состояние системы ($x ∈ \{0,1\}$) -- консенсус
           по всех нижестоящих листьях будет x.
        4. *Бивалентное* состояние -- возможен консенсус как 0 так и 1.
        5. *Критическое* состояние -- такое бивалентное состояние, все
           дети которого одновалентны.
      * Лемма: Существует начальное бивалентное состояние.

        Это нетривиально следует из того факта, что алгоритм без
        ожиданий.

        Возьмем конечное количество шагов, построим дерево.
        $???$
        Доказательство было на доске и не сохранилось.
      * Лемма: Существует критическое состояние

        Тоже следует из wait-free. Если есть бивалентное, будем
        смотреть его детей. Если есть хотя бы один бивалентный ребенок,
        то спускаемся в него, пока бивалентных детей больше нету.
        За счет конечности дерева такое будет существовать, и
        валентность детей будет различна (иначе валентность самого узла
        тоже определена).

      Для атомарных регистров рассмотрим возможные пары операций в
      критическом состоянии:
      * Операции над разными регистрами коммутируют.
      * Два чтения коммутируют.
      * Любая операция + запись -- состояние пишущего потока не зависит
        от порядка операций. Противоречие (в чем???).
   4. Бывают Read-Modify-Write регистры.

      #+NAME: read-modify-write reg
      #+BEGIN_SRC text
        class RMWRegister:
              private shared int reg

              def read():
                  return reg

              def getAndF(args):
                  do atomically:
                     old = reg
                     reg = F(args)(reg)
                     return old
      #+END_SRC
      Функция F может быть ~getAndSet~, ~getAndIncrement~,...

      #+NAME: Consensus for RMW reg, реализация для 2х потоков
      #+BEGIN_SRC text
        threadlocal int id // 0 or 1

        shared RMWRegister rmw
        shared int proposed[2]

        def decide(val):
            proposed[id] = val
            if (rmw.getAndF() == v0)
                return proposed[i]
            else:
                return proposed[1-i]
      #+END_SRC

      * Консенсусное число нетривиального RMW регистра $≥ 2$.

        Нужно чтобы была хотя бы одна подвижная точка функции $F$,
        например $F(v_0) = v_1 ≠ v_0$.

   5. Common2 RMW регистры
      * $F_1$ и $F_2$ коммутируют если $F_1(F_2(x)) = F_2(F_1(x))$.
      * $F_1$ перезаписывает $F_2$ если $F_1(F_2(x)) = F_1(x)$.
      * Класс $С$ RMW регистров принадлежит Common2 если любая пара
        функций либо коммутирует либо одна из функций перезаписывает
        другую.
      * Теорема: нетривиальный класс Common2 RMW регистров имеет
        консенсусное число 2.

        Третий поток не может отличить глобальное состояние при
        изменении порядка выполнения коммутирующих или перезаписывающих
        операций в критическом состоянии.
   6. Универсальные объекты
      Объект с консенсусным числом $∞$ называется универсальным объектом.
      По определению, с его помощью можно реализовать консенсусный
      протокол для любого числа потоков.

      #+NAME: CAS register
      #+BEGIN_SRC text
        class CASRegister:
              private shared int reg

              def CAS(expect, update):
                  do atomically:
                     old = reg
                     if old == expect:
                        reg = update
                        return true
                     return false
      #+END_SRC

      CAS -- самый популярный универсальный объект, процессоры в том
      или ином виде его реализуют.

      * CAS и консенсус
        #+NAME: реализация протокола через CAS+READ
        #+BEGIN_SRC text
          def decide(val):
              if CAS(NA, val):
                  return val
              else:
                  return read()
        #+END_SRC

      * Универсальность консенсуса. Теорема.
        Любой последовательый объект можно реализовать без ожидания для
        N потоков используя консенсусный протокол для N объектов

        * Такое построение -- универсальная конструкция
        * Следствие 1: С помощью любого класса объектов с консенсусным
          числом N можно реализовать любой объект с консенсусным числом
          ≤ N
        * Следствие 2: С помощью универсального объекта можно
          реализовать вообще любой объект
          * Сначала реализуем консенсус для любого числа потоков (по
            определению универсального объекта)
          * Потом через консенсус любой другой объект используя
            универсальную конструкцию.
        * Доказательство теоремы
          1. Универсальная конструкция без блокировки через CAS
             #+BEGIN_SRC text
               shared CASRegister reg

               def concurrentOperationX(args):
                   loop:
                       old = reg.read()
                       upd = old.deepCopy()
                       res = upd.serialOperationX(args)
                   until reg.CAS(old, upd)
                   return res
             #+END_SRC

             * Без блокировки универсальная конструкция проста и
               проктична, если использовать CAS в качестве примитива.
             * Для реализации через консенсус надо чтобы каждый объект
               консенсуса пользовался потоком один раз
             * Для реализации без ожидания нужно чтобы потоки помогали
               друг другу.
          2. Через консенсус.

             ОБъект -- односвязный список стейтов.
             Последний элемент -- текущий стейт.

             #+NAME: Через консенсус без блокировки
             #+BEGIN_SRC text
               class Node:
                     val               // readonly
                     Consensus next    // init fresh obj

               shared Node root        // readonly
               threadlocal Node last   // init rood

               def concurrentOperationX(args):
                   loop:
                       old = last.val
                       upd = old.deepCopy()
                       res = upd.serialOperationX(args)
                       node = new Node(upd)
                       last = last.next.decide(node)
                   until last == node
                   return res
             #+END_SRC

             * Но с ожиданием

          3. Через консенсус без ожидания
             * Храним в узле операцию, которую нужно выполнить, а не
               результат -- каждый поток обновляет и хранит свою
               локальную копию объекта
             * Нумеруем операции последовательными числами, заведя
               переменную ~seq~. После выполнения прописываем номер
               исполненной операции.
             * Каждй поток хранит последнее ему известное значение
               конца списка в элементе массива ~know[id]~.
             * Каждый поток будет заранее записывать операцию, которую
               он планирует выполнить -- в массиве ~announce~.

             #+NAME: Через консенсус без блокировки
             #+BEGIN_SRC text
               class Node:
                     int seq           // init 0
                     args              // readonly
                     Consensus next    // init fresh obj

               shared Node[] announce // init root
               shared Node[] know // init root

               def concunrrentOperationX(args):
                   announce[id] = new Node(args)
                   know[id] = maxSeqFrom(know)
                   while announce[id].seq == 0
                         Node help =
                              announce[know[id].seq % N]
                         Node prev = help if help.seq == 0
                              else announce[id]
                         know[id] = prev.next.decide(node)
                         know[id].seq = prev.seq + 1
                   know[id] = announce[id]
                   return updateMyLastTo(announce[id])

               def updateMyLastTo(node):
                   while last != node:
                         res = my.serialOperationX(last.args)
                         last = last.next
                         return res
             #+END_SRC
   7. Сводная иерархия
      |--------------------------------------------+--------------------|
      | Объект                                     | Консенсусное число |
      |--------------------------------------------+--------------------|
      | Атомарные регистры                         | 1                  |
      | Снимок состояния нескольких регистров      |                    |
      |--------------------------------------------+--------------------|
      | getAndSet, getAndAdd, очередь, стек        | 2                  |
      |--------------------------------------------+--------------------|
      | Атомарная запись m регистров из m(m+1)/2   | m                  |
      |--------------------------------------------+--------------------|
      | compareAndSet, LoadLinked/StoreConditional | ∞                  |
      |--------------------------------------------+--------------------|
** Практические построения на списке, вступление
   Будем смотреть всякие практические построения на списках.
   Будем писать код уже на джаве настоящей.

   *Java* -- первый язык, в котором появилась модель памяти (/memory
   model/). Почему джава? Трюки c++ (~if_arch_~...) не работают в джаве,
   джава очень WORA, и прочее.

   *JMM* определяет:
   1. Межпоточные действия -- чтение и запись,
      синхронизация. Синхронизация -- ~volatile~/~synchronized~/запуск или
      остановка потоков.
   2. Отношение синхронизации (/synchronizes-with/) и отношение
      happens-before.
      Java гарантирует, что если в программе нету гонок, то исполнение
      последовательно согласовано (а значит и линеаризуемо).
   3. Всякие гонки и прочее.

   Выполнение корректно синхронизированной программы будет выглядеть
   последовательно согласовано. Гонки за данными не могут нарушить
   базовые гарантии безопасности платформы (система типов, все кроме
   ~long/double~ атомарны, все поля гарантированно инициализированы
   нулями, дополнительные гарантии для ~final~ полей).

   #+NAME: рабочий вариант 1 решения того же самого кода без volatile
   #+BEGIN_SRC java
     volatile int flag;
     int value;

     void int() {
         value = 2;
         flag = 1;
     }

     int take() {
         while (flag == 0); // кушаем cpu тут
         return value;
     }
   #+END_SRC

   #+NAME: решение 2, cpu не прогорает
   #+BEGIN_SRC java
     int flag, value;

     void synchronized int() {
         value = 2;
         flag = 1;
     }

     int synchronized take() {
         while (flag == 0); // кушаем cpu тут
         return value;
     }
   #+END_SRC

   Таким образом, мы реализовали thread-safe объект.

** Типы синхронизации на примере списка (LinkedSet)
   * *Многопоточные объект* -- это объект, который можно использовать
     из нескольких потоков без дополнительной внешней синхронизации,
     при этом:
     1. Специфицируется через последовательное поведение.
     2. По умолчанию требуется линеаризуемость операций (редко -- более
        слабые условия).
     3. Редко удается реализовать все операции wait-free. Чаще всего
        делается с блокировками или без них (что на самом деле
        lock-free).

   Типы синхронизации:
   1. Грубая синронизация (~Coarse-grained~).
   2. Тонкая (~fine-grained~).
   3. Оптимистичная (~optimistic~).
   4. Ленивая (~lazy~).
   5. Неблокирующая (~non-blocking~).

   Будем строить многопоточные связанные списки. Массивами пользоваться
   намного эффективней, но они сложнее пишутся.

   #+NAME: Что пытаемся синхронизировать
   #+BEGIN_SRC java
     // инвариант node.key < node.next.key
     class Node {
         final int key;
         final T item;
         Node next;
     }
   #+END_SRC
   Пустой список будет состоять из 2х граничных элементов:
   #+BEGIN_SRC java
     Node head = Node(Integer.MIN_VALUE, null);
     head.next = Node(Integer.MAX_VALUE, null);
   #+END_SRC
*** Грубая синхронизация
    Обеспечиваем синхронизацию через
    ~java.util.concurrent.locks.ReentrantLock lock~.
    Такой подход дает немножко больше функционала чем секции
    ~synchronized~.

    #+NAME: грубая синхронизация списка
    #+BEGIN_SRC java
      class LinkedSet {
          final Node head;
          final Lock lock; // mutex

          boolean contains(int key) {
              lock.lock();
              try {
                  Node curr = head;
                  while (curr.key < key) {
                      curr = curr.next;
                  }
                  return key == curr.key;
              } finally { lock.unlock() }
          }

          boolean add(int key, T item) {
              lock.lock();
              try {
                  Node pred = head, curr = pred.next;
                  while (...) {}
                      /// stuff
              } finally { lock.unlock(); }
          }
          boolean remove (int key, T item) {
              lock.lock();
              try {
                  // stuff
              } finally { lock.unlock; }
          }
      }
    #+END_SRC
*** Тонкая синхронизация
    Обеспечиваем синхроизацию взаимным исключением на каждом
    объекте. При любых операциях одновременно удерживаем блокировку
    текущего и предыдущего элемента, чтобы не потерять инвариант
    ~pred.next == curr~.

    #+NAME: Тонкая синхронизация
    #+BEGIN_SRC java
      class Node {
          final int key;
          final T item;
          final Lock lock;
          Node next;

          void lock() { lock.lock(); }
          void unlock() { lock.unlock(); }
      }

      class LinkedSet {
          boolean contains() {
              Node pred = head; pred.lock();
              Node curr = pred.next; curr.lock();
              try {
                  while (curr.key < key) {
                      // отпускаем блокировку у предыдущего объекта
                      // берем у следующего.
                      pred.unlock();
                      pred = curr;
                      curr = curr.next;
                      curr.lock();
                  }
                  return key == curr.key;
              } finally { curr.unlock(); pred.unlock(); }
          }

          boolean add(int key, T item) {
              Node pred = head; pred.lock();
              Node curr = pred.next; curr.lock();
              try {
                  // addition
                  while (curr.key < key) {
                      pred.unlock(); pred = curr;
                      curr = curr.next; curr.lock();
                  }
                  if (key == curr.key) return false; else {
                      Node node = new Node(key, item);
                      node.next = curr; pred.next = node;
                      return true;
                  }
              } finally { curr.unlock; pred.unlock; }
          }

          boolean remove(int key, T item) {
              Node pred = head; pred.lock();
              Node curr = pred.next; curr.lock();
              try {
                  // removal
              } finally { curr.unlock; pred.unlock; }

          }
      }
    #+END_SRC
*** Оптимистичная синхронизация
    Алгоритм построения:
    1. Ищем элемент без синхронизации, но перепроверяем с
       синхронизацией.
       1. Если перепроверка сломалась, то начинаем операцию заново
       2. Поиск не зациклится, ибо ключи упорядочены, никогда не
          меняются внутри Node, значения next не могут возникнуть
          ниоткуда даже при чтении без синхронизации
    2. Имеет смысл только если обход дешев и быстр, а обход с
       синхронизацией -- наоборот.
    3. Потоки всегда синхронизируются между собой ("synchronizes with")
       через критические секции, поэтому никаких дополнительных
       механизмов не нужно.
    #+NAME:Оптимистичная синхронизация
    #+BEGIN_SRC java
      class LinkedSet {
          // проверяет, что pred является предыдущим для curr
          // идет от начала списка до pred оптимистично, там сравнивает
          boolean validate(Node pred, Node curr) {
              Node node = head;
              while (node.key <= pred.key) {
                  if (node == pred) {
                      return pred.next == curr;
                  }
                  node = node.next;
                  if (node == null) return false;
              }
          }

          boolean contains(int key) {
          retry: while (true) {
                  Node pred = head, curr = pred.next;
                  while (curr.key < key) {
                      pred = curr; curr = curr.next;
                      if (curr == null) continue retry;
                  }
                  pred.lock(); curr.lock();
                  try {
                      if (!validate(pred, curr)) continue retry;
                      return curr.key == key;
                  } finally { curr.unlock(); pred.unlock();
                  }
              }
          }
          boolean add(int key, T item) {
          retry: while (true) {
                  Node pred = head, curr = pred.next;
                  while (curr.key < key) {
                      pred = curr; curr = curr.next;
                      if (curr == null) continue retry;
                  }
                  pred.lock(); curr.lock();
                  try {
                      if (!validate(pred, curr)) continue retry;
                      if (curr.key == key) return false; else {
                          Node node = new Node(key, item);
                          node.next = curr; pred.next = node;
                          return true;
                      }
                  } finally { curr.unlock(); pred.unlock(); }
              }
          }
          // remove аналогично
      }
    #+END_SRC
*** Ленивая синхронизация
    Как строить:
    1. Добавляем в ~Node boolean~ флажок, в котором будем помечать
       удаленные элементы. Удаление в две фазы -- флажок помечен
       соответствует логическому удалению, физическое следует позже.
    2. Инвариант: все непомеченные элементы всегда в списке.
    3. Результат: для валидации не надо просматривать список (только
       проверить, что элементы не удалены логически и ~pred.curr ==
       next~), остальное как в оптимистичном варианте.

    Поиск без ожидания:

    #+NAME:Ленивая синхронизация
    #+BEGIN_SRC java
      class Node {
          final int key;
          final T item;
          final Lock lock;
          boolean marked;
          // Очень важен volatile для линеаризуемости!
          volatile Node next;

          void lock() { lock.lock(); }
          void unlock() { lock.unlock(); }
      }

      class LinkedSet {
          boolean validate(Node prev, Node next) {
              return !pred.marked &&
                  !curr.marked &&
                  pred.next == curr;
          }

          boolean add(T elem) {
          retry: while (true) {
                  Node pred = head, curr = pred.next;
                  while (curr.key < key) {
                      pred = curr; curr = curr.next;
                      //                   ^^^^^^
                      //            тут curr.next != null
                  }
                  pred.lock(); curr.lock();
                  try {
                      if (!validate(pred,curr)) continue retry;
                      if (curr.key == key) {
                          curr.marked = true; // для validate
                          pred.next = curr.next; // точка линеаризации
                          return true;
                      } else return false;
                  } finally { curr.unlock(); pred.unlock(); }
              }
          }

          void delete (T elem) {
          retry: while (true) {
                  Node pred = head, curr = pred.next;
                  while (curr.key < key) {
                      pred = curr; curr = curr.next;
                      //                   ^^^^^^
                      //            тут curr.next != null
                  }
                  pred.lock(); curr.lock();
                  try {
                      if (!validate(pred,curr)) continue retry;
                      if (curr.key == key) return false;
                      else {
                          Node node = new Node(key, item);
                          node.next = curr; // сначала! порядок важен
                          pred.next = node; // тут точка линеаризации
                          return true;
                      }
                  } finally { curr.unlock(); pred.unlock(); }
              }
          }

          // Wait-free поиск!
          boolean contains(int key) {
              Node curr = head;
              while (curr.key < key) {
                  curr = curr.next; // точка линеаризации
              }
              return key == curr.key;
          }
      }
    #+END_SRC
*** Неблокирующая синхронизация
    Сделать синхронизацию без блокировок нетривиально:
    * Простое использование CAS не помогает -- удаление двух соседних
      элементов будет конфликтовать
      1, 2, 3, 4, удалим 2, 3 одновременно, но указатель 1 → 3
      сохранится.
    * Трюк такой: объединим ~(next, marked)~ в одну переменную, и будем ее
      изменять CASом атомарно.
      * Одновременное удаление соседних двух элементов будет
        конфликтовать
      * Каждая операция модификации выполняется одним успешным CAS'ом.
      * Это выполнение CAS'а и есть точка линеаризации
    * Будем пытаться удалять физически, от этого добавление и удаление
      станут lock-free, а поиск вообще wait-free.
    * В реализации будем использовать для пары
      ~java.util.concurrent.atomic.AtomicMarkableReference~.
** Продолжение построений на списках, стеках
   #+DATE: 2015.10.19
   Можно строить структуры универсально, храня на нее указатель и меняя
   его CAS'ом каждый раз. Так, например, работает счетчик -- в джаве
   это ~AtomicInteger~.

   Персистентные структуры тоже несложно пишутся, достаточно заменить
   CAS'ом root на новый после изменения структуры. Остальное дерево
   остается прежней версии (персистентность, собсна).
*** Стек LIFO
    Рассмотрим частный, вырожденный случай древовидной структуры --
    стек. Он не масштабируемый. Если конкуренция очень большая, то
    производительность в многосокетных системах на top будет падать.
    #+NAME: stack implementation
    #+BEGIN_SRC java
      // such immutable!
      class Node {
          final T item;
          final Node next;
      }

      final AtomicReference<Node> top = new AtomicReference<Node>(null);

      void push(T item) {
           while (true) {
                 Node node = new Node(item, top.get());
                 if (top.compareAndSet(node.next, node)) // линеаризация
                    return;
           }
      }

      T pop() {
        while (true) {
              Node node = top.get();

   if (node == null) throw new EmptyStack();
              if (top.compareAndSet(node, node.next)) // линеаризация
                 return node.item;
        }
      }
    #+END_SRC

    С разделяемой памятью вообще все достаточно сложно, там не только
    race condition'ы в большом количестве, но и куча проблем с
    производительностью. Будем пока считать что стек хороший.
*** Очереди на списках, Майкл-Скотт
    Будем делать очередь на списках. Наивно с помощью универсальной
    конструкции так себе, а популярный алгоритм -- Майкла Скотта.

    Делаем список, у очереди есть указатель на голову и хвост, все
    односвязно. Будем элементы добавлять и удалять достаточно
    естественно.
    Добавление: Создаем элемент, ссылаемся на голову, с помощью CAS'а
    меняем указатель на голову в классе.
    Дописать элемент в хвост сложно, потому что нужно поменять сразу две
    ячейки памяти -- указатель класса на хвост, указатель предыдущего
    элемента хвоста на последний.

    Идея алгоритма Майкла-Скотта такая: будем брать элемент и
    подписывать его в хвост, меняя ссылку предыдущего, а физически
    перемещать tail (указатель из класса) потом.
    Если другой поток увидит, что очередь в состоянии "есть ссылка на
    tail, у которого есть следующий элемент", то он может помочь
    переставить указатель класса на нужный элемент.

    #+NAME: Майкл-Скотт
    #+BEGIN_SRC java
      class Node {
          T item;
          final AtomicReference<Node> next;
      }

      AtomicReference<Node> head =
          new AtomicReference<Node>(new Node(null));
      AtomicReference<Node> tail =
          new AtomicReference<Node>(head.get());

      void enqueue(T item) {
          Node node = new Node(item);
       retry: while (true) {
              Node last = tail.get(),
                  next = last.next.get();
              if (next == null) {
                  if (!last.next.compareAndSet(null, node))
                      continue retry;
                  // оптимизация -- сами переставляем tail
                  tail.compareAndSet(last, node);
                  return;
              }
              // помогаем другим операциям enqueue с tail
              tail.compareAndSet(last, next);
          }
      }

      T dequeue() {
       retry: while (true) {
              Node first = head.get(),
                  last = tail.get(),
                  next = first.next();
              if (first == last) {
                  if (next == null) throw new EmptyQueue();
                  // Помогаем операциям enqueue с tail
                  tail.compareAndSet(last, next);
              } else {
                  if (head.compareAndSet(first, next)) // линеаризация
                      return next.item;
              }
          }
      }
    #+END_SRC
*** ABA problem
    Есть проблема в средах без сборки мусора, называется ABA. Суть:
    Будем реализовывать самый первый стек этой лекции на C, без Garbage
    collector'а.
    Добавим  в стек несколько элементов -- A и B.
    Может быть такое, что top стека может быть: A B A.
    Достанем указатель на top, сделаем успешно cas, на return нас
    перебил другой поток, и что-то переаллочилось, теперь в A лежит
    какая-то другая фигня.

    Еще раз: в стеке 1 элемент, по адресу A (top = A).
    Мы делаем ему pop, достаем A. В это время нас прерывают.
    Другой поток делает pop A, push B, pop B, push C на месте A появился
    другой элемент, но CAS сравнивает только указатели, и в этом случае
    он не обнаружит эту проблему.
    В джаве это не работает так, потому что память на A нельзя
    освободить, пока на нее ссылаются.

    Решить ABA проще всего с помощью реализации сборщика мусора.
    Другой способ -- пользоваться версиями. Хранить в top пару из
    указателя и версии. Таким образом если стек за время top.get и cas
    успел поменяться, мы сравним версии и упадем. Именно поэтому мы
    можем делать cas на 2х последовательных словах, это позволяет нам
    менять одновременно указатель + версию.
    Еще можно пользоваться Hazard Pointers -- многопоточный сборщик
    мусора, который работает только для наших узлов.
** Алгоритмы на массивах
*** Стек на массиве
    Давайте делать стек на массиве.

    В однопоточном варианте стек на массиве -- очень просто.
    Типа держим размер, pop/push меняет размер массива и ячейку.
    Но это все равно не взлетит в многопоточном варианте совсем прям
    наивно.

    Вот делаем мы ~push~. Сначала увеличим top cas'ом, а потом проставим
    элемент. Push будет работать, но pop в такой реализации упадет --
    если мы уже увеличили top, но не положили элемент, то достанет
    какой-то мусор.

    Аналогично если сначала проставляем элемент, а потом увеличиваем
    ~top~, то там будет что-то старое.

    С очередями проблемы те же.

    Будем писать дек, пытаясь реализовать obstruction-free свойство.
    Дек будет циклическим.  Храним в элементе пару -- значение и
    версия. Там где дек пустой, будем хранить ~(left_null, version)~,
    справа ~(right_null, version)~.

    Для корректности алгоритма не будем полагаться на указатели ~left~ и
    ~right~ в классе дека -- они будут типа для производительности, а
    индексироваться будем за $O(n)$.

    На практике этим никто не пользуется, потому что все равно
    медленнее, чем на ссылочном листе.

    #+NAME: Дек без помех
    #+BEGIN_SRC java
     int rightOracle() {
         int k = right; // для оптимизации
         while (a[k] != RN) k++;
         while (a[k-1] == RN) k--;
         right = k; // запомнили для оптимизации
         return k;
     }

     void rightPush(T item) {
      retry: while (true) {
             int k = rightOracle();
             {T item, int ver} prev = a[k-1], cur = a[k];
             if (prev.item == RN || cur.item != RN) continue;
             if (k == MAX-1) throw new FullDeque();
             if (CAS(a[k-1], prev, {prev.item, prev.ver+1} &&
                     CAS(a[k], cur, {item, cur.ver+1}))) return;
         }
     }

     T rightPop() {
      retry: while (true) {
             int k = oracleRight();
             {T item, int ver} cur = a[k-1], next = a[k];
             if (cur.itim == RN || next.item != RN) continue;
             if (cur.item == LN) throw new EmptyDeque();
             if (CAS(a[k], next, {RN, next.ver+1}) &&
                 CAS(a[k-1], cur, {RN, cur.ver + 1}))
                 return cur.item;
         }
     }
    #+END_SRC
*** Хэш-таблицы на массиве
    Бывают с прямой адресацией (по хэшу находим ведро, и все элементы с
    таким хэшом попадают в это ведро -- там дальше список или дерево).
    На практике с прямой адресацией все медленно, потому что там опять
    массивы или списки.
    Бывают с открытой, это самый лучший вариант.
    Но со списками намного проще.

    Будем пользоваться алгоритмом Split-Ordered lists.
    Засунем все элементы в одно большое связанео множество. Упорядочим
    их по хэшу. Для ускорения заведем слева хэш-таблицу, адресующую те
    элементы листа с заданным хэшом. Эта дополнительная таблица делается
    только для ускорения.
    Когда будем хотеть расширить таблицу, создадим вторую, скопируем ее
    черезстрочно, будем по мере обращений к хэшу ее обновлять (вторую).


    Открытая адресация.
    Делаем на массиве, будем считать ведро по хэшкоду, если занято, то
    дальше.
    Добавлять из нескольких потоков легко -- просто делаем cas. Удалять
    из такой таблицы можно прописывая некоторое особенное
    значение T. Нельзя прудмать алгоритм, который бы многопоточно
    закрывал дырки в этих списках.
    Ну, допустим мы забиваем элементы T, но как перевыделять память со
    временем -- для освобождения элементов T или расширения таблицы.

    Сделаем так, что таблица хранит указатель на "реальную" внутреннюю
    таблицу. Когда копируем, создаем новую таблицу, а указатель поставим
    в конце. Операция изменения ищет в новой таблице, если нету, то ищет
    в старой, если находит -- копирует в новую.
    Таким образом мы перенесем все элементы в новую таблицу.
    Как переносить, собственно?

    Если собираемся переносить, то пометим битиком значение. После этого
    мы занимаем слот в новой таблице, после этого копируем значение в
    новой таблице. Затем в старой пометим, что мы уже скопировали.
    #+BEGIN_SRC text
      (0, 0)
         ↓
      {Claim key}
         ↓
      (K, 0)
         ↓
      {Set value}
         ↓
      (K, V)            → Start copy → (K, V')
         ↕                               ↑
      {insert/delete}                  Moved
         ↕                               ↑
      (K, T)            → Moved      → (K, T')
    #+END_SRC
** CASN
   Этот алгоритм с переносом таблиц есть частный случай.
   Хотим чтобы работало корректно (линеаризуемо) и:
   1. Lock-free.
   2. Disjoint-Access Parallel (непересекающиеся доступы параллельны).

   #+NAME: CASN -- желаемое поведение
   #+BEGIN_SRC java
     boolean CASN(CASEntry... entries) atomic {
         for (CASEntry entry: entries)
             if (entry.a.value != entry.expect)
                 return false;
         for (CASEntry entry: entries)
             entry.a.value = entry.update;
         return true;
     }
   #+END_SRC

   Если мы сделаем CASN, то сделаем стек на массиве -- будем
   одновременно делать CAS 2 раза.

   #+NAME: CASN -- реализация
   #+BEGIN_SRC java
     import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;

     public class CASEntry<T> {
         final DataReference<T> a; // что поменять
         final T expect; // ожидаемое значение
         final T update; // на что заменить
         // И тут простой конструктор для всех трех полей
     }

     // RDCSS сложна, только если ячейка может страдать от ABA.
     // Если нет, то проще.
     class RDCSSDescriptor {
         private final DataReference a1;
         private final Object expect1;
         private final DataReference a2;
         private final Object expect2;

         private final Object update2;
         // и конструктор

         Object invoke() {
             Object r;
             do {
                 r = a2.getAndCAS(expect2, this);
                 if (r instanceof RDCSSDescriptor)
                     ((RDCSSDescriptor)r).complete();
             } while (r instanceof RDCSSDescriptor);
             if (r == expect2) complete();
             return r;
         }

         void complete() {
             if (a1.value == expect1) a2.CAS(this, update2);
             else a2.CAS(this.expect2);
         }
     }

     enum Status {
         UNDECINED, SUCCEEDED, FAILED
     }

     class CASNDescriptor {
         private final DataReference status =
             new DataReference(Status.UNDECINED);
         private final CASEntry[] entries;

         // надо гарантировать одинаковый порядок обработки
         // DataReference каждым CASN, их надо как-то упорядочить
         CASNDescriptor(CASEntry[] entries) {
             this.entries = entries;
             Arrays.sort(this.entries);
         }

         boolean complete() {
             if (status.value == Status.UNDECINED) {
                 Status newStatus = Status.SUCCEEDED;
                 for (int i = 0; i < entries.length;) {
                     CASEntry entry = entries[i];
                     // AQUIRE ENTRY
                     Object val = new RDCSSDescriptor(this.status,
                                                      Status.UNDECIDED,
                                                      entry.a,
                                                      entry.expect,
                                                      this).invoke();
                     // AQUIRE ENTRY END

                     if (val instanceof CASNDescriptor) {
                         if (val != this) {
                             ((CASNDescriptor)val).complete();
                             continue; // retry this entry
                         }
                     } else if (val != entry.expect) {
                         newStatus = Status.FAILED;
                         break;
                     }
                     i++; // go to next entry
                 }
                 this.status.CAS(Status.UNDECIDED, newStatus);
             }
             boolean succeeded = status.value == Status.SUCCEEDED;
             for (CASEntry entry : entries) {
                 // RELEASE
                 entry.a.CAS(this, succeeded ? entry.update : entry.expect);
             }
             return succeeded;
         }
     }

     public class DataReference<T> {
         // хранимое значение
         volatile Object value;

         private static final
           AtomicReferenceFieldUpdater<DataReference, Object>
             VALUE_UPDATER =
               AtomicReferenceFieldUpdater.newUpdater(
                 DataReference.class, Object.class, "value");

         boolean CAS(Object expect, Object update) {
             return VALUE_UPDATER.compareAndSet(this, expect, update);
         }

         Object getAndCAS(Object expect, Object update) {
             do {
                 Object curval = value;
                 if (curval != expect) return curval;
             } while (!CAS(expect, update));
             return expect;
         }

         public T get() {
             while (true) {
                 Object curval = value;
                 if (curval instanceof RDCSSDescriptor) {
                     ((RDCSSDescriptor)curval).complete();
                     continue;
                 }
                 if (curval instanceof CASNDescriptor) {
                     ((CASNDescriptor)curval).complete();
                     continue; // retry
                 }
                 return (T)curval;
             }
         }

         public T get();
         public static boolean CASN(CASEntry... entries);
     }
   #+END_SRC
** Сложные блокировки
   Проведем анализ *конфликтов* (/data race/) -- два
   несинхронизированных доступа к одной ячейке данных, один из которых
   запись.

   *Матрица конфликтов* (для регистра) -- какие методы конфликтуют:
   |---+---+---|
   |   | R | W |
   |---+---+---|
   | R |   | × |
   |---+---+---|
   | W | × | × |
   |---+---+---|

   Подход этой матрицы позволяет чисто автоматизированно составить
   матрицу для сложной структуры с большим количеством методов.

   Можно тривиально убрать конфликты с помощью грубой блокировки на
   каждом конфликтующем методе.
   С другой стороны, жиненная ситуация -- после грубой блокировки
   некоторые методы могут работать одновременно (к примеру только
   читающие методы).

   Эту проблему решают read-write locks. Можем создать класс, который
   умеет лочиться по ~read~ или по ~write~. Такой класс будет принимать
   сколько угодно локов по ~read~, но остальные не будут совместимы.

   Другое решение -- делать структуру данных, используя тонкую
   блокировку. Например, с помощью CASN.

   Как сделать линеаризуемый многопоточный объект?
   1. Блокировки (aka synchronized): грубая, тонкая, ..., read-write.
   2. Без блокировки
      1. Универсальная конструкция (Copy-on-write + CAS, частичное
         копирование + CAS).
      2. CASN.
      3. Специфичные для структуры алгоритмы.

   Проблемы блокировки:
   1. В системе нет прогресса, пока объект заблокирован.
   2. Требуются дополнительные переключения контекста чтобы дать
      закончить работу блокирующему потоку. Это может сильно жрать
      CPU.
   3. Минимальный параллелизм работы, причем параллелизм обратно
      пропорционален количеству блокировок.
   4. Deadlocks.
** STM
   Как делать сложные вещи и не думать? STM!  Типа навешиваем какие-то
   вещи на кусок кода, и он выполняется атомарно. Такое есть, например,
   в Clojure. И в хаскеле тоже есть! Проблема -- оно работает медленно
   и поэтому не подходит для плюсов/джавы.

   #+NAME: Чего хочется от STM
   #+BEGIN_SRC java
     public class Employees {
         Set working = new ConcurrentSet();
         Set vacating = new ConcurrentSet();

         // псевдокод
         public boolean contains(Employee e) {
             atomic {
                 return working.contains(e) ||
                     vaccating.contains(e);
             }
         }

         public void startVacation(Employee e) {
             atomic {
                 working.remove(e);
                 vacating.add(e);
             }
         }
     }
   #+END_SRC

   Будем писать класс транзакций и класс переменной для транзакции.
*** Транзакции с блокировкой:
    * Можно двухфазовой блокировкой. Все конфликтующие блокировки
      защищаются локами, в начале транзакции локи накапливаются, в
      конце отпускаются.
    * Тогда любое исполнение такой системы будет линеаризуемо
    #+NAME: Реализация транзакций с блокировкой
    #+BEGIN_SRC java
      public class Transaction {
          private static final ThreadLocal<Transaction> CURRENT =
              new ThreadLocal<Transaction>();

          private final List<Lock> locks = new ArrayList<Lock>();

          private final Set<TVar<?>> writes = new HashSet<TVar<?>>();

          public void addWrite(TVar<?> var) {
              writes.add(var);
          }

          void addLock(Lock lock) { locks.add(lock); }

          // commit с блокировкой
          public boolean commit() {
              for (Lock lock : locks) lock.unlock();
              return true;
          }

          public void rollback() {
              for (TVar<?> var : writes) var.rollback();
              for (Lock lock : locks) lock.unlock();
          }

          public static Transaction beginTransaction() {
              Transaction t = new Transaction();
              CURRENT.set(t);
              return t;
          }

          public static Transaction currentTransaction() {
              return CURRENT.get();
          }

          public static <R> R atomic(AtomicBlock<R> call) {
              for (;;) {
                  Transacion t = beginTransaction();
                  try {
                      R result = call.call();
                      if (t.commit()) return result;
                  } catch (RuntimeException | Error e) {
                      t.rollback();
                      throw e;
                  }
              }
          }
      }

      public class TVar<T> {
          private T value;
          private final ReadWriteLock lock =
              new ReentrantReadWriteLock();

          // для rollback в Transaction
          private static final Object UNDEFINED = new Object();
          private Object oldValue = UNDEFINED;

          public T get() {
              lock.readLock().lock();
              Transaction.currentTransaction().addLock(lock.readLock());
              return value;
          }

          public void set(T value) {
              if (oldValue = UNDEFINED) {
                  lock.writeLock().lock();
                  this.oldValue = this.value;
                  Transaction.currentTransaction().addWrite(this);
              }
              this.value = value;
          }

          void rollback() {
              value = (T)oldValue;
              oldValue = UNDEFINED;
              lock.writeLock().unlock();
          }
      }
    #+END_SRC
*** Транзакции без блокировки
    Предоставим реализацию без помех. Разные потоки могут бесконечно
    долго мешать друг другу закончить транзакцию без прогресса, но если
    активен только один поток, то прогресс гарантирован.

    Проблематика -- даже читающие транзакции конфликтуют.  В этом
    смысле решение с блокировкой лучше.

    #+NAME: Реализация транзакции с блокировкой (obstruction-free)
    #+BEGIN_SRC java
      public class Transaction {
          private static final int ACTIVE = 0;
          private static final int COMITED = 1;
          private static final int ABORTED = -1;
          private final AtomicInteger state = new AtomicInteger(ACTIVE);

          public boolean isCommited() {
              return state.get() == COMMITED;
          }
          public boolean commit() {
              return state.compareAndSet(ACTIVE, COMMITED);
          }
          public void rollback() {
              state.compareAndSet(ACTIVE, ABORTED);
          }
          class VarHolder<T> {
              final Transaction owner;
              final Object value;
              Object newValue; // updated by owner

              VarHolder(Transaction owner, Object value) {
                  this.owner = owner;
                  this.value = value;
                  this.newValue = value;
              }

              // текущее значение зависит от состояния владельца
              T current() {
                  return owner.isCommited() ? (T)newValue : (T)value;
              }
          }
      }

      public class TVar<T> {
          private AtomicReference<VarHolder<T>> holder =
              new AtomicReference<VarHolder<T>>();

          public T get() {
              return (T)open().newValue;
          }

          public void set(T value) {
              open().newValue = value;
          }

          // переменную нужно открыть перед любым доступом
          VarHolder<T> open() {
              Transaction tx = Transaction.current();
              VarHolder<T> old, upd;
              do {
                  old = holder.get();
                  if (old.owner == tx) return old;
                  old.owner.rollback(); // если активен
                  upd = new VarHolder<T>(tx, old.current());
              } while (!holder.compareAndSet(old, upd));
              return upd
          }
      }

    #+END_SRC

    Параллельно читать можно, для этого необходимо в ~TVar~ при чтении
    не открывать переменную. Значение тогда сможет поменяться в
    процессе транзакции, и линеаризуемость пропадает.

    Решить это можно с помощью пост-проверки транзакции на
    корректность. Или с помощью многоверсионного контроля корректности.
** Мониторы и локи
   Представим операцию как функцию над парой из состояния и
   аргументов. Раньше мы рассматривали функции тлоько всюду
   определенные.

   Возьмем блокирующую очередь. Пусть ~put~ кладет только, если есть
   место. Если нету, то она зависает, то есть put частично
   определена. Аналогично предтсавим себе take, который может
   вытаскивать элемент из очереди только, если очередь не пуста. Будем
   поддерживать, с другой стороны, и не блокирующиеся операции -- ~size~,
   ~offer~, ~poll~ (возвращает ~null~ если пуста).

   Примечание: тут блокировка обозначает нечто другое -- определенность
   функции.

   Тут нужно переопределить линеаризуемость и исполнение:
   1. $inv(A)$ -- это вызов, но не всегда есть $resp(A)$. $A$ называется
      незавершенной операцией, а $inv(A)$ незавершенным вызовом.
   2. Исполнение линеаризуемо, если в исполнении можно:
      * Добавить такие ответы для незавершенных вызовов.
      * Выкинуть остальные незавершенные вызовы.
      * Можно упорядочить, получить допустимое последовательное
        исполнение: \[inv(A₁) → resp(A₁) → ⋯ \]

   *Монитор* -- это пара из mutex'а и набора условных переменных:
   1. Взаимное исключение для защиты данных от одновременного изменения.
   2. Условные переменные для ожидания.
   3. Придумано Энтони Хоаром.

   В java каждый объект имеет монитор с одной условной переменной:
   * ~synchronized == monitorenter + monitorexit.~
   * ~wait~, ~notify~, ~notifyAll~ -- для работы с условной переменной.

   Что такое wait?
   * Может выходить из критической секции (монитора), чтобы другие
     потоки могли в нее попасть и поменять состояние объекта
   * Дожидается сигнала через условную переменную.
   * Снова входит в критическую секцию (в монитор), чтобы этот поток
     мог перепроверить состояние объекта и выполнить свою операцию если
     состояние подходящее.
   * Сигнал посылается через ~notify~ (сигнал одному ждущему потоку),
     ~notifyAll~ (сигнал всем ждущим потокам).

   #+NAME: Пример очереди в java
   #+BEGIN_SRC java
     public class BlockingQueue<T> {
         private final T[] items;
         private final int n;
         private int head;
         private tail;

         public synchronized int size() {
             return (tail - head + n) % n;
         }

         // Если очередь пуста, возвращает null
         // полностью определен в любом состоянии
         public synchronized T poll0 {
             if (head == tail) return null;
             T result = items[head];
             items[head] = null;
             head = (head + 1) % n;
             return result;
         }

         // не определен для пустой очереди
         // Если очередь пуста -- ждет. Кидает exception == может блокироваться.
         // Цикл зачем? См. Object.wait: spurious wakeups are possible...
         public synchronized T poll throws Interruptedexception {
             while (head == tail) wait(); // критическая разница
             T result = items[head];
             items[head] = null;
             if ((tail + 1) % n == head) notifyAll(); // очередь была полна
             head = (head + 1) % n;
             return result;
         }

         // Сам метод не блокируется, но будит потоки, которые ждут
         // пока очередь станет не пуста
         // Нужно будить другие потоки, только если действительно
         // очередь становится не пуста.
         // Сигнал пойдет только после выхода из монитора (критической секции).
         public synchronized boolean offer(T item) {
             int next = (tail + 1) % n;
             if (next == head) return false;
             items[tail] = item;
             if (head == tail) notifyAll();
             tail = next;
         }

         // ждет пока очередь не полна и будет потоки, которые могут ждать пока
         // очередь станет не пуста
         public synchronized void put(T item) throws Interruptedexception {
             while (true) {
                 int next = (tail + 1) % n;
                 if (next == head) { wait(); continue; }
                 items[tail] = item;
                 if (head == tail) notifyAll();
                 tail = next;
                 return;
             }
         }

         // в методе take тоже нужно пытаться будить put, когда мы забрали последний
         // элемент
     }
   #+END_SRC

   Рассмотрим еще раз разницу ~notify~ и ~notifyAll~:
   * Нам нужно было использовать одну условную пееменную для двух
     условий: очередь не пуста и очередь не полна, поэтому пользуемся
     ~notifyAll~.
   * Если бы для каждого условия использовалась бы отдельная
     переменная, ~notify~ было бы достаточно. Но у java есть только
     одна условная переменная на каждый монитор.

   ~j.u.c.ReentrantLock~ спасает! Там есть методы всякие, которые
   предоставляет интерфейс ~Condition~ с методами ~await~, ~signal~,
   ~signalAll~. Можно таким образом сделать эффективным ~take~, в котом мы
   делаем все то же самое, что с интерфейсом ~wait/notify~, но на локе и
   методами с похожими названиями. Но тут можно сделать два condition'а
   и делать на каждом ~signal~, а не ~signalAll~.

   У каждого потока есть флаг ~interrupted~.
   1. Его ставит метод ~Thread.interrupt~.
   2. Его проверяют методы ~wait~, ~await~ и так далее.
   3. В случае обнаружения выставленного эти методы:
      * Прекращают ждать.
      * Сбрасывают флаг.
      * Кидают ~InterruptedException~.

   Что делать с ненужным ~InterruptedException~? Если нужно
   реализовывать метод, который ждет, но не кидает
   ~InterruptedException~, то ~interrupted~ флаг надо
   перевыставить. Тогда ожидание можно прерывать через
   ~Thread.interrupt~.

   Частая ошибка в ббилиотеках -- забыли перевыставить ~interrupted~
   флаг.

   #+BEGIN_SRC java
     // возвращает null если прервали InterruptedException
     public T takeOrNull() {
         try {
             return take();
         } catch (InterruptedException e) {
             // перевыставим флаг interrupted
             Thread.currentThread().interrupt();
             return null;
         }
     }
   #+END_SRC

   Пишем поток, обрабатывающий очередь.
   1. Заводим свой флаг, сигнализирующий что поток надо остановить. В
      отличии от флага ~interrupted~, нет риска что какой-то сторонний
      метод его случайно сбросит.
   2. для прерывания ожиданий нужен ~Thread.interrupt()~. *НИКОГДА* не
      пользоваться ~Thread.stop()~.

   Главный метод: метод run выполняется в отдельном потоке. Метод run
   выходит в случае прерывания.
** SPSC очередь без блокировок и конвейер
   Есть задачи и последовательные действия. $A₁...Aₙ$ (типа посчитать
   что-нибудь, преобразовать ответ, запаковать, записать в файл,..).

   Пусть время выполнения действия $Aᵢ$ равно $tᵢ$. Тогда общее время
   на задачу равно $∑tᵢ$. Один поток в единицу времени выполняет
   $\frac{1}{∑tᵢ}$ задач.

   Для увеличения пропускной способности сделаем конвейер на $n$
   потоках.

   Структура SPSC очереди.

   Не блокирующийся ~offer~: пишем без блокировок, поэтому важен порядок
   действий и точки линеаризации операций.
   CAS не нужен, только один producer меняет ~tail~. Ожиданием займемся позже.
   #+BEGIN_SRC java
     public boolean offer(T item) {
         // читаем один раз tail (только мы его меняем)
         int tail = this.tail;
         // здесь volatile чтение head (его меняет consumer)
         if (((tail+1) & mask) == head) return false; // полна
         items[tail] = item;
         // в самом конце передвинем tail
         this.tail = (tail + 1) & mask; // volatile write
         //        ^ это точка линеаризации операции offer
         return true;
     }
   #+END_SRC

   * ~LockSupport.park~ усыпляет текущий поток до тех пор:
     * Пока другой поток не вызовет ~unpark~
     * Что-то еще...
   * ~LockSupport.unpark~ делает ???

   Вот ~offer~ с ~unpark~:
   #+BEGIN_SRC java
     public boolean offer(T item) {
         int tail = this.tail;
         if (((tail+1) & mask) == head) return false; // полна
         items[tail] = item;
         this.tail = (tail + 1) & mask; // volatile write
         LockSupport.unpark(consumer); // разбудить ждущего потребителя
         return true;
     }
   #+END_SRC

   #+BEGIN_SRC java
     public T take() throws InterruptedException {
         // это поможет при отладке
         assert Thread.currentThread() == consumer;
         // читаем один раз head
         int head = this.head; // volatile read
         while (true) {
             if (Thread.interrupted()) throw new InterruptedException();
             // здесь volatile чтение tail ( его меняет producer)
             if (head == tail) { LockSupport.park(); continue; }
             T result = items[head];
             items[head] = null;
             this.head = (head + 1) & mask;
             LockSupport.unpark(producer);
             return result;
         }
     }
   #+END_SRC

   Блокирующийся ~take~ -- разбор:
   * Нужен цикл ожидания (park может проснуться сам).
   * Нужно избежать ухода в бесконечный цикл.

   Блокирующийся ~take~ -- оптимальный ~unpark~.
   #+BEGIN_SRC java
     public T take() throws InterruptedException {
         // это поможет при отладке
         assert Thread.currentThread() == consumer;
         // читаем один раз head
         int head = this.head; // volatile read
         while (true) {
             if (Thread.interrupted()) throw new InterruptedException();
             // здесь volatile чтение tail ( его меняет producer)
             if (head == tail) { LockSupport.park(); continue; }
             T result = items[head];
             items[head] = null;
             this.head = (head + 1) & mask; // volatile write
             //        ^ это точка линеаризации операции take
             // если очередь была полна до операции (producer мог спать)
             if (((takl + 1) & mask) == head) LockSuppor.unpark(producer);
             return result;
         }
     }
   #+END_SRC

   * Все остальные операции аналогично.
   * Оптимизации SPSC очереди.
     * Блочная работа - можно доставать сразу несколько задач.
     * Обобщается на конвейер из n потоков.
       * $n$ потоков, работающие в конвейере, будут использовать общий
         циклический буфер.
       * Кладем задачу в буфер первым действием
       * Удалем задачу из буфера последним действием
       * У каждого потока есть свой ~index~ в буфере, а с $n = 2$ было
         ~tail == producer index, head == consumer index~.
       * Каждый поток работает над задачами до ~index~ предыдущего потока
         в конвейере и следит, чтобы не упереться в следующий.

   Практические наблюдения про конвейеры:
   * *Конвейер* (/pipeline/) имеет смысл, если отдельные действия по
     задаче примерно равны по продолжительности
   * Есть накладный расход на организацию. На быстрых действиях не выгодно.
   * Накладной расход на задачу можно уменьшить, обрабатывая элемениты
     пачками (/batching/).
   * Конвейер повышает *пропускную способность* (/throughput/) принося
     в жертву *задержку* (/latency/) -- время обработки одной задачи от
     начала до конца.
* Распределенные системы
** Вступление
   #+DATE: 2016-02-15
   Чем отличается курс от предыдущего? Типа будем изучать модели,
   которые обмениваются сообщениями. Это можно сэмулировать на том,
   что мы проходили в предыдущем курсе, но это неэффективно. А хочется
   быстро, типа как в ~NUMA~ там или вот эти все ~MOESI~ (но
   когерентные кеши -- это параллельная система, а не распределенная).

   Все короче распределенное в eтом мире поетому предмет оче важный и
   интересный! XХДДDDddDD)))

   Система масштабируется вертикально, если мы даем ей больше ядер и
   она быстрее работает. Система масштабируется горизонтально, если
   от большего количества машин становится лучше.

   Важные отличия распределенных систем:
   1. Нельзя полагаться на общее время или общее состояние системы --
      оно постоянно меняется.
   2. Географически распределена.
   3. Обмен сообщениями, а не общая память.
   4. Может отказать частично.
   5. Больше надежность, сложно кодить, меньше стоит.

   Модель:
   * Проессы $P,Q,R ... ∈ ℙ$
   * События $a,b,c,d,e... ∈ E$, в процессах $proc(e) ∈ P$.
   * Сообщения $m ∈ M$, события посылки/приема $snd(m),rev(m) ∈ E$.
   * Произошло-до между событиями ($→$):
     * Минимальный строгий частичный порядок, что
       * если $e$ и $f$ произошли в одном процессе и $e < f$ (e шло перед
         f), то $e → f$.
       * если $m$ сообщение, то $snd(m) → rcv(m)$.
     * Другими словами -- транзитивное замыкание порядка событий на
       процессе и посылке/приема сообщений.

   Графическая нотация -- параллельные горизонтальные линии как
   потоки, стрелочки между узлами на них как передчи сообщений, вот
   ето все.

   Логические часы: для каждого события e определим число $C(e)$ так,
   что: $∀e,f ∈ E:e → f ⇒ C(e) < C(f)$.

   Такая функция $C$ называется логичксеими часами. В обратную сторону
   отношение не верно и не может быть, потому что порядок на числах
   полный, а произошло-до -- частичный.

   *Логические часы Лампорта*: время это целое число $C$ в каждом
   процессе.

   Алогоритм:
   * Перед каждой посылкой увеличивает $C$ на единицу.
   * При посылке сообщения процесс посылает свое время $C$.
   * При приеме сообщения делаем $C := max(received_C, C) + 1$.

   Очевидно логические часы Лампорта являются логическими часами.
   События в одинаковое логическое время параллельны.

   *Векторные часы*: для каждого события e определим вектор $VC(e)$ так,
   что $∀e,f ∈ E: e → f ⇔  VC(e) < VC(f)$.

   Сравнение векторов происходит покомпонентно (не лексикографически).
   Такая функция будет называтеся векторными часами.

   Алгоритм векторного времени: время это целочисленный вектор
   $VC$. Будем по посылке инкрементировать, по посылке отправлять, а при
   приеме делаем покомпонентно $VC: = max(received_VC, VC)$.

   При этом важно: $∀e,f ∈ E: proc(e) = Pᵢ, proc(f) = Pⱼ : e → f ⇔
   (VC(E)ᵢ,VC(E)ⱼ) < (VC(f)ᵢ, VC(f)ⱼ)$. Типа хватает только двух
   сравнений. Если процессы параллельны, то вектора будут несравнимы.

   *Часы с прямой зависимостью* (/direct dependency/): храним вектор, а
   посылает только одно число: $∀e,f ∈ E: e →_d f ⇔ VC_d(e) <
   VC_d(f)$, где $e →_d f ⇔ e < f ∨ ∃m ∈ M: e ≤ snd(m) ∧ rcv(m) ≤ f$.

   Формально это комбинация Лампорта и векторного.

   *Матричные часы*: храним матрицу, посылаем тоже матрицу.

   Взаимное исключение в распределенных системах:
   1. Критическая секция $CSᵢ$ состоит из двух событий:
      * $Enter(CSᵢ)$ -- вход
      * $Exit(CSᵢ)$ -- выход
      * $i$ -- порядковый номер захода в критическую секцию
   2. Основное требование: *взаимное исключение*: два процесса не
      должны быть в критической секции одновременно, то есть $Exit(CSᵢ)
      → Enter(CSᵢ₊₁)$.

   Также в системах с общей памятью нужны доп требования /прогресса/:
   * Минимальное требование -- каждое желание процесса попасть в
     критическую секцию будет рано или поздно удовлетворено.
   * Также может быть гарантирован тот или иной уровень честности
     удовлетворения желаний процессов о входе в крит. секцию.

   Централизованный алгоритм:
   * Выделенный координатор
   * Три типа сообщений:
     * ~req[uest]~ -- от запрашиваающего процесса координатору
     * ~ok~ -- от координатора
     * ~rel[ease]~ -- после выхода из критической секции
   * Требует 3 сообщения на критическую секцию независимо от
     количества участвующих процессов
   * Не масштабируется из-за необходимости иметь выделенного
     координатора.

   Подход шаринга -- это короче сделать несколько координаторов и
   пользоваться ими. Но это не решает проблему надежности -- если
   падает один координатор, то его часть данных, за которую он
   отвечает, становится недоступна.

   Алгоритмы взаимного исключения (хотим что-то делать в критической
   секции):
   * Алгоритм Лампорта ($3N-3$ сообщения).

     Устроен как централизованый, но на основе логических
     часов.

     Каждый процесс хранит очередь всех билетиков на запрос.

     Каждый процесс посылает ~req~ всем другим процессам. Процесс,
     принимающий ~req~ делает следующее: если он принимает два ~req~ с
     одинаковыми часами, то упорядочиваем их по номеру
     процесса. Первому запросу отвечают ~ok~ с меткой времени.

     Когда процесс получает ~ok~ от всех, то он входит в критическую
     секцию, если его запрос всем остальным был сделан раньше. Типа
     отправил раньше чем все другие обработали.

     После выхода из критической секции посылается ~rel~.

     Этот алгоритм сильно основан на FIFO: любые два сообщения от
     одного потока другому должны придти в порядке отправления.
   * Алгоритм Рикарда и Агравалы ($2N-2$ сообщения)

     Модификация алгоритма Лампорта: давайте не будем отсылать ~ack~
     на ~req~ если мы работаем в критической секции. Объединим
     acknowledge и release.
   * Алгоритм обедающих философов (от $0$ до $2N-2$ сообщений)
     Проблема предыдущих алгоритмов в том, что они посылают сообщения
     потокам, которые потенциально могут вообще не хотеть войти в
     критическую секцию.

     Пусть есть $n$ процессов и между соседними есть какие-то
     конфликты памяти (в задаче философов граф конфликтов -- колесо, а
     в общем случае граф может быть любым). Ориентируем граф
     конфликтов так, чтобы в нем не оказалось циклов. Если нет
     входящих ребер (мы -- исток), тогда будем брать ресурсы. После
     использования ресурсов все исходящие ребра перевернем. Две
     теоремы из теории графов: в графе без циклов можно истоки вот так
     менять и циклов не образуется; в графе без циклов есть исток.

     Ресурсы могут быть чистыми и грязными. Задача -- собрать все
     чистые ресурсы. Грязные ресурсы получаются после
     использования. Если приходит запрос на грязный ресурс, мы его
     чистим и отдаем.

     Как инициализировать граф? У потоков есть идентификаторы. Можно
     посортить с помощью них -- граф отсортированный таким образом не
     будет иметь циклов.

     Можно решить эту задачу и рандомно -- хватать какие-то ресурсы,
     если не получилось, отдаем и ждем какое-то рандомное количество
     времени.
   * Алгоритм на основе токена

     Работает в системах, где связь кольцевая. Процесс будет выполнять
     критическую секцию только когда у него есть токен. После
     использования токена или если делать ничего не нужно, токен
     отправляется по кольцу дальше.

     Как раз ethernet работает как рандомизированные философы с полным
     графом, а token ring вот делал кольцевую передачу данных,
     отцепляя от информации ту, которая нужна конкретно одному
     компуктеру.
   * Алгоритмы на основе кворума.

     Будем спрашивать только подмножество процессов. Кворум: $Q ⊂ 2ᵖ$:
     $∀A,B ∈ Q: A∩B ≠ ∅$. Надмножество кворума -- это тоже кворум.

     * Централизованный кворум -- один пека.
     * Простое большинство и взвешенное большинство.
     * Рушащиеся стены.
** Глобальные состояния и срезы
   Хотим уметь запоминать состояние распределенной системы, чтобы
   можно было ее восстановить в случае каких-либо проблем.

   * *Срез* -- такое $G ⊂ E$, что $∀f ∈ G, e ∈ E, e < f ⇒ e ∈ G$.
   * *Согласованный срез* -- срез $G$, что $∀f ∈ G, e ∈ E: e → f ⇒ e ∈
     G$.

   [[http://neerc.ifmo.ru/wiki/index.php?title=Алгоритм_Чанди-Лампорта][Алгоритм Чанди Лампорта на neerc.ifmo.ru]]

   Алгоритм Чанди-Лампорта для согласованного запоминания глобального
   состояния системы (получения согласованного среза):
   1. Есть инициатор, который запоминает свое состояние, посылает
      токен всем соседям.
   2. При получении токена /первый раз/ процесс запоминает свое
      состояние и посылает токен соседям.
   3. Запомненные состояния образуют согласованный срез, если
      сообщения между процессами идут FIFO.
   4. Чтобы восстановить работу системы из запомненного состояния
      (checkpoint) надо еще запоминать сообщения в пути.

      Запоминание сообщений: нужно запомнить все сообзщения $m$ такие
      что $snd(m) ∈ G ∧ rcv (m) ∈ E \ G$. варианты реализации --
      запоминание на стороне получателя или отправителя.

   Глобальные свойства:
   * Стабильные предикаты
     * Берем согласованные срезы; если предикат верен, то будет верен
       и в дальнейшем. С другой стороны, строить согласованный срез
       дорого -- $O(n²)$ сообщений.
     * Пример -- потеря токена, взаимная блокировка,..
   * Нестабильные предикаты
     * Локальный предикат -- предикат по состоянию одного процесса.
     * Если предикат есть дизъюнкция локальных предикатов, то
       вычисление легко.
     * С конъюнкцией все неочевидно -- как найти правильный срез?

   Если предикат $P$ имеет вид конъюнкции локальных предикатов над
   состоянием каждого процесса: $P = L₁∧L₂∧...∧Lₙ$. Как пример
   предиката -- "в системе нет координатора", причем локальное условие
   -- "я не координатор".

   Будем говорить, что слабый конъюктивный предикат истинен, если он
   истинен хотя бы на одном согласованном срезе.

   Сложные предикаты, являющиеся логической комбинацией локальных
   предикатов, всегда можно представить в нормальной дизъюнктивной
   форме и рассматривать как дизъюнкцию слабых конъюнктивных
   предикатов.

   Слабый конъюнктивный предикат: централизованный алгоритм.
   * Каждый работающий процесс отслеживает свое векторное время $VC$.
   * При наступлении истинности локального предиката $L$ увеличиваем
     свою компоненту, посылаем сообщение координатору $C$, указывая
     векторное время когда это произошло.
   * Любой срез итого задается вектором.
     * Координатор поддерживает в памяти /срез-координат/ и очередь
       необработанных сообщений от каждого процесса.
     * Срез координат согласован тогда и только тогда когда все
       соответствующие вектора попарно несравнимы.
   * Координатор хранит вектора среза-кандидата и флажок для каждой
     его компоненты: красный -- этот элемент не может быть частью
     согласованного среза, зеленый -- может.
   * Начальное состояние -- все по нулям, красные.
   * Обрабатываем приходящие сообщения только от красных процессов,
     сообщения от зеленых ставим в очередь.
     * Сравниваем пришедший вектор попарно с другими процессами, если
       новый вектор больше, то делаем меньший вектор красным.
     * После обработки сообщения делаем процесс зеленым.
   * Если все зеленое, то мы нашли согласованный срез.
