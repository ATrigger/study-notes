#+TITLE: Конспект по ПП от Елизарова

* Какие-то материалы:
  https://www.slideshare.net/secret/6dv9wtl1pDOTgu
  https://www.slideshare.net/secret/h3wT59xRPciKM6
  https://www.slideshare.net/secret/yDV9vtRs61gEdg

  https://www.slideshare.net/secret/E1asIyWYNfvkNv
  https://www.slideshare.net/secret/LnSxMJ7JZ25JFe
  Консенсус:
  https://www.slideshare.net/secret/LnSxMJ7JZ25JFe
  Реализация ссылочных структуры:
  https://www.slideshare.net/secret/zrtgOfnRQY6K0Z
  Массивы, CASN, R/W Locks, STM:
  https://www.slideshare.net/secret/8ZkekdbzRSIjsP

  Рекомендуемые учебники: · The Art of Multiprocessor Programming,
  Maurice Herlihy, Nir Shavit,
  http://www.amazon.com/The-Multiprocessor-Programming-..  Это
  основной учебник для осеннего семестра. Его надо знать и любить.

  · Concurrent and Distributed Computing in Java, Vijay K. Garg,
  http://www.amazon.com/Concurrent-Distributed-Computin..  Обзор для
  всех частей курса (пригодится так же и для второго семестра).
* Вступление, модели, их свойства, согласованность
  #+DATE: 07.09.2015
  SMP (symmetric multiprocessing) -- два или больше ядра, на каждом по
  потоку.
  SMT (simultaneous multithreading) -- два или больше потоков
  исполняются одним ядром.
  NUMA -- not uniform memory access (все знают, что это еще с 1
  курса)

  Операционные системы (классификация по параллельности):
  1. Однозадачные
  2. Пакетные задания (batch processing)
  3. Многозадачные
     1. Кооперативная (cooperative) многозадачность
        Переход от одной задачи к другой происходит явно, когда
        программа готова передать процессорное время другой.
     2. Вытесняющая (preemptive) многозадачность
        Текущий подвид -- ОС сама расставляет инструкции как ей этого
        хочется.

  Поток и процесс (на практике вперемешку):
  * Процесс -- владеет памятью и ресурсами
  * Поток -- контекст исполнения внутри процесса.

  Модели программирования:
  1. Однопоточное/однозадачное
  2. Многозадачное
     1. Модель с общей памятью
        Единственное, что объединяет потоки -- общие объекты.
        Общий объект -- переменная (read/write, тип). Иногда зовутся
        регистрами, так как на практике значения лежат как раз в
        регистрах ЦП.
     2. Модель с передачей сообщений

  Модели исполнения:
  1. Модель чередований
     Строим дерево, в котором описываем все возможные перестановки
     операций над общими объектами. Такая модель не описывает
     появление пары (0, 0) в следующем примере:
     #+NAME: java no-volatile
     #+BEGIN_SRC text
       thread P {
              x = 1
              r1 = y
       }
       thread Q {
              y = 1
              r2 = x
       }
     #+END_SRC
     Но оно может появиться вследствие того факта, что компилятор
     может переставить инструкции или же просто запись обоих значений
     будет отложена процессором.
     Модель чередования не описывает конкретно физических реалий этого
     мира -- ведь свет за один такт процессора проходит 10см, элементы
     просто физически не могут синхронизоваться.
     Физическая -- это световой конус.
  2. Happens before
     Исполнение системы -- пара <H,→>
     * H -- множество операций (чтение и запись ячеек памяти)
     * e → f значит, что e произошло раньше f -- частичный строгий
       порядок на H
     * a ∥ b, если ¬(a → b | b → a)
  3. Модель глобального времени
     Каждая операция -- интервал [t_inv, t_resp], и если выражать
     через happens-before, то
     a → b ≡ t_resp(a) < t_inv(b)

  Конфликты:
  * Конфликт (data race) -- ситуация, когда происходит две
    параллельных операции, и одна из них -- запись.
  * Корректно синхронизированная программа -- программа без
    конфликтов.

  Исполнения:
  1. Последовательное -- все операции линейно упорядочены отношением
     happens-before (→). В модели глобального времени ничего не
     наслаивается вообще.
  2. Правильное -- сужение исполнения на один поток (только операции,
     приналежащие конкретному потоку) последовательно.
     Неправильные исполнения -- вообще какая-то чепуха (параллельность
     в одном потоке). Или a = (b++) + (c++) в плюсах.
  3. Допустимое последовательное исполнение -- выполнены
     последовательные спецификации всех объектов.
     Посл. спецификация объекта -- последовательность сужения
     исполнения на конкретный объект.

  Условия согласованности:
  1. Последовательная согласованность
     Исполнение посл. согласованно, если можно сопоставить ему
     допустимое последовательное исполнение, причем программный
     порядок (≡ порядок операций на каждом потоке) сохраняется.

     Кстати последовательная согласованность на каждом объекте не
     влечет за собой последовательную согласованность исполнения.
  2. Линеаризуемость
     Исполнение линеаризуемо, если можно сопоставить ему
     допустимое последовательное исполнение, которое сохраняет порядок
     happens-before.

     Линеаризуемость локальна, линеаризуемость на каждом объекте
     влечет линеаризуемость системы.
     Операции над линеаризуемыми объектами называют атомарными.
     Исполнение системы, выполняющее операции над линеаризуемыми
     объектами, можно анализировать в модели чередования.
     Свойство thread-safe объекта есть ровно линеаризуемость.

     Если в примере java-novolatile сделать x,y volatile, то пара
     (0,0) не будет появляться, то есть исполнение действительно
     соответствует модели чередования.

     Реализуется volatile в java локами памяти (memory lock). Тут мы
     немного теряем производительность, но не страшно.
* Блокировки, взаимное исключение, deadlock'и
  #+DATE: 14.09.2015
  Линеаризуемость -- суперское свойство, тащемта.
  Даже если в каждом потоке все операции атомарны, мы не можем
  утверждать, что объект линеаризуем (ну представьте себе класс
  очереди с методами push/pop).
  Мы вот хотим линеаризуемую очередь.

  Самый простой метод сделать так -- это использование блокировок
  (locks, mutex (mutual exclusion)).
  Идея: заведем в объекте member Mutex m, будем его лочить и
  разлочивать. Этот объект будет гарантировать, что объект будет
  застрявать на .lock, если мьютекс уже залочен и т.д.
  Код с mutex'ами будет thread-safe, если операции будут защищены
  одним и тем же мьютексом.

  * Взаимное исключения -- свойство исполнения, при котором
    критические секции не могут выполняться параллельно -- это
    требование корректности взаимного исключения.

  При этом взаимное исключение имеет ряд условных условий прогресса:
    1. Свобода взаимной блокировки (deadlock-freedom) -- свойство
       взаимного исключения, при котором если несколько потоков
       пытаются войти в критическую секцию, то хотя бы один сделает
       это за конечное время (при условии что критические секции сами
       по себе конечны).
    2. Отсутствие голодания (starvation-freedom) -- если какой-то
       поток пытается войти в критическую секцию, он сделает это за
       конечное время (опять-таки, при условии, что крит. секции
       исп. за конечное время).
    3. Линейное ожидание -- каждый поток совершает O(n) действий перед
       тем, как войти в критическую секцию (условие аналогично)
    4. First Come First Served (FSFS) -- свойство сильнее линейного
       ожидания, потоки обслуживаются в порядке утыкания в критическую
       секцию (условие аналогично).

  Как написать mutex, собственно?
  1. Aлгоритм Петерсона -- гарантирует взаимное исключение, отсутствие
     взаимной блокировки и отсутствие голодания.
     Преимущество -- самый простой.
     #+BEGIN_SRC text
       threadlocal int id // 0 or 1
       shared boolean want[2]
       shared int     victim

       def lock:
           want[id] = true
           victim = id
           while (want[1-id] and victim == id) {}

       def unlock:
           want[id] = false
     #+END_SRC
  3. Aлгоритм Петерсона для N потоков (filter algorithm).
     Все то же самое, но может делать O(N²) ожидания.
     #+BEGIN_SRC text
       threadlocal int id
       shared int level[N]
       shared int victim[N]

       def lock:
           for j = 1..N-1:
               level[id] = j
               victim[j] = id
               while exist k: k != id and
                              level[k] >= j and
                              victim[j] == id:
                              {}

       def unlock:
           level[id] = 0
     #+END_SRC
  4. Алгоритм Лампорта (булочника -- 1 вариант)
     Обладает свойством FCFS. Это вариант с бесконечными метками
     label. Можно сделать с конечными.
     Первые две строки lock называются doorway.
     #+BEGIN_SRC text
       threadlocal int id
       shared boolean want[N]  // init false
       shared int     label[N] // init 0

       def lock:
           want[id] = true
           label[id] = max(label) + 1
           while exists k: k != id and
                           want[k] and
                           (label[k], k) < (label[id], id)
                           {}
     #+END_SRC

  Блокировки бывают грубыми и тонкими. Грубая -- блокировать всю
  операцию целиком. Тонкая -- блокировать операции над общими
  объектами внутри, а не вызов, но тогда необходима двухфазовая
  блокировка.

  Есть проблема deadlock'а. Допустим, что есть два mutex'а, мы лочимся
  в одном треде сначала по m1, потом по m2, в другом треде
  наоборот. Можем задедлочиться тут короче.

  Закон Амдала для параллельной работы:
  speedup = 1/(S + (1-S)/N) -- максимальное ускорение при запуске кода
  в N потоков, если доля кода S выполнена последовательно.
* Алгоритмы/объекты без блокировок, свободы (lock/wait/obstr)
  #+DATE: 21.09.2015
  Алгоритмы без блокировок.

  Безусловные условия прогресса:
  1. Obstruction-free (отсутствие помех) -- свойство алгоритма, в
     котором если остановить всe потоки кроме одного (любого) в любом
     месте, один должен завершиться за конечное время. Так должно
     работать для каждого объекта.
     Очевидно, что объект с блокировкой не имеет такого свойства.
  2. Lock-freedom -- если много потоков пытаются сделать операцию, то
     хотя бы один поток должен ее исполнить за конечное время. Плохо
     то, что это условие не исключает голодания.
  3. Wait-freedom (самое сильное условие) -- если какой-то поток
     пытается выполнить операцию, то он это сделает (вне зависимости
     от действия/бездействия других потоков).

  Объекты без блокировки.
  ОБъекты бывают с lock-freedom, но этот термин перегружен.
  * Регистры без блокировки
    * Свойства физических регистров:
      1. Неатомарны
      2. Работают без ожидания.
      3. Предполагают только одного читателя и одного писателя
      4. Попытка записать и прочитать одновременно -- UB
      5. Они безопасные (safe) -- в смысле, после записи, будет
         прочитано последнее записанное значение.
    * Классификация регистров
      1. По условиям согласованности:
         1. Безопасные (safe) -- гарантирует получение последнего
            записанного значения, если операция чтения не параллельна
            операции записи.
         2. Регулярные (regular) -- при чтении выдает последнее
            записанное, или то, что уже пишется.
         3. Атомарные (atomic) -- линеаризуемое (как регулярный,
            только если уже прочитал новое значение, то старое нельзя
            прочитать).
            Как проверить регистр на атомарность в схеме глобального
            времени -- поставить в каждой полоске точку,
            соответствующую этому конкретному действию. Порядок по
            точкам должен быть атомаррным.
      2. По количеству потоков (SR, MR, SW, MW : single/multi
         reader/writer)

    * Будем строить более сложные регистры из простых требуя
      wait-free условие.
      Пусть у нас есть Safe SRSW Boolean регистр.
      1. Regular SRSW Boolean
         #+BEGIN_SRC text
           safe shared boolean r
           threadlocal boolean last

           def write(x):
             if (x != last)
               last = x
               r = x

           def read(): return r
         #+END_SRC
      2. Regular SRSW M-Valued
         Пусть у нас массив r хранит булевые значения, и число в
         нем хранится последовательностью единиц,
         терминированной нулем. Тогда это реализуется так:

         #+BEGIN_SRC text
           regular shared boolean[M] r

           def write(x): // Справа налево
             r[x] = 0
             for i = x-1 downto 0: r[i] = 1

           def read(): // Слева направо
             for i = 0 to M-1: if r[i] == 0: return i
         #+END_SRC
      3. Atomic SRSW M-Valued
         Будем хранить пару -- значение и версию. Версию можно
         разумно ограничить. Есть алгоритм без жульничества с
         версиями, но он на практике плох.

         #+BEGIN_SRC text
           safe shared (int x, int v) r
           threadlocal (int x, int v) lastRead
           threadlocal int lastWriteV

           def write(x):
             lastWriteV++
             r = (x, lastWriteV)

           def read():
             cur = r
             if cur.v > lastRead.v:
               lastRead = cur
             return lastRead.x
         #+END_SRC

         Атомарный регистр: проблемы
         1. Версии -- могут хранить пару в регуярном, но версии
            растут неограниченно.
         2. Блокировки -- алгоритм Лампорта будет работать на
            регулярных регистрах, но это не дает алгоритм без ожидания

         Теорема: не существует алгоритма построения атомарного
         регистра без ожидания, который использует конечное число
         регулярных регистров конечного размера так, чтобы их писал
         только писатель, а читал только читатель
         * Доказательство
           Нужна обратная связь от читателя к писателю.
      4. Atomic MRSW M-Valued
         Нужно отслеживать версию записанного значения, храня пару
         (x, v) в каждом из N регистров в которые пишет писатель.
         Наивно сделать это нельзя.
         Заведем N*(N-1) регистров для общения между читателями.

         1. Каждый читатель выбирает более позднее значение из
            записанного писателем и из прочитанных значенией
            других читателей
         2. Читатель записывает свое прочитанное значение и версию для
            всех остальных читателей.
      5. Atomic MRMW M-Valued
         Нужна поддержка N писателей
         Отслеживаем версию записанного значения
         1. Каждый читатель выбирает более позднюю версию
         2. Для проставления версий писателями используем doorway
            секцию из алгоритма булочника (Лампорта)
            * Версия состоит из пары номера потока писателя и
              собственно числа
    * Атомарный снимок состояния N регистров
      Наивная реализация не обеспечивает атомарность.

      Вот этот алгоритм уже lock-free, но достаточно наивный --
      читает, пока массивы не совпадут.
      #+NAME: lock-free implementation of atomic registers snapshot
      #+BEGIN_SRC text
        shared (int x, int v) r[N]

        // wait-free
        def update(i, x):
            r[i] = (x, r[i].v + 1)

        // lock-free
        def scan():
            old = copy()
            loop:
                cur = copy()
                if forall i: cur[i].v == old[i].v
                   return cur.x  // we can get starvation here,
                                 // if update is executed too frequent
                old = cur
      #+END_SRC

      Вот wait-free реализация с костылями.
      #+NAME: wait-free implementation
      #+BEGIN_SRC text
        shared (int x, int v, int[N] s) r[N]

        def update():
            s = scan()
            r[i] = (x, r[i].v + 1, s)

        shared (int x, int v, int[N] s) r[N]

        // wait-free, O(N^2)
        def scan():
            old = copy()
            boolean updated[N]
            loop:
                cur = copy()
                for i = 0..N-1:
                    if cur[i].v != old[i].v:
                       if updated[i]: return cur.s
                       else:
                        update[i] = true
                        old = cur
                        continue loop
                return cur.x
      #+END_SRC
      * Лемма: Если значение поменялось второй раз, значит копия
        снимка s была получена вложенной операцией scan.
* Консенсус
  #+DATE: 05.10.2015

  Консенсус -- это объект, который помогает n потокам придти к общему
  мнению.
  #+BEGIN_SRC text
    class Consensus:
          def decide(val):
          ...
          return decision
  #+END_SRC

  Каждый поток использует объект Consensus один раз.
  Требуются две вещи:
  * Согласованность (consistency): все потоки должны вернуть одно и то
    же значение из метода decide.
  * Обоснованность (validity): возвращенное значение было входным
    значением какого-то из потоков.

  #+NAME: Консенсус с блокировкой
  #+BEGIN_SRC text
    shared int decision
    Mutex mutex

    def decide(val):
        mutex.lock()
        if (decision == NA):
           decision = val
        mutex.unlock()
        return decision
  #+END_SRC
  Но мы хотим без ожидания.

  Все не так просто.
  Консенсусное число:
  1. Если с помощью класса атомарных объектов С и атомарных регистров
     можно реализовать консенсусный протокол без ожидания для N
     потоков (и не больше), то говорят что у класса С консенсусное
     число равно N.
  2. Теорема:
     Атомарные регистры имеют консенсусное число 1.
     * То есть с помощью атомарных регистров даже 2 потока не могут
       придти к консенсусу без ожидания (докажем от противного) для 2х
       возможных значений при T = {0, 1}
     * С ожиданием задача решается очевидно (с помощью любого
       алгоритма взаимного исключения).
  3. Определения и леммы для любых классов объектов:
     * Определения и концепции
       1. Исходныe объекты атомарны. Любое исполнение можно
          рассматривать как последовательное в каком-то порядке.
       2. Рассматриваем дерево состояния, листья -- конечные состояния
          помеченные 0 или 1 (в зависимости от значения консенсуса).
       3. x-валентное состояние системы (x = 0,1) -- консенсус по всех
          нижестоящих листьях будет x.
       4. Бивалентное состояние -- возможен консенсус как 0 так и 1
       5. Критическое состояние -- такое бивалентное состояние, все
          дети которого одновалентны.
     * Лемма: Существует начальное бивалентное состояние
       Это нетривиально следует из того факта, что алгоритм без
       ожиданий.
       Возьмем конечное количество шагов, построим дерево
       ???
       Доказательство было на доске и не сохранилось.
     * Лемма: Существует критическое состояние
       Тоже следует из wait-free. Если есть бивалентное, будем
       смотреть его детей. Если есть хотя бы один бивалентный ребенок,
       то спускаемся в него, пока бивалентных детей больше нету.
       За счет конечности дерева такое будет существовать, и
       валентность детей будет различна (иначе валентность самого узла
       тоже определена).

     Для атомарных регистров рассмотрим возможные пары операций в
     критическом состоянии:
     * Операции над разными регистрами коммутируют.
     * Два чтения коммутируют.
     * Любая операция + запись -- состояние пишущего потока не зависит
       от порядка операций. Противоречие (в чем???)
  4. Бывают Read-Modify-Write регистры.
     #+NAME: read-modify-write reg
     #+BEGIN_SRC text
       class RMWRegister:
             private shared int reg

             def read():
                 return reg

             def getAndF(args):
                 do atomically:
                    old = reg
                    reg = F(args)(reg)
                    return old
     #+END_SRC
     Функция F может быть getAndSet, getAndIncrement,...

     #+NAME: Consensus for RMW reg, реализация для 2х потоков
     #+BEGIN_SRC text
       threadlocal int id // 0 or 1

       shared RMWRegister rmw
       shared int proposed[2]

       def decide(val):
           proposed[id] = val
           if (rmw.getAndF() == v0)
               return proposed[i]
           else:
               return proposed[1-i]
     #+END_SRC

     * Консенсусное число нетривиального RMW регистра >= 2
       Нужно чтобы была хотя бы одна подвижная точка функции F,
       например F(v0) == v1 != v0.

  5. Common2 RMW регистры
     * F1 и F2 коммутируют если F1(F2(x)) == F2(F1(x))
     * F1 перезаписывает F2 если F1(F2(x)) == F1(x)
     * Класс С RMW регистров принадлежит Common2 если любая пара
       функций либо коммутирует либо одна из функций перезаписывает
       другую.
     * Теорема: нетривиальный класс Common2 RMW регистров имеет
       консенсусное число 2
       Третий поток не может отличить глобальное состояние при
       изменении порядка выполнения коммутирующих или перезаписывающих
       операций в критическом состоянии.
  6. Универсальные объекты
     Объект с консенсусным числом ∞ называется универсальным объектом.
     По определению, с его помощью можно реализовать консенсусный
     протокол для любого числа потоков.

     #+NAME: CAS register
     #+BEGIN_SRC text
       class CASRegister:
             private shared int reg

             def CAS(expect, update):
                 do atomically:
                    old = reg
                    if old == expect:
                       reg = update
                       return true
                    return false
     #+END_SRC
     CAS -- самый популярный универсальный объект, процессоры в том
     или ином виде его реализуют.

     * CAS и консенсус
       #+NAME: реализация протокола через CAS+READ
       #+BEGIN_SRC text
         def decide(val):
             if CAS(NA, val):
                 return val
             else:
                 return read()
       #+END_SRC

     * Универсальность консенсуса. Теорема.
       Любой последовательый объект можно реализовать без ожидания для
       N потоков используя консенсусный протокол для N объектов

       * Такое построение -- универсальная конструкция
       * Следствие 1: С помощью любого класса объектов с консенсусным
         числом N можно реализовать любой объект с консенсусным числом
         ≤ N
       * Следствие 2: С помощью универсального объекта можно
         реализовать вообще любой объект
         * Сначала реализуем консенсус для любого числа потоков (по
           определению универсального объекта)
         * Потом через консенсус любой другой объект используя
           универсальную конструкцию.
       * Доказательство теоремы
         1. Универсальная конструкция без блокировки через CAS
            #+BEGIN_SRC text
              shared CASRegister reg

              def concurrentOperationX(args):
                  loop:
                      old = reg.read()
                      upd = old.deepCopy()
                      res = upd.serialOperationX(args)
                  until reg.CAS(old, upd)
                  return res
            #+END_SRC

            * Без блокировки универсальная конструкция проста и
              проктична, если использовать CAS в качестве примитива.
            * Для реализации через консенсус надо чтобы каждый объект
              консенсуса пользовался потоком один раз
            * Для реализации без ожидания нужно чтобы потоки помогали
              друг другу.
         2. Через консенсус
            ОБъект -- односвязный список стейтов.
            Последний элемент -- текущий стейт.

            #+NAME: Через консенсус без блокировки
            #+BEGIN_SRC text
              class Node:
                    val               // readonly
                    Consensus next    // init fresh obj

              shared Node root        // readonly
              threadlocal Node last   // init rood

              def concurrentOperationX(args):
                  loop:
                      old = last.val
                      upd = old.deepCopy()
                      res = upd.serialOperationX(args)
                      node = new Node(upd)
                      last = last.next.decide(node)
                  until last == node
                  return res
            #+END_SRC

            * Но с ожиданием

         3. Через консенсус без ожидания
            * Храним в узле операцию, которую нужно выполнить, а не
              результат -- каждый поток обновляет и хранит свою
              локальную копию объекта
            * Нумеруем операции последовательными числами, заведя
              переменную seq. После выполнения прописываем номер
              исполненной операции.
            * Каждй поток хранит последнее ему известное значение
              конца списка в элементе массива know[id]
            * Каждый поток будет заранее записывать операцию, которую
              он планирует выполнить -- в массиве announce

            #+NAME: Через консенсус без блокировки
            #+BEGIN_SRC text
              class Node:
                    int seq           // init 0
                    args              // readonly
                    Consensus next    // init fresh obj

              shared Node[] announce // init root
              shared Node[] know // init root

              def concunrrentOperationX(args):
                  announce[id] = new Node(args)
                  know[id] = maxSeqFrom(know)
                  while announce[id].seq == 0
                        Node help =
                             announce[know[id].seq % N]
                        Node prev = help if help.seq == 0
                             else announce[id]
                        know[id] = prev.next.decide(node)
                        know[id].seq = prev.seq + 1
                  know[id] = announce[id]
                  return updateMyLastTo(announce[id])

              def updateMyLastTo(node):
                  while last != node:
                        res = my.serialOperationX(last.args)
                        last = last.next
                        return res
            #+END_SRC
  7. Сводная иерархия
     |--------------------------------------------+--------------------|
     | Объект                                     | Консенсусное число |
     |--------------------------------------------+--------------------|
     | Атомарные регичтры                         | 1                  |
     | Снимок состояния нескольких регистров      |                    |
     |--------------------------------------------+--------------------|
     | getAndSet, getAndAdd, очередь, стек        | 2                  |
     |--------------------------------------------+--------------------|
     | Атомарная запись m регистров из m(m+1)/2   | m                  |
     |--------------------------------------------+--------------------|
     | compareAndSet, LoadLinked/StoreConditional | ∞                  |
     |--------------------------------------------+--------------------|
* Практические построения на списке
  Будем смотреть всякие практические построения на списках.
  Будем писать код уже на джаве настоящей.

  Java -- первый язык, в котором появилась модель памяти (memory
  model). Почему джава? Трюки c++ (if_arch_...) не работают в джаве,
  джава очень WORA, и прочее.

  JMM определяет:
  1. Межпоточные действия -- чтение и запись,
     синхронизация. Синхронизация -- volatile/synchronized/запуск или
     остановка потоков.
  2. Отношение синхронизации (synchronizes-with) и отношение
     happens-before.
     Java гарантирует, что если в программе нету гонок, то исполнение
     последовательно согласовано (а значит и линеаризуемо).
  3. Всякие гонки и прочее.

  Выполнение корректно синхронизированной программы будет выглядеть
  последовательно согласовано. Гонки за данными не могут нарушить
  базовые гарантии безопасности платформы (система типов, все кроме
  long/double атомарны, все поля гарантированно инициализированы
  нулями, дополнительные гарантии для final полей).

  #+NAME: рабочий вариант 1 решения того же самого кода без volatile
  #+BEGIN_SRC java
    volatile int flag;
    int value;

    void int() {
        value = 2;
        flag = 1;
    }

    int take() {
        while (flag == 0); // кушаем cpu тут
        return value;
    }
  #+END_SRC

  #+NAME: решение 2, cpu не прогорает
  #+BEGIN_SRC java
    int flag, value;

    void synchronized int() {
        value = 2;
        flag = 1;
    }

    int synchronized take() {
        while (flag == 0); // кушаем cpu тут
        return value;
    }
  #+END_SRC

  Таким образом, мы реализовали thread-safe объект.

  Типы синхронизации:
  1. Грубая синронизация (Coarse-grained)
  2. Тонкая (fine-grained)
  3. Оптимистичная (optimistic)
  4. Ленивая (lazy)
  5. Неблокирующая (non-blocking)

  Будем строить многопоточные связанные списки.

  #+NAME: Что пытаемся синхронизировать
  #+BEGIN_SRC java
    // инвариант node.key < node.next.key
    class Node {
        final int key;
        final T item;
        Node next;
    }
  #+END_SRC

  #+NAME: грубая синхронизация списка
  #+BEGIN_SRC java
    class LinkedSet {

        boolean contains(int key) {
            lock.lock();
            try {
                Node curr = head;
                while (curr.key < key) {
                    curr = curr.next;
                }
                return key == curr.key;
            } finally { lock.unlock() }
        }

        boolean add(int key, T item) {
            lock.lock();
            try {
                Node pred = head, curr = pred.next;
                while (...) {}
                    /// stuff
            } finally { lock.unlock(); }
        }
        boolean remove (int key, T item) {
            lock.lock();
            try {
                // stuff
            } finally { lock.unlock; }
        }
    }
  #+END_SRC


  #+NAME: Тонкая синхронизация
  #+BEGIN_SRC java
    class Node {
        final int key;
        final T item;
        final Lock lock;
        Node next;

        void lock() { lock.lock(); }
        void unlock() { lock.unlock(); }

        void search() {
            Node pred = head; pred.lock();
            Node curr = pred.next; curr.lock();
            try {
                while (curr.key < key) {
                    pred.unlock(); pred = curr;
                    curr = curr.next; curr.lock();
                }
                return key == curr.key;
            } finally { curr.unlock; pred.unlock; }
        }

        boolean add(int key, T item) {
            Node pred = head; pred.lock();
            Node curr = pred.next; curr.lock();
            try {
                // addition
            } finally { curr.unlock; pred.unlock; }
        }

        boolean remove(int key, T item) {
            Node pred = head; pred.lock();
            Node curr = pred.next; curr.lock();
            try {
                // removal
            } finally { curr.unlock; pred.unlock; }

        }
    }
  #+END_SRC


  Оптимистичная синхронизация:
  1. Ищем элемент без синхронизации, но перепроверяем с
     синхронизацией.
     1. Если перепроверка сломалась, то начинаем операцию заново
     2. Поиск не зациклится, ибо ключи упорядочены, никогда не
        меняются внутри Node, значения next не могут возникнуть
        ниоткуда даже при чтении без синхронизации
  2. Имеет смысл только если обход дешев и быстр, а обход с
     синхронизацией -- наоборот.
  3. Потоки всегда синхронизируются между собой ("synchronizes with")
     через критические секции, поэтому никаких дополнительных
     механизмов не нужно.
  #+NAME:Оптимистичная синхронизация
  #+BEGIN_SRC java
        retry: while (true) {
            Node pred = head, curr = pred.next;
            while (curr.key < key) {
                pred = curr; curr = curr.next;
                if (curr == null) continue retry;
            }
            pred.lock(); curr.lock();
            try {
                if (!validate(pred, curr)) continue retry;
                return curr.key == key;
            } finally { curr.unlock(); pred.unlock();
            }
         }
    // остальные операции аналогично
  #+END_SRC

  Ленивая синхронизация:
  1. Добавляем в Node boolean флажок, в котором будем помечать
     удаленные элементы.
  2. Инвариант: все непомеченные элементы всегда в списке.
  3. Результат: для валидации не надо просматривать список, остальное
     как в оптимистичном варианте.

  #+NAME:Ленивая синхронизация
  #+BEGIN_SRC java
    void add(T elem) {
     retry: while (true) {
            Node pred = ...;
            while (...) {
                pred = curr; curr = curr.next; // тут curr != null
            }
            pred.lock(); curr.lock();
            try {
                if (...) continue retry;
                if (curr.key == key) return false;
                else {
                    // тут точка линеаризации
                }
            }
        }
    }

    void delete (T elem) {
     retry: while (true) {
            Node pred = get;

            // ставим маркер
        }
    }

    boolean contains(int key) {
        Node curr = head;
        while (curr.key < key) {
            curr = curr.next; // точка линеаризации
        }
        return key == curr.key;
    }
  #+END_SRC

  Неблокирующая синхронизация
  * Простое использование CAS не помогает -- удаление двух соседних
    элементов будет конфликтовать
    1, 2, 3, 4, удалим 2, 3, но указатель 1 → 3 сохранится.
  * Трюк такой: объединим (next, marked) в одну переменную, и будем ее
    изменять CASом.
  * Плюс к этому будем физически удалять в других потоках помеченные
    элементы.


  Стек еще очень просто пишется, пишем универсальную конструкцию
  (персистентное копирование).
* Продолжение построений на списках, стеках
  #+DATE: 2015.10.19
  Вот короче стек есть, но он не масштабируемый. Если конкуренция
  очень большая, то производительность в многосокетных системах на top
  будет падать.
  #+NAME: stack implementation
  #+BEGIN_SRC java
    void push(T item) {
         while (true) {
               Node node = new Node(item, top.get());
               if (top.compareAndSet(node.next, node)) // линеаризация
                  return;
         }
    }

    T pop() {
      while (true) {
            Node node = top.get();
            if (node == null) throw new EmptyStack();
            if (top.compareAndSet(node, node.next)) // линеаризация
               return node.item;
      }
    }
  #+END_SRC

  С разделяемой памятью вообще все достаточно сложно, там не только
  race condition'ы в большом количестве, но и куча проблем с
  производительностью.

  Будем пока считать что стек хороший.

  Будем делать очередь на списках. Наивно с помощью универсальной
  конструкции так себе, а популярный алгоритм -- Майкла Скотта.

  Делаем список, у очереди есть указатель на голову и хвост, все
  односвязно. Будем элементы добавлять и удалять достаточно
  естественно.
  Добавление: Создаем элемент, ссылаемся на голову, с помощью CAS'а
  меняем указатель на голову в классе.
  Дописать элемент в хвост сложно, потому что нужно поменять сразу две
  ячейки памяти -- указатель класса на хвост, указатель предыдущего
  элемента хвоста на последний.

  Идея алгоритма Майкла-Скотта такая: будем брать элемент и
  подписывать его в хвост, меняя ссылку предыдущего, а физически
  перемещать tail (указатель из класса) потом.
  Если другой поток увидит, что очередь в состоянии "есть ссылка на
  tail, у которого есть следующий элемент", то он может помочь
  переставить указатель класса на нужный элемент.

  #+NAME: Майкл-Скотт
  #+BEGIN_SRC java
    void enqueue(T item) {
        Node node = new Node(item);
     retry: while (true) {
            Node last = tail.get(),
                next = last.next.get();
            if (next == null) {
                if (!last.next.compareAndSet(null, node))
                    continue retry;
                // оптимизация -- сами переставляем tail
                tail.compareAndSet(last, node);
                return;
            }
            // помогаем другим операциям enqueue с tail
            tail.compareAndSet(last, next);
        }
    }

    T dequeue() {
     retry: while (true) {
            Node first = head.get(),
                last = tail.get(),
                next = first.next();
            if (first == last) {
                if (next == null) throw new EmptyQueue();
                // Помогаем операциям enqueue с tail
                tail.compareAndSet(last, next);
            } else {
                if (head.compareAndSet(first, next)) // линеаризация
                    return next.item;
            }
        }
    }
  #+END_SRC

  Есть проблема без GC, называется ABA. Суть:
  Будем реализовывать самый первый стек этой лекции на C, без Garbage
  collector'а.
  Добавим  в стек несколько элементов -- A и B.
  Может быть такое, что top стека может быть: A B A.
  Достанем указатель на top, сделаем успешно cas, на return нас
  перебил другой поток, и что-то переаллочилось, теперь в A лежит
  какая-то другая фигня.

  Еще раз: в стеке 1 элемент, по адресу A (top = A).
  Мы делаем ему pop, достаем A. В это время нас прерывают.
  Другой поток делает pop A, push B, pop B, push C на месте A появился
  другой элемент, но CAS сравнивает только указатели, и в этом случае
  он не обнаружит эту проблему.
  В джаве это не работает так, потому что память на A нельзя
  освободить, пока на нее ссылаются.

  Решить ABA проще всего с помощью реализации сборщика мусора.
  Другой способ -- пользоваться версиями. Хранить в top пару из
  указателя и версии. Таким образом если стек за время top.get и cas
  успел поменяться, мы сравним версии и упадем. Именно поэтому мы
  можем делать cas на 2х последовательных словах, это позволяет нам
  менять одновременно указатель + версию.
  Еще можно пользоваться Hazard Pointers -- многопоточный сборщик
  мусора, который работает только для наших узлов.
* Алгоритмы на массивах
  Давайте делать стек на массиве.
  В однопоточном варианте стек на массиве -- очень просто.
  Типа держим размер, pop/push меняет размер массива и ячейку.
  Но это все равно не взлетит в многопоточном варианте совсем прям
  наивно.
  Вот делаем мы push. Сначала увеличим top cas'ом, а потом проставим
  элемент. Push будет работать, но pop в такой реализации упадет --
  если мы уже увеличили top, но не положили элемент, то достанет
  какой-то мусор.
  Аналогично если сначала проставляем элемент, а потом увеличиваем
  top, то там будет что-то старое.
  С очередями проблемы те же.

  Будем писать дек, пытаясь реализовать obstruction-free свойство.
  Дек будет циклическим.  Храним в элементе пару -- значение и
  версия. Там где дек пустой, будем хранить (left_null, version),
  справа (right_null, version).
  Для корректности алгоритма не будем полагаться на указатели left и
  right в классе дека -- они будут типа для производительности, а
  индексироваться будем за O(n).

  На практике этим никто не пользуется, потому что все равно
  медленнее, чем на ссылочном листе.
  #+BEGIN_SRC java
    int rightOracle() {
        int k = right; // для оптимизации
        while (a[k] != RN) k++;
        while (a[k-1] == RN) k--;
        right = k; // запомнили для оптимизации
        return k;
    }

    void rightPush(T item) {
     retry: while (true) {
            int k = rightOracle();
            {T item, int ver} prev = a[k-1], cur = a[k];
            if (prev.item == RN || cur.item != RN) continue;
            if (k == MAX-1) throw new FullDeque();
            if (CAS(a[k-1], prev, {prev.item, prev.ver+1} &&
                    CAS(a[k]))) {}
        }
    }

    T rightPop() {
     retry: while (true) {
            int k = oracleRight();
            {T item, int ver} cur = a[k-1], next = a[k];
            if (cur.itim == RN || next.item != RN) continue;
            if (cur.item == LN) throw new EmptyDeque();
            if (CAS(a[k], next, {RN, next.ver+1}) &&
                CAS(a[k-1], cur, {RN, cur.ver + 1}))
                return cur.item;
        }
    }
  #+END_SRC

* Хэш-таблицы
  Бывают с прямой адресацией (по хэшу находим ведро, и все элементы с
  таким хэшом попадают в это ведро -- там дальше список или дерево).
  На практике с прямой адресацией все медленно, потому что там опять
  массивы или списки.
  Бывают с открытой, это самый лучший вариант.
  Но со списками намного проще.

  Будем пользоваться алгоритмом Split-Ordered lists.
  Засунем все элементы в одно большое связанео множество. Упорядочим
  их по хэшу. Для ускорения заведем слева хэш-таблицу, адресующую те
  элементы листа с заданным хэшом. Эта дополнительная таблица делается
  только для ускорения.
  Когда будем хотеть расширить таблицу, создадим вторую, скопируем ее
  черезстрочно, будем по мере обращений к хэшу ее обновлять (вторую).


  Открытая адресация.
  Делаем на массиве, будем считать ведро по хэшкоду, если занято, то
  дальше.
  Добавлять из нескольких потоков легко -- просто делаем cas. Удалять
  из такой таблицы можно прописывая некоторое особенное
  значение T. Нельзя прудмать алгоритм, который бы многопоточно
  закрывал дырки в этих списках.
  Ну, допустим мы забиваем элементы T, но как перевыделять память со
  временем -- для освобождения элементов T или расширения таблицы.

  Сделаем так, что таблица хранит указатель на "реальную" внутреннюю
  таблицу. Когда копируем, создаем новую таблицу, а указатель поставим
  в конце. Операция изменения ищет в новой таблице, если нету, то ищет
  в старой, если находит -- копирует в новую.
  Таким образом мы перенесем все элементы в новую таблицу.
  Как переносить, собственно?

  Если собираемся переносить, то пометим битиком значение. После этого
  мы занимаем слот в новой таблице, после этого копируем значение в
  новой таблице. Затем в старой пометим, что мы уже скопировали.
  (0, 0)
  ↓
  {Claim key}
  ↓
  (K, 0)
  ↓
  {Set value}
  ↓
  (K, V)            → Start copy → (K, V')
  ↕                                  ↑
  {insert/delete}                  Moved
  ↕                                  ↑
  (K, T)            → Moved      → (K, T')
* CASN
  Этот алгоритм с переносом таблиц есть частный случай.
  Хотим чтобы работало корректно (линеаризуемо) и:
  1. Lock-free
  2. Disjoint-Access Parallel (непересекающиеся доступы параллельны).

  #+NAME: CASN -- желаемое поведение
  #+BEGIN_SRC java
    boolean CASN(CASEntry... entries) atomic {
        for (CASEntry entry: entries)
            if (entry.a.value != entry.expect)
                return false;
        for (CASEntry entry: entries)
            entry.a.value = entry.update;
        return true;
    }
  #+END_SRC

  Если мы сделаем CASN, то сделаем стек на массиве -- будем
  одновременно делать CAS 2 раза.

  # Тут мы показываем, как это писать -- очень быстро, чтобы
  # переписывать на ходу.
  # TODO переписать
* Сложные блокировки и STM
  Проведем анализ конфликтов (data race).
  Матрица конфликтов (для регистра) -- какие методы конфликтуют:
  |---+---+---|
  |   | R | W |
  |---+---+---|
  | R |   | × |
  |---+---+---|
  | W | × | × |
  |---+---+---|

  Подход этой матрицы позволяет чисто автоматизированно составить
  матрицу для сложной структуры с большим количеством методов.

  Можно тривиально убрать конфликты с помощью грубой блокировки на
  каждом конфликтующем методе.
  С другой стороны, жиненная ситуация -- после грубой блокировки
  некоторые методы могут работать одновременно (к примеру только
  читающие методы).

  Эту проблему решают read-write locks.
  Можем создать класс, который умеет лочиться по read или по write.

  Другое решение -- делать структуру данных, используя тонкую
  блокировку. Например, с помощью CASN.


  Как сделать линеаризуемый многопоточный объект?
  1. Блокировки (aka synchronized): грубая, тонкая, ..., read-write
  2. Без блокировки
     1. Универсальная конструкция (Copy-on-write + CAS, частичное
        копирование + CAS)
     2. CASN
     3. Специфичные для структуры алгоритмы

  Проблемы блокировки:
  1. В системе нет прогресса, пока объект заблокирован
  2. Требуются дополнительные переключения контекста чтобы дать
     закончить работу блокирующему потоку. Это может сильно жрать
     CPU.
  3. Минимальный параллелизм работы, причем параллелизм обратно
     пропорционален количеству блокировок.
  4. Deadlocks

  Как делать сложные вещи и не думать? STM!
  Типа навешиваем какие-то вещи на кусок кода, и он выполняется
  атомарно. Такое есть, например, в Clojure. Проблема -- оно работает
  медленно и поэтому не подходит для плюсов/джавы.

  В джаве тоже есть, класс Transaction. Как это реализовываать?
  Можно двухфазовой блокировкой.
