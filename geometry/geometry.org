#+TODO: X 0 1 2 | 3
#+LANGUAGE: ru
#+LaTeX_HEADER: \usepackage[a4paper, left=2.5cm,right=2cm,top=2cm,bottom=2cm]{geometry}
#+LaTeX_HEADER: \usepackage[russian]{babel}             % Russian translations
#+LaTeX_HEADER: \usepackage{amssymb,amsmath,amsthm}     % Mathematic symbols, theorems, etc.
#+LaTeX_HEADER: \usepackage[boxed]{algorithm2e} % Algorithm listings
#+LaTeX_HEADER: \usepackage{styling}                    % Styling for theorems (local)
#+TITLE:  Конспект по вычислительной геометрии (Ковалёв)
#+AUTHOR: Volkhov M., Mukhutdinov D., Belyy A.

\clearpage
* Как пользоваться этим документом
  1. Писать билетики параллельно
  2. Все формулы оформлять в латехе.
     * http://www.math.uiuc.edu/~hildebr/tex/course/intro2.html
     * https://en.wikibooks.org/wiki/LaTeX/Mathematics
     * https://en.wikibooks.org/wiki/LaTeX/Advanced_Mathematics
     * Рекомендуется смотреть конспект Сугака [[https://github.com/sugakandrey/Functional-analysis/blob/master/hahnbanach.tex][тут]].
  3. Можно пользоваться ~(org-toggle-pretty-entities)~ чтобы latex
     отображался юникодом в emacs'е.
  4. *TODO* обозначают степень написанности материала. Положительное
     значение интерпретируется как процент. X -- метка для "тут нифига
     не ясно и проблемы".
  5. Смотреть превью формул с помощью ~C-c C-x C-l~.
  6. Экспортить с помощью ~C-c C-e l p~. Если не работает -- сначала в
     `tex`, а потом уже экспортировать `pdflatex`'ом. Экспорт
     игнорирует ошибки, поэтому сделать это руками и пофиксить их --
     не так плохо.
  7. Если что-то не собирается, писать ~@volhovm~.
  8. Синтаксис теха смотреть хз где, но есть
     http://detexify.kirelabs.org/classify.html для непонятных
     символов.
  9. Синтаксис орга -- это тут:
     * http://orgmode.org/manual/Emphasis-and-monospace.html
     * http://orgmode.org/manual/LaTeX-and-PDF-export.html#LaTeX-and-PDF-export
     * http://orgmode.org/tmp/worg/org-tutorials/org-latex-export.html
     * http://orgmode.org/manual/Embedded-LaTeX.html#Embedded-LaTeX
     * Остальное (списки, хедеры, блабла) очевидно.
  \clearpage
* Tickets
#+ATTR_LATEX: :environment longtable
|----+----+--------------------------------------------------------------------------------------|
|  4 |  1 | Принадлежность точки выпуклому и невыпуклому многоугольникам                         |
| 21 |  1 | Триангуляция Делоне.                                                                 |
|    |    | Алгоритм и доказательство его корректности.                                          |
|  5 |  2 | Статические выпуклые оболочки на плоскости.                                          |
|    |    | Джарвис, Грэм, Эндрю, Чен, QuickHull. Оболочка многоугольника, оболочка полилинии.   |
| 20 |  2 | Триангуляция Делоне.                                                                 |
|    |    | - существование;                                                                     |
|    |    | - приводимость любой триангуляции флипами к ТД;                                      |
|    |    | - эквивалентность критерия Делоне для треугольников критерию для ребер.              |
|  8 |  3 | Триангуляция многоугольника.                                                         |
|    |    | Существование, ушная триангуляция.                                                   |
| 17 |  3 | Сумма Минковского (определение, вычисление)                                          |
| 12 |  4 | ППЛГ и РСДС (PSLG и DCEL): определение, построение РСДС множества прямых             |
| 15 |  4 | Трапецоидная карта.                                                                  |
| 10 |  5 | Пересечение полуплоскостей, связь с выпуклыми оболочками                             |
| 13 |  5 | Пересечение многоугольников (PSLG overlaying)                                        |
|  7 |  6 | Выпуклая оболочка в n-мерном пространстве. Quick-hull и вероятностный алгоритм.      |
| 11 |  6 | Пересечение множества отрезков.                                                      |
|  9 |  7 | Триангуляция многоугольника заметающей прямой                                        |
| 14 |  7 | Локализация в ППЛГ.                                                                  |
|    |    | - методом полос (персистентные деревья);                                             |
|    |    | - Киркпатрик.                                                                        |
|  6 |  8 | Динамическая выпуклая оболочка (достаточно log^2 на добавление/удаление)             |
| 19 |  8 | Граф видимости и планирование движения.                                              |
|    |    | - построение графа видимости заметающим лучом;                                       |
|    |    | - сокращение графа видимости;                                                        |
|    |    | - построение навигационного графа на трапецоидной карте;                             |
|    |    | - планирование маршрута невыпуклого тела с вращением (без суммы Минковского).        |
|  3 |  9 | Пересечение отрезков и поворот: определение, свойства, вычисление                    |
| 22 |  9 | Диаграмма Вороного.                                                                  |
|    |    | - определение и свойства;                                                            |
|    |    | - диаграмма Вороного высших порядков, построение;                                    |
|    |    | - связь с подразбиением Делоне (ближайший и дальнейший);                             |
|    |    | - алгоритм построения ДВ.                                                            |
|  1 | 10 | Skip quadtree: определение, время работы                                             |
| 18 | 10 | Минимальная охватывающая окружность множества точек. Вероятностный алгоритм.         |
|  2 | 11 | Пересечение прямоугольника с множеством прямоугольников и непересекающихся отрезков: |
|    |    | - range tree + fractional cascading;                                                 |
|    |    | - interval tree;                                                                     |
|    |    | - segment tree;                                                                      |
|    |    | - priority search tree;                                                              |
|    |    | - k-d tree.        van Kreveld, de Berg, Overmars, Cheong                            |
| 16 | 11 | Диаметр множества точек (вращающиеся калиперы)                                       |
|----+----+--------------------------------------------------------------------------------------|
\clearpage
* 3 1:  Skip quadtree                                               :avbelyy:
** 3 Сжатое квадродерево
  #+CAPTION: Обычное и сжатое квадродеревья, содержащие по 3 точки.
  [[./figures/COMPR_QUADTREE.png]]

  #+ATTR_LATEX: :options [Квадродерево]
  #+BEGIN_defn
  Дерево, каждая внутренняя вершина которого содержит 4 ребенка.
  #+END_defn

  #+ATTR_LATEX: :options [Интересный квадрат]
  #+BEGIN_defn
  Квадрат, в котором содержится хотя бы одна точка из $P$.
  #+END_defn

  #+ATTR_LATEX: :options [Сжатое квадродерево]
  #+BEGIN_defn
  Квадродерево, внутренним вершинам которого соответствуют только
  интересные квадраты.
  #+END_defn

  *Построение сжатого квадродерева* происходит по обычному квадродереву
  следующим образом: у внутренней вершины заводим по 4 указателя для
  4 четвертей. Если в четверти 2 и более точки $P$ - указатель
  ссылается на наибольший интересный квадрат этих точек, если одна -
  ссылается на неё саму, если 0 - указатель ~NULL~.

  *Время работы операций в сжатом квадродереве* -- $O(n)$ на локализацию,
  вставку и удаление.
** 3 Randomized skip quadtree
  #+CAPTION: Skip quadtree, состоящее из трёх уровней -- $Q_0$, $Q_1$ и $Q_2$.
  [[./figures/SKIP_QUADTREE.png]]

  #+ATTR_LATEX: :options [Randomized skip quadtree]
  #+BEGIN_defn
  Последовательность сжатых квадродеревьев над подмножествами точек
  $P: {P_0, P_1, ..., P_k}$, где $P_0 = P$ \--- исходное множество
  точек, $P_i \in P_{i-1}$ и каждый элемент $P_{i-1}$ входит в $P_i$ с
  вероятностью $p \in (0,1)$. Skip quadree \--- это последовательность
  уровней $Q_i$, где $Q_i$ -- сжатое квадродерево над
  точками $P_i$.
  #+END_defn

  *Время работы операций в skip quadtree* -- $O(\log{n})$. Сначала
    опишем, как проходят операции, а потом докажем их время работы.

  * *Общая операция подъем*

    По вершине с уровня $i$ нужно получить эту же вершину на уровне
    $i - 1$. За $O(1)$. Как сделать? Проще всего как в skip list:
    "прошить" ссылками на вершину уровня выше каждую внутреннюю
    вершину каждого квадродерева.

  * *Локализация*

    Локализуемся на уровне $k$, далее сделаем подъем, окажемся в
    квадродереве уровня ниже и локализуемся в нем, но уже не от корня,
    а с того квадрата, который нашли на предыдущем уровне. Повторим это
    $k$ раз. В результате локализуемся на нулевом уровне.

  * *Вставка*

    Локализуемся на всех уровнях, запоминая ссылки. Сделаем вставку в
    квадродерево нулевого уровня, далее с вероятностью p сделаем
    вставку на 1 уровне и так далее до первого недобавления.
    Количество уровней при этом увеличится максимум на 1 (с
    вероятностью $p^k$).

  * *Удаление*

    Локализуемся на всех уровнях, удалим квадрат везде и обновим
    ссылки. Если уровень стал пустым \--- удалим его.

  #+ATTR_LATEX: :options [О количестве шагов на одном уровне]
  #+BEGIN_lemma
  На каждом уровне в среднем совершается O(1) шагов для поиска точки
  x.
  #+END_lemma

  #+BEGIN_proof
  Пусть в $Q_i$ (то есть на $i$-ом уровне) поиск точки $x$,
  начинающийся с корня, проходит по квадратам $p_0, p_1, \dots,
  p_m$. Пусть случайная величина $j$ -- количество шагов поиска в
  $Q_i$, тогда $p_{m - j}$ -- последний квадрат из $p_0, p_1,
  \dots, p_m$, являющийся интересным в $Q_{i + 1}$.

  Оценим вероятность того, что делается $j$ шагов. Забьём на случай $j
  = 0$, так как он не важен при расчёте мат. ожидания. На пути $p_{m -
  j + 1} \dots, p_m$ будет хотя бы $j + 1$ непустых четвертинок. У
  первого квадрата на этом пути есть хотя бы 2 непустые четвертинки,
  одна из них -- следующий квадрат на пути, в котором тоже хотя бы 2
  непустые четвертинки, и так далее. В последнем квадрате просто хотя
  бы 2 непустые четвертинки. Чтобы $p_{m - j}$ был последним из $p_0,
  p_1, \dots, p_m$ интересным квадратом в $Q_{i + 1}$ небходимо, чтобы
  среди этих как минимум $j + 1$ непустых четвертинок только одна
  (вероятность этого назовём $Pr_1$) или ноль (вероятность этого
  назовём $Pr_0$) были непустыми в $Q_{i + 1}$. Иначе, если будет хотя
  бы пара непустых четвертинок, то их наименьший общий предок в дереве
  будет интересным квадратом и будет находиться глубже $p_{m -
  j}$. Таким образом, искомая вероятность не превосходит $Pr_0 +
  Pr_1$.

  Пусть $q = 1 - p$.

  $Pr_0 \leq q^{(j + 1)}$, потому что это в сущности вероятность того,
  что ни одна точка из как минимум $j + 1$ непустых четвертинок не
  попала на уровень выше.

  $Pr_1 \leq (j + 1) \cdot pq^j$, потому что это в сущности
  вероятность того, что ровно одна точка из как минимум $j + 1$
  непустых четвертинок попала на уровень выше.

  $E(j) = \sum\limits_{j = 1}^{m} j \cdot Pr(j) \leq \sum\limits_{j =
  1}^{m} j \cdot (q^{(j + 1)} + (j + 1) \cdot pq^j) \leq
  \sum\limits_{j = 1}^{\infty} j \cdot (q^{(j + 1)} + (j + 1) \cdot
  pq^j)$

  Это почти геометрическая прогрессия, только на полином домножили,
  определяется всё экспоненциальным множителем, так что это
  $O(1)$. Можно совсем строго оценить, но и так понятно, что ряд
  сходится, а сойтись он может только к константе.
  #+END_proof

  #+ATTR_LATEX: :options [О количестве уровней]
  #+BEGIN_lemma
  Математическое ожидание количества уровней составляет $O(\log{n})$.
  #+END_lemma

  #+BEGIN_proof
  - Для оценки мат. ожидания посчитаем вероятность того, что
    количество уровней $h$ равно $k$.

    $p(h = k) = 1 - p(h > k) - p(h < k)$.

    $p(h < k) = (1 - p^{k})^n$, потому что вероятность того, что точка
    дойдёт до уровня $k$, равна $p^{k}$.

    $p(h > k) = (1 - (1 - p^{k + 1})^n)$, потому что вероятность того,
    что точка не дойдёт до уровня $k + 1$, равна $1 - p^{k + 1}$.

    $p(h = k) = 1 - p(h > k) - p(h < k) = 1 - (1 - (1 - p^{k +
    1})^n) - (1 - p^{k})^n = (1 - p^{k + 1})^n - (1 - p^k)^n \leq 1 -
    (1 - p^k)^n \leq np^k$

  - Теперь посчитаем мат. ожидание количества уровней:

    $E(h) = \sum\limits_{k = 1}^{\infty} k \cdot p(h = k) = p(1) \cdot
    1 + \dots + p(\log_{1/p} n) \cdot \log_{1/p} n + \sum\limits_{k =
    \log_{1/p} n + 1}^{\infty} k \cdot p(k)$

  - Оценим первую сумму:

    $p(1) \cdot 1 + \dots + p(\log_{1/p} n) \cdot \log_{1/p} n \leq p(1)
    \cdot \log_{1/p} n + \dots + p(\log_{1/p} n) \cdot \log_{1/p} n =
    O(\log(n))$, поскольку сумма этих вероятностей не превосходит
    единицу.

  - Оценим вторую сумму:

    $\sum\limits_{k = \log_{1/p} n + 1}^{\infty} k \cdot p(k) = \leq
    \sum\limits_{k = \log_{1/p} n}^{\infty} k \cdot n p^k = n \cdot
    \sum\limits_{k = \log_{1/p} n}^{\infty} k \cdot p^k$

  - Рассмотрим эту сумму:

    $\sum\limits_{k = \log_{1/p} n}^{\infty} k \cdot p^k = p^{\log_{1/p}
    n} \cdot \sum\limits_{k = 0}^{\infty} (k + \log_{1/p} n) \cdot p^k =
    p^{\log_{1/p} n} \cdot (\sum\limits_{k = 0}^{\infty} (k p^k) +
    \log_{1/p} n \cdot \sum\limits_{k = 0}^{\infty} (p^k)) =
    p^{\log_{1/p} n} \cdot (O(1) + \log_{1/p} n \cdot O(1)) = 1/n \cdot
    O(\log(n))$

  - Суммируя всё вышесказанное, получаем, что $O(\log(n))$.
  #+END_proof

  #+ATTR_LATEX: :options [О времени работы операций в skip quadtree]
  #+BEGIN_thm
  Локализация, вставка и удаление работают в среднем за $O(\log{n})$.
  #+END_thm

  #+BEGIN_proof
  Следует из двух предыдущих лемм.  Будем подниматься через
  $O(\log{n})$ уровней до нулевого, делая на каждом уровне $O(1)$
  шагов.
  #+END_proof
  \clearpage
* 2 2:  Пересечение прямоугольника с множеством пр-уг/отр       :flyingleafe:
** 2 Пересечение прямоугольника запроса $q$ с множеством прямоугольников $P$
   Задача: существует множество прямоугольников $P$. Стороны
   прямоугольников параллельны осям координат. Задается прямоугольник
   запроса $q$, такой же. Нужно быстро определить множество
   прямоугольников, пересекающихся с $q$.

   Формально: нужно найти множество $S = \{ p \in P : p \cap q \neq
   \emptyset \}$

   Разобьем это множество на три множества-подзадачи:
   \begin{align*}
   S &= A \cup B \cup C \\
   A &= \{ p \in P : \exists i: p_i \in corners(p), p_i \in q \} \\
   B &= \{ p \in P : \exists i: s_i \in sides(p), s_i \cap q \neq \emptyset \} \\
   C &= \{ p \in P : \exists i: p_i \in corners(q), p_i \in p \} \\
   \end{align*}

   Иначе говоря, $A$ -- это случай, когда $p$ целиком лежит в $q$, $B$
   -- когда $p$ и $q$ пересекаются, $C$ -- когда $q$ целиком лежит в
   $p$. Разберем все три случая отдельно.
*** 2 Нахождение множества точек, попадающих в прямоугольник запроса.

    Для начала быстро рассмотрим одномерный случай. Быстро выдавать
    множество точек, попадающих в отрезок, можно с помощью
    сбалансированного дерева поиска. (*Примечание:* можно и с помощью
    отсортированного массива и бинпоиска, но в такую структуру данных
    нельзя эффективно вставить новую точку).

    Как это делать - очевидно: идем вглубь дерева, пока не встретим
    узел, разделяющий концы отрезка. После этого ищем каждый конец
    отрезка в отдельности и добавляем к ответу все поддеревья, лежащие
    справа (для левого конца) и слева (для правого конца) от пути.

    Такое дерево можно построить за $O(n \log n)$, она будет занимать
    $O(n)$ памяти, запрос будет обработан за $O(\log n + k)$, где
    $k$ - величина ответа. Как расширить эту структуру на двумерный
    случай и добиться сопоставимых результатов?

**** *Способ 1. Range trees*

     Рассмотрим обработку двумерного запроса как обработку 2 одномерных
     запросов по отдельности: по $x$ -координате и по $y$ -координате. То
     есть, сначала мы отсеиваем все точки, попадающие в запрос по $x$,
     а потом из них выбираем точки, попадающие в этот запрос по $y$.

     Мы делаем это, на самом деле, очень просто: строим для всего
     множества точек бинарное дерево поиска по $x$, а в каждом узле
     этого дерева дополнительно строим дерево поиска по $y$ для
     соответствующего поддерева.

     #+CAPTION: Иллюстрация к Range-tree
     [[./figures/RANGE_TREES.png]]

     #+BEGIN_lemma
     Такая структура данных, несмотря на кажущуюся громоздкость,
     занимает $O(n \log n)$ памяти
     #+END_lemma

     #+BEGIN_proof
     Рассмотрим некую точку $p$. В дереве первого уровня путь от корня
     до нее занимает $O(\log n)$ узлов. Значит, она содержится в каждом
     дереве 2-го уровня, встретившемся на пути, но не встречается
     больше ни в каких деревьях 2-го уровня. Таким образом, количество
     копий каждой точки во всей структуре данных оценивается в $O(\log
     n)$. Всего точек $n$, значит, структура занимает $O(n \log n)$
     памяти.
     #+END_proof

     #+BEGIN_lemma
     Такую структуру данных можно построить за $O(n \log n)$
     #+END_lemma

     #+BEGIN_proof
     Если строить каждое дерево второго уровня втупую за $O(n \log n)$,
     то это, конечно, будет долго. Однако, если мы сначала отсортируем
     список вершин по $y$, то деревья второго уровня можно будет
     строить за $O(n)$ снизу вверх. Таким образом, каждый узел
     основного дерева будет строиться за $O(m)$, где $m$ - количество
     точек в поддереве узла. Значит, узел строится за такое время,
     сколько памяти занимает, а вся структура занимает $O(n \log n)$
     памяти. Поэтому за столько же по времени произойдет построение дерева.
     #+END_proof

     #+BEGIN_lemma
     Двумерный запрос в таком дереве займет $O(\log^2 n + k)$ времени.
     #+END_lemma

     #+BEGIN_proof
     Запрос в дереве 1 уровня пройдет за $O(\log n)$. При этом во время
     выполнения запроса вызовутся запросы по $y$ для всех деревьев
     поиска 2 уровня, встретившихся по пути - таких $O(\log n)$. В
     дереве поиска 2 уровня ситуация аналогична одномерной + нужно
     время на вывод результата. Итого: $O(\log^2 n + k)$
     #+END_proof

     *Замечание* Легко видеть, что Range tree легко обобщается на
     высшие размерности - достаточно просто понапихать деревьев низших
     уровней. В таком случае на построение и память уйдет $O(n
     \log^{d-1} n)$, а на запрос - $O(n \log^d + k)$. Доказательство
     этих фактов оставим читателю (это легко, мне лень, Ковалев не
     спросит).

     *Fractional cascading*

     Время запроса $O(n \log^2 n + k)$ - казалось бы, не так уж плохо,
     но на серьезных $n$ этот квадрат у логарифма даст серьезный
     прирост во времени. Можно ли от него избавиться? Оказывается, да!
     Для этого существует техника, называемая fractional cascading.

     *Идея*: Мы делаем $O(\log n)$ запросов по деревьям второго уровня
     для одного и того же ренджа по $y$ - координате. Может быть, мы
     можем как-то использовать результаты запросов в старших
     поддеревьях для младших?

     Проиллюстрируем идею fractional cascading на более простом
     примере. Предположим, у нас есть 2 массива объектов - $A_1, A_2$ -
     отсортированных по ключу, причем $A_2 \subset A_1$. Приходит
     запрос -  выдать все объекты из обоих массивов с ключом, лежащим в
     отрезке $(l, r)$. Можно втупую сделать бинпоиск на обоих
     массивах. А можно делать бинпоиск только в большем массиве $A_1$,
     а во втором массиве выдать ответ сразу, воспользовавшись ссылками,
     ведущими из каждого объекта в $A_1$ в первый объект в $A_2$,
     больший или равный данному. (см. иллюстрацию)

     #+CAPTION: Иллюстрация к Fractional Cascading
     [[./figures/FRAC_CASC.png]]

     Так вот! Теперь заметим, что каждое дерево 2-го уровня в
     Range-tree содержится в своем предке. А давайте тогда не будем
     делать деревья 2 уровня, а вместо них сделаем вот такие каскадные
     массивы. Причем в каждом элементе такого массива есть 2 ссылки -
     на upper-bound в левом и правом сыне.

     Такая структура данных называется layered range-tree. Она
     занимает столько же памяти, сколько и обычный range-tree
     (очевидно). Докажем пару других фактов.

     #+BEGIN_lemma
     Layered range-tree строится за $O(n \log n)$
     #+END_lemma

     #+BEGIN_proof
     Корневой массив строим, просто отсортировав точки по $y$ за $O(n
     \log n)$. Покажем способ построить из массива длины $n$ два
     дочерних массива с каскадными ссылками за $O(n)$.

     Разделить отсортированный массив по некоему $x$ на два можно за
     $O(n)$ легко - идем по элементам по порядку и в зависимости от их
     $x$ координаты кладем их в конец левого или правого
     массивов. Проставить ссылки же можно с помощью трех указателей.

     Ставим указатели $i, j, k$ в начало корневого массива, левого и
     правого сына соответственно. Перебираем $A[i]$, смотрим в
     $A_l[j]$ и увеличиваем $j$ до тех пор, пока $A_l[j] <
     A[i]$. Аналогично делаем с $A_r$. Проставляем в $A[i]$ ссылки на
     $A_l[j]$ и $A_r[k]$ и увеличиваем $i$. Эта процедура, очевидно,
     занимает линейное время.
     #+END_proof

     #+BEGIN_lemma
     Запрос в layered range-tree занимает $O(\log n + k)$ времени
     #+END_lemma

     #+BEGIN_proof
     Запрос по 1 уровню занимает $O(\log n)$, на выходе мы получаем
     $O(\log n)$ каскадных массивчиков, в которых нужно провести
     запрос по $y$. Но мы за $O(\log n)$ делаем этот запрос только в
     корне, и за этот же $O(\log n)$ спускаемся вниз по каскадным
     ссылкам, зацепляя все найденные массивы. Итого - $O(\log n + k)$
     #+END_proof

     *Замечание* Fractional cascading, вообще говоря, снижает время
     запроса по range-tree в d-мерном пространстве до $O(\log^{d-1} +
     k)$ (доказывать не буду, я заебался уже)

**** *Способ 2. k-d trees*

     Идея: давайте поиск по $y$ - координате будем делать не после
     того, как завершили поиск по $x$ - координате, а как бы
     вперемешку. Строим "слоеное" дерево: сначала поделим множество
     точек примерно пополам по $x$, потом по $y$, потом снова по $x$ и
     так далее.

     #+CAPTION: K-d tree
     [[./figures/KD_TREE.png]]

     #+BEGIN_lemma
     K-d tree построится за $O(n \log n)$ и будет занимать $O(n)$ места.
     #+END_lemma

     #+BEGIN_proof
     Дерево строится рекурсивно, множество, по которому строятся
     правое и левое поддерево, примерно одинаковы - для этого ищется
     медиана. Таким образом, глубина дерева - $O(\log n)$. Медиану
     можно найти за $O(n)$ (сложно, но можно, проще посортить все
     заранее), разделить множество по медиане - тоже за $O(n)$. Итого,
     каждый вызов без учета рекурсии занимает $O(n)$, всего вызовов
     $O(\log n)$, итого $O(n \log n)$

     Что касается места: k-d tree имеет вид обычного сбанансированного
     бинарного дерева с $n$ листьями, в котором каждый узел занимает
     $O(1)$ памяти. Значит, всего памяти $O(n)$
     #+END_proof

     Пусть нам теперь нам прилетел прямоугольный запрос. Рекурсивно
     спускаемся с ним по дереву, "нарезая" его медианами. Если в
     запрос какая-то область попала целиком - возвращаем все
     поддерево.

     \begin{algorithm}[H]
      \SetKwFunction{QueryKDT}{QueryKDT}%
      \func{\QueryKDT{v, R}}{
        \KwData{Корень дерева $v$, и прямоугольник $R$}
        \KwResult{Множество точек, попавших в прямоугольник}
        \eIf{$v$ -- лист}{
          \If{$point(v) \in R$}{report $point(v)$}
        }{
          \eIf{область узла $v$ полностью содержится в $R$}{
            report-all($v$)
          }{
            \If{область $v_l$ пересекается с $R$}{
              \QueryKDT{$v_l$, $R$}
            }
            \If{область $v_r$ пересекается с $R$}{
              \QueryKDT{$v_r$, $R$}
            }
          }
        }
      }
      \caption{Алгоритм построения PST}
    \end{algorithm}

    #+BEGIN_lemma
    Запрос в k-d tree занимает $O(\sqrt{n} + k)$ времени.
    #+END_lemma

    #+BEGIN_proof
    Без учета рекурсивных вызовов и вывода ответа, \QueryKDT
    выполняется за $O(1)$. С выводом ответа все понятно, но сколько
    будет рекурсивных вызовов? Их будет столько, сколько на пути
    попадется областей, пересекаемых границей прямоугольника. Границы
    прямоугольника могут быть сколь угодно длинными. Поэтому верхней
    оценкой на количество областей, пересекаемый 1 гранью
    многоугольника, можно считать количество областей, пересекаемых
    случайной вертикальной прямой (с горизонтальной гранью -- симметрично).

    Обозначим количество таких областей в k-d tree для n точек как
    $Q(n)$, пересекающую прямую -- $l$. Пусть разделяющая прямая в
    корне -- вертикальная. Тогда прямая $l$ пересечет область в корне
    и ровно одного из сыновей - 2 пересечения. Но в сыне разделяющая
    прямая будет горизонтальной! То есть, прямая точно пересечет обоих
    внуков. А вот во внуках ситуация уже будет аналогична корню. В
    каждом внуке примерно $n/4$ точек. Теперь мы можем записать
    рекуррентную формулу:

    $Q(n) = \begin{cases}
      O(1), & \mbox{if } n = 1 \\
      2 + 2Q(n/4), & \mbox{otherwise}
    \end{cases}$

    Тут надо сделать какой-то шмяк-шмяк и сказать, что эта рекурсия
    имеет решение $Q(n) = O(\sqrt{n})$. На самом деле, так и есть.
    #+END_proof

    Итого: k-d tree отвечает на запросы явно помедленнее range tree
    (даже не layered), однако занимает меньше памяти и явно проще в исполнении.

*** 3 Нахождение множества отрезков, пересекающих прямоугольник запроса (но не лежащих концом внутри)
    CLOSED: [2016-01-10 Sun 15:57]
    Пусть есть множество отрезков $S$, таких, что каждый отрезок
    параллелен либо оси $x$, либо оси $y$. Дан прямоугольник запроса
    $q$. Нужно найти все отрезки, пересекающие $q$. Утверждается, что
    не существует отрезков, лежащих в нем концом. (типа, все такие
    отрезки мы можем найти, рассмотрев только их концы в предыдущей
    задаче).

    Пусть найден такой отрезок $s$. Тогда, если он горизонтальный, он
    пересекает обе вертикальные грани $q$, а если вертикальный - обе
    горизонтальные. Значит, достаточно найти отрезки, что пересекают
    левую или нижнюю грани прямоугольника.

    Следовательно, задача свелась к нахождению множества
    горизонтальных отрезков, пересекающихся с данным вертикальным
    отрезком (с горизонтальным случай симметричный).

    Сначала решим более простую задачу: найдем все горизонтальные
    отрезки, пересекающие вертикальную прямую с координатой $q_x$.

**** *Interval tree*

     Эта задача, на самом деле, одномерная, $y$ - координаты не
     важны. Давайте попробуем построить эдакое бинарное дерево на
     отрезках. Найдем медиану $x_{mid}$ всех середин отрезков и разобъем отрезки
     на 3 множества, $I_{mid}, I_l, I_r$ - отрезки, пересекающие
     медиану, и лежащие целиком слева и справа соответственно. Для
     $I_l$ и $I_r$ рекурсивно построим поддеревья. А вот что делать с
     $I_{mid}$?

     У $I_{mid}$ есть одно хорошее свойство - все отрезки оттуда
     пересекают $x_{mid}$. Это значит, что если $q_x > x_mid$, то $q_x
     \in [l, r] \in I_{mid} \ \ \mathrm{iff} \ \ q_x \leq r$. Слева ситуация
     симметричная.

     Тогда, чтобы искать все отрезки из $I_{mid}$, входящие в ответ, за
     $O(k_{\nu})$ (где $k_{\nu}$ - это количество таких отрезков),
     достаточно хранить $I_{mid}$ в виде двух отсортированных
     списков. Первый список отсортирован по убыванию координаты правого
     конца отрезка, левый - по возрастанию координаты левого
     конца. Тогда, если $q_x \geq x_{mid}$, мы идем по правому списку
     до тех пор, пока координата очередного конца не станет меньше
     $q_x$. В обратном случае поступаем симметрично с левым списком.

     #+CAPTION: Устройство interval tree
     [[./figures/INT_TREES.png]]

     #+BEGIN_lemma
     Interval tree имеет глубину $O(\log n)$ и размер $O(n)$
     #+END_lemma

     #+BEGIN_proof
     Глубина: медиана на то и медиана, чтобы делить отрезки примерно
     пополам, поэтому дерево выходит сбалансированным.
     Размер: каждый отрезок входит только в один из $I_{mid}$, и в этом
     $I_{mid}$ он хранится дважды - в левом и правом списках. Итого
     $O(n)$ места.
     #+END_proof

     #+BEGIN_lemma
     Interval tree строится за $O(n \log n)$
     #+END_lemma

     #+BEGIN_proof
     Определим процедуру $\mathrm{buildTree}(I)$ так:
     1) Если $I = \emptyset$, возвращаем пустой лист, иначе
     2) Найдем медиану всех отрезков в $I$ (за $O(n)$)
     3) Разобьем $I$ на $I_{mid}, I_l, I_r$ по медиане
        (своп-своп-фигакс за $O(n)$)
     4) Посортим 2 раза $I_{mid}$ по координатам концов и сформируем
        списки $L_l, L_r$ (за $O(n_{mid} \log n_{mid}))$
     5) $\mathrm{buildTree}(I_l), \ \mathrm{buildTree}(I_r)$

     Всего без учета рекурсивных вызовов - $O(n + n_{mid} \log
     n_{mid})$

     Рекурсивных вызовов будет $O(\log n)$, поэтому с их учетом $O(n)$
     составляющая даст $O(n \log n)$. Суммарное время на сортировку
     всех списков также $O(n \log n)$, так как их суммарная длина $O(n)$.
     #+END_proof

     #+BEGIN_lemma
     Запрос в interval tree занимает $O(\log n + k)$ времени.
     #+END_lemma

     #+BEGIN_proof
     В каждом узле мы тратим $O(k_{\nu})$ на вывод всех подходящих
     отрезков в нем и делаем рекурсивный вызов. Так как рекурсивных
     вызовов будет $O(\log n)$, суммарное время работы $O(\log n) +
     \sum {O(k_{\nu})} = O(\log n + k)$
     #+END_proof

     Мы научились находить все горизонтальные отрезки, пересекающие
     прямую запроса. Но нужен-то нам отрезок, то есть нам надо как-то
     включить $y$ - координаты в игру. Внезапно мы можем это сделать
     достаточно просто - давайте в нашем interval tree $I_{mid}$
     хранить не как два отсортированных списка, а как range tree! В
     этом range tree мы будет делать запросы по бесконечному с одной
     стороны прямоугольнику: $(-\infty, q_x] \times [q_y,
     q_y']$, если $q_x < x_{mid}$, и $[q_x, \infty) \times [q_y,
     q_y']$ иначе.

     #+CAPTION: Вид запроса к range tree
     [[./figures/STAKAN.png]]

     #+BEGIN_lemma
     Interval tree c range tree вместо списков будет занимать $O(n \log
     n)$ памяти, построится за $O(n \log n)$, и будет отвечать на
     запрос за $O(\log^2 n + k)$
     #+END_lemma

     #+BEGIN_proof

     Память: каждый $I_{mid}$ занимает $O(n_{mid} \log n_{mid})$
     памяти, $\sum {n_{mid}} = n$, значит, $\sum {|I_{mid}|} = O(n \log
     n)$.

     Время построения: range tree строится за $O(n \log n)$, как и 2
     отсортированных списка, поэтому предыдущая оценка работает.

     Время запроса: запрос в range tree (с fractional cascading)
     занимает $O(\log n + k)$, всего таких range tree $O(\log n)$,
     поэтому суммарное время запроса $O(\log^2 n + k)$
     #+END_proof

**** *Priority search trees*

     Использовать range trees как подструктуру для interval trees - на
     самом деле громоздко и overkill. Сделаем структуру, которая
     специально заточена на обработку запросов в виде бесконечных
     стаканов.

     Priority search tree - это такой heap, очень похожий на
     декартку. Точки в нем упорядочены по приоритету -- $x$ -
     координате. Однако оно не является корректным деревом бинпоиска
     по $y$ - координате. Декартка нам не подходит, потому что в
     случае неравномерного разброса точек декартка получится очень
     несбалансированной. А в priority search tree мы при построении
     сыновей для текущего узла мы делим поддерево по медиане по $y$ -
     координате, поэтому дерево всегда получается сбалансированным.

     #+CAPTION: Priority-seacrh tree
     [[./figures/PS_TREES.png]]

     Приведем алгоритм построения priority-search tree.

     \begin{algorithm}[H]
      \SetKwFunction{BuildPST}{BuildPST}%
      \func{\BuildPST{P}}{
        \KwData{Набор точек $\{p_i\}$, отсортированный по $x$ - координате}
        \KwResult{Корректное PST на точках}
        $V_p \longleftarrow p_1$\;
        $y_{mid} \longleftarrow$ медиана $\{ p_2, ... , p_n \}$\;
        $P_l \longleftarrow \{ p \in P \setminus \{p_1\} \ | \ p_y < y_{mid} \}$\;
        $P_r \longleftarrow \{ p \in P \setminus \{p_1\} \ | \ p_y \geqslant y_{mid} \}$\;
        $V_l \longleftarrow \ $ \BuildPST{$P_l$}\;
        $V_r \longleftarrow \ $ \BuildPST{$P_r$}\;
        return $V$\;
     }
     \caption{Алгоритм построения PST}
    \end{algorithm}

    #+BEGIN_lemma
    Этот алгоритм работает за $O(n \log n)$
    #+END_lemma

    #+BEGIN_proof
    Сортировка по иксу работает $O(n \log n)$. Шаг алгоритма без учета
    рекурсивных вызовов работает за $O(n)$, а глубина рекурсии $O(\log
    n)$. Итого $O(n \log n)$
    #+END_proof

    *Замечание*: Если отсортировать массив не по $x$, а по $y$, то
    можно будет построить PST как декартку снизу вверх за $O(n)$.

    Очевидно, что PST занимает $O(n)$ памяти.

    В таком дереве мы можем выдать все точки, лежащие левее некоего
    $q_x$, за $O(k)$. Действительно - просто спускаемся вглубь и
    выдаем все подходящие точки, пока они подходят. Если не подходит
    какая-то точка - не подходит и все ее поддерево.

    Зато теперь мы понимаем, как отвечать на "стаканные"
    запросы. Приведем алгоритм:

    \begin{algorithm}[H]
      \SetKwFunction{QueryPST}{QueryPST}%
      \func{\QueryPST{$v$, $(-\infty, q_x] \times [q_y, q_y']$}}{
        \KwData{Корень PST и область запроса ('стакан')}
        \KwResult{Набор всех точек из дерева, удовлетворяющих запросу}
        Идем вниз дерева, ищем $q_y$ и $q_y'$. Обозначим как $v_{split}$ узел, на котором пути поиска разделятся\;
        \For{$u$ -- узел на пути поиска $q_y$ или $q_y'$}{
          \If{$u_p \in (-\infty, q_x] \times [q_y, q_y']$}{report $u_p$}
        }
        \For{$u$ -- узел на пути поиска $q_y$ в левом поддереве $v_{split}$}{
          \If{путь поиска поворачивает влево}{report-all($u_r$, $q_x$)}
        }
        \For{$u$ -- узел на пути поиска $q_y'$ в правом поддереве $v_{split}$}{
          \If{путь поиска поворачивает вправо}{report-all($u_l$, $q_x$)}
        }
      }
     \caption{Алгоритм запроса в PST}
    \end{algorithm}

    #+CAPTION: Иллюстрация к алгоритму запроса в PST
    [[./figures/PS_QUERY.png]]

    #+BEGIN_lemma
    Запрос в PST работает за $O(\log n + k)$
    #+END_lemma

    #+BEGIN_proof
    Длина пути поиска в дереве -- $O(\log n)$, а кроме спуска по этому
    пути мы только выводим вершины, попавшие в ответ. Итого $O(\log
    n + k)$
    #+END_proof

    #+BEGIN_lemma
    Interval tree c двумя PST вместо списков будет занимать $O(n)$ памяти,
    построится за $O(n \log n)$, и будет отвечать на запрос за
    $O(\log^2 n + k)$
    #+END_lemma

    #+BEGIN_proof
    PST занимает столько же места ($O(n)$) и строится такое же время,
    как списки ($O(n \log n)$), поэтому оценки на память и
    препроцессинг такие же. Время ответа на запрос такое же, как у
    layered range tree, поэтому и оценка времени ответа аналогичная
    ($O(\log^2 n + k)$)
    #+END_proof

*** 3 Нахождение всех прямоугольников, в которые попадает точка.
    CLOSED: [2016-01-10 Sun 15:57]
    Каждый axis-aligned прямоугольник можно задать 2 отрезками - его
    проекциями на оси $x$ и $y$. Задача проверки попадания точки в
    прямоугольник сводится к проверке того, что проекции точки
    попадают в соответствующие проекции прямоугольника.

    Сделаем двухуровневый interval tree: дерево верхнего уровня будет
    построено по $x$ - проекциям прямоугольников. $I_{mid}$ в этом
    дереве будем хранить в виде обычного interval tree, но построенного
    уже по $y$ - проекциям прямоугольников, попавших в $I_{mid}$.

    Очевидно, что такая структура сохранит размер и время построения
    обычного interval tree (так как обычное interval tree строится за
    $O(n \log n)$ и занимает $O(n)$ места, ровно как два сортированных
    списка). И запрос в такой структуре будет выполняться за $O(\log^2
    n + k)$, аналогично interval tree с PST.
** 3 Пересечение прямоугольника с множеством непересекающихся отрезков.
   CLOSED: [2016-01-10 Sun 04:11]
   Если мы хотим пересекать прямоугольник с рандомно повернутыми
   отрезками, идея interval tree не работает. Сделаем другую
   структуру, она будет опираться не на факт axis-aligned'ности
   отрезков, а на факт их непересекаемости.

*** 3 Segment tree
    CLOSED: [2016-01-10 Sun 04:11]
    Это не то дерево отрезков, к которому мы привыкли.

    Посмотрим на одномерный случай (та же задача, что решалась с
    пом. interval tree). Пусть $I = \{[x_1 : x_{1}'], [x_2 : x_{2}'],
    ..., [x_n : x_{n}']\}$ -- множество отрезков в $\R$. Возьмем концы
    этих отрезков и отсортируем их, получим точки $p_1, p_2, ...,
    p_m$. Назовем множеством элементарных интервалов $E = \{
    (-\infty : p_1), [p_1 : p_1], (p_1 : p_2), ..., (p_m : +\infty)
    \}$.

    Построим на множесте $E$ сбалансированное дерево поиска. Листьями
    этого дерева являются сами элементарные интервалы, а внутренними
    узлами -- их объединения. Обозначим интервал, сопоставленный узлу
    $v$ как $Int(v)$.

    Если мы для каждого узла -- элементарного интервала -- будем
    хранить список отрезков из $I$, в которые он входит, мы сможем
    легко найти все отрезки, содержащие точку запроса $q_x$. Но это
    супер-неэффективно по памяти, если у нас есть куча перекрывающихся
    отрезков (будет $O(n^2)$). Но это можно исправить! В уже
    построенное дерево на элементарных интервалах будем вставлять
    очередной отрезок сверху вниз, оставляя его в тех узлах, которые
    он полностью покрывает.

    #+CAPTION: Структура Segment tree
    [[./figures/SEG_TREE.png]]

    Обозначим множество отрезков из $I$, хранящихся в узле $v$, как $I(v)$

    \begin{algorithm}[H]
      \SetKwFunction{InsertSegment}{InsertSegment}%
      \func{\InsertSegment{v, $[x, x']$}}{
        \KwData{Корень дерева и вставляемый отрезок}
        \KwResult{Дерево, в которое вставлен отрезок}
        \eIf{$Int(v) \subset [x, x']$}{
          $I(v) = I(v) \cup \{[x, x']\}$
        }{
          \If{$Int(v_l) \cap [x, x'] \neq \emptyset$}{
            \InsertSegment{$v_l$, $[x, Int(v_l)_r]$}
          }
          \If{$Int(v_r) \cap [x, x'] \neq \emptyset$}{
            \InsertSegment{$v_r$, $[Int(v_r)_l, x']$}
          }
        }
      }
      \caption{Вставка отрезка в дерево}
      \end{algorithm}

    #+BEGIN_lemma
    1) Такое дерево строится за $O(n \log n)$
    2) Оно занимается $O(n \log n)$ памяти
    #+END_lemma

    #+BEGIN_proof
    1) *Время построения*: Само дерево строится, как любое дерево
       бинпоиска $O(n \log n)$. Вставка отрезка -- по алгоритму выше
       -- занимает $O(\log n)$, всего отрезков $O(n)$, итого $O(n \log
       n)$.

    2) *Память*: Посмотрим, в каких из узлов дерева может содержаться
       некий отрезок $[x, x']$. Заметим, что на одной и той же глубине
       в дереве отрезок может содержаться не более, чем в 2 узлах --
       по построению алгоритма. Сдедовательно, дерево содержит $O(\log
       n)$ копий каждого отрезка. Итого $O(n \log n)$ памяти.
    #+END_proof

    *Возвращаемся к двумерному случаю*

    \begin{wrapfigure}{l}{0.3\textwidth}
    \centering
    \includegraphics[width=0.3\textwidth]{./figures/SEG_SUBTREE.png}
    \caption{Структура данных 2-го уровня: дерево поиска}
    \end{wrapfigure}

    Пусть мы хотим пересечь множество непересекающихся отрезков с
    вертикальным отрезком ${q_x} \times [q_y, q_y']$. Построим segment
    tree для проекций отрезков на ось $x$ -- сможем находить все
    отрезки, пересекающие вертикальную прямую $q_x$. Заметим, что так
    как отрезки непересекающиеся, то в пределах одного элементарного
    интервала они не меняют своего порядка по $y$. Значит, мы можем
    хранить $I(v)$ для каждого узла как дерево поиска по отрезкам, в
    котором сможем делать запросы по точке пересечения (как статус
    Бентли-Оттмана)

    Так как запрос в дереве поиска выполняется за $O(\log n)$ без
    учета вывода ответа, и таких деревьев поиска надо проверить
    $O(\log n)$, время ответа на запрос в segment tree составляет
    $O(\log^2 n + k)$

    \clearpage

* 1 3:  Пересечение отрезков и поворот                              :volhovm:
  Рассмотрим задачу проверить пересечение отрезков.

  Вот есть у нас \(S_{1}=(p_{11},p_{12}), S_{2}=(p_{21},p_{22})\).

  В общем случае с Евклидовым пространством возникакуют какие-то
  проблемы, поэтому рассмотрим следующее определение Афинного
  пространства:

  A -- аффинное пространство, если A -- такой набор точек, что:
  1. В пространстве существует хотя бы одна точка.
  2. \(A, B, \leftrightarrow v = \vect{A B}\), причем \(B = A + v\).
  3. Точка + вектор = точка.
  4. ... и еще 40 аксиом векторного пространства

  Аффинное пространство отличается от стандартного евклидового тем,
  что в нем все точки равноправны, то есть ноль не зафиксирован. Типа
  у нас в этом пространстве есть точки, а векторы строятся из них.

  Рассмотрим гиперплоскость в n-мерном аффинном пространстве. Она,
  очевидно, задается $n-1$ вектором, или как минимум $n$ точками.

  Рассмотрим произвольную точку $A$ и набор векторов: $AP_1 \cdots
  AP_n$. Тогда если точка $A$ принадлежит гиперплоскости, то такой
  набор, очевидно, линейно зависим.

  Возьмем другую случайную точку $B$ и посмотрим, как меняются
  координаты при переходе из системы координат, связанной с $A$ в
  систему, связанную с $B$ (очевидно, что такой набор векторов может
  задавать базис, если он ЛНЗ).

  \begin{thm}[О повороте]
  Тут должно быть какое-то утверждение о повороте.
  \end{thm}

  \begin{proof}

  Рассмотрим точку $X$ в базисах из векторов $\{\vect{AP_i}\}_i$ и
  $\{\vect{BP_i}\}_i$. Тут точки ${P_i}$ задают гиперплоскость, то есть
  принадлежат ей и не линейно зависимы друг относительно друга в ней.

  \[
  X = X_A^1\vect{A P_1} +
      X_A^2\vect{A P_2} +
      \cdots +
      X_A^n\vect{A P_n}
    = X_B^1\vect{B P_1} +
      X_B^2\vect{B P_2} +
      \cdots +
      X_B^n\vect{B P_n}
  \]

  Для каждого вектора $\vect{AP_i}$ выразим его в базисе векторов
  ${\vect{BP_i}}$.

  \begin{align*}
  &\vect{AP_1} =
         \alpha_1^1\vect{B P_1} +
         \cdots +
         \alpha_1^n\vect{B P_n}\\
  &\cdots \\
  &\vect{AP_n} =
         \alpha_n^1\vect{B P_1} +
         \cdots +
         \alpha_n^n\vect{B P_n}
  \end{align*}

  Подставим выраженные $AP_i$ в первое уравнение.

  \begin{align*}
  X &= X_A^1\left(\sum\alpha_1^i\vect{BP_i}\right) +
       X_A^2\left(\sum\alpha_2^i\vect{BP_i}\right) +
       \cdots +
       X_A^n\left(\sum\alpha_n^i\vect{B P_i}\right) \\
    &= \vect{BP_1} \left(\sum\alpha_i^1X_A^i\right) +
       \vect{BP_2} \left(\sum\alpha_i^2X^i_A\right) +
       \cdots +
       \vect{BP_n} \left(\sum\alpha_i^nX_A^i\right)
  \end{align*}

  Сопоставив это с $X$, выраженным через $\{\vect{BP_i}\}_i$,
  получим следующую зависимость:

  \begin{align*}
    \left(X_B^1,X_B^2,\cdots,X_B^n\right)
  = \left(X_A^1,X_A^2,\cdots,X_A^n\right)
    \times
    \begin{pmatrix}
     \alpha_1^1 & \cdots & \alpha_1^n \\
     \vdots     & \ddots & \vdots     \\
     \alpha_n^1 & \cdots & \alpha_n^n
    \end{pmatrix}
  + \left(\vect{BA}^1,\cdots,\vect{BA}^n\right)
  \end{align*}

  Последнее --- вектор перехода из точки $B$ в $A$.
  Пусть дана точка $O$, которая воспринимается как ноль координат. Пусть
  также дана точка $O'$, которая выражается через $O$.
  Тогда матрица $A$ записывается следующим образом:
  \[
  A =
  \begin{pmatrix}
    P_1 - O' \\
    P_2 - O' \\
    \cdots  \\
    P_n - O'
  \end{pmatrix}
  \]

  Тут $P_i$ и $O'$ -- это точки, координаты которых записаны отнсительно базиса
  $O\{e_1,\cdots,e_n\}$.

  Заметим, что мы можем разбить все пространство на три класса согласно того,
  какой знак перехода из $O$ в $O'$. $A$ \--- матрица перехода от $O$ к $O'$,

  Ориентация \--- свойство точки относительно базиса $O\{e_1,\cdots,e_n\}$ и
  гиперплоскости, заданной точками $\{P_i\}_{i=1}^n$.

  Известный факт из линейной алгебры:
  \[
   \begin{vmatrix}
    \vect{P_1} & 1      \\
    \vect{P_2} & 1      \\
    \vdots     & \vdots \\
    \vect{P_n} & 1      \\
    \vect{A}   & 1
   \end{vmatrix}
  =
   \begin{vmatrix}
    P_1 - A \\
    P_2 - A \\
    \vdots  \\
    P_n - A
   \end{vmatrix}
  \]

  Покажем, что знак детерминанта матрицы $A$ действительно зависит от положения
  точки относительно гиперплоскости. Возьмем $A$, $B$, рассмотрим множество
  точек $\{\vect{A}t + \vect{B}(1-t)\}$.

  *тут какая-то магия, TODO*

  \end{proof}

  \clearpage
* 3 4:  Локализация в многоугольнике                                :avbelyy:
   Задача: есть многоугольник P. Задается точка q в
   пространстве. Нужно определить, находится ли эта точка внутри или
   снаружи многоугольника.
** 3 Выпуклый многоугольник
   Время работы -- $O(\log{n})$.

   Пусть задан выпуклый многоульник с вершинами, упорядоченными против часовой
   стрелки и произвольная начальная точка $p_0$. Тогда:

   - Если q лежит левее грани $p_0 p_1$ или правее грани $p_0 p_{n-1}$, точка находится снаружи многоугольника.
   - Иначе бинпоиском найдем ребро $p_i p_{i+1}$ такое, что
     $turn(p_0, p_i, q)$ и $turn(p_0, p_{i+1}, q)$ имеют разный
     знак.
   - Проверим поворот $turn(p_i, p_{i+1}, q)$.
     - Если он левый -- точка находится внутри.
     - Если правый -- снаружи.
** 3 Невыпуклый многоугольник
   Время работы -- $O(n)$.

   - Пустим луч из точки вдоль оси X, посчитаем количество пересечений с границей многоугольника.

       *Замечание:* если луч пройдет по границе многоугольника, то
     какие-то пересечения учтутся дважды. Условимся, что при
     пересечении с горизонтальным ребром мы на него забиваем, а с
     негоризонтальным по точке Q -- учитываем, если Q -- верхняя точка
     для ребра.

   - Тогда, если количество пересечений чётно, точка находится внутри.
   - Если нечётно -- снаружи.

   #+CAPTION: Все случаи пересечения луча из точки q с границей невыпуклого P.
   [[./figures/POINT_IN_POLY.png]]

   В задачах с целочисленными координатами точек можно пускать луч под
   небольшим наклоном, так, чтобы он наверняка не проходил через точки
   с целочисленными координатами. Тогда считать пересечения будет
   намного проще.

   \clearpage

* 2 5:  Статические выпуклые оболочки в $\R$                    :flyingleafe:
** 3 Джарвис (заворачивание подарка)
   CLOSED: [2016-01-07 Thu 17:12]
   1. Берем самую нижнюю левую точку $p_0$.
   2. За $O(n)$ перебираем все точки, берем минимальную точку по углу относительно $p_0$.

      *Пояснение*: Пусть мы хотим сравнить по этому параметру точки $p_i$ и $p_j$.
      Тогда $p_i < p_j \Leftrightarrow turn(p_0, p_i, p_j) < 0$.
   3. Добавляем выбранную точку в оболочку, проделываем то же самое с ней и т. д.

   Общее время работы, очевидно, $O(n^2)$

   *Доказательство корректности*

   Пусть после завершения Джарвиса осталась точка $P$, не лежащая внутри
   полученной оболочки. Это значит, что она лежит справа от некоторого ребра $AB$
   (считаем, что ребра оболочки упорядочены против часовой стрелки, так что все внутренние
   точки лежат слева от них).

   Но тогда $P$ меньше по повороту относительно $A$ чем $B$.
   Значит, мы должны были выбрать ее, а не $B$, для построения очередного ребра оболочки,
   когда мы рассматривали точку $A$. *Противоречие*. Следовательно, такой точки $P$ не существует.
** 3 Грэм
   CLOSED: [2016-01-07 Thu 17:12]
   Возьмем самую левую нижнюю точку p. Отсортируем все остальные точки по повороту,
   который они образуют с этой каким-нибудь нормальным алгоритмом (за $O(n \log n)$).
   Если все три точки лежат на одной прямой, то меньшей считается та точка, которая ближе к p.

   Положим в стек точку p и первую точку из отсортированного списка остальных. Далее идем
   по всем точкам из списка и делаем следующее:

   1. Обозначим рассматриваемую точку как a, а последние 2 точки, лежащие на стеке - как b и c.
   2. Если $turn(c, b, a) \geq 0 (правый)$, то скидываем со стека точку b и возвращаемся к пункту 1
   3. Иначе кладем a на стек и рассматриваем следующую вершину по списку.

   В конце в стеке будут лежать вершины выпуклой оболочки.

   *Корректность*

   Докажем корректность алгоритма по индукции.

   * *База*
     На третьем шаге алгоритм, очевидно, построит корректную выпуклую оболочку для первых 3 точек
     (просто потому, что невыпуклую построить нельзя))) )
   * *Переход*
     Пусть на k - 1 шаге построена корректная выпуклая оболочка для первых k - 1 точек.
     Докажем, что на k-ом шаге будет построена корректная выпуклая оболочка для k точек.
     1) В силу отсортированности точек по повороту, точки $p_1 .. p_{k-1}$ лежат слева от ребра
        $p_k p_0$ (возможно, $p_{k-1}$ лежит на ребре)
     2) На шаге 2 алгоритма из прошлой оболочки будут выброшены все вершины, видные из $p_k$,
        то есть, ни с каким из оставшихся в оболочке ребер $p_k$ не будет образовывать правый поворот.
     3) Следовательно, все ребра новой оболочки будут образовывать со всеми остальными вершинами левый (или нулевой)
        поворот, что нам и нужно.

    *Асимптотика*

    Сортировка точек за $O(n \log n)$. Проход по точкам за $O(n)$, так как каждая точка может 1 раз быть
    добавлена в стек и 1 раз из него удалена, всего точек $n$. Итого $O(n \log n)$.

** 3 Эндрю
   CLOSED: [2016-01-07 Thu 17:12]
   Эндрю - это почти в точности Грэм.
   1. Возьмем самую левую и самую правую точки - $p_0$ и $p_n$
   2. Разделим все множество точек на "верхние" и "нижние" - выше прямой $p_0 p_n$ и ниже ее, соответственно.
   3. Для "верхних" и "нижних" точек построим верхнюю и нижнюю оболочку соответственно.
      Строить будет Грэмом, но представляя, что точка $p_0$ лежит в $\inf$ и $-\inf$ соответственно.
      Тогда мы можем сказать, что обычная сортировка точек по координате $x$ эквивалентна сортировке по
      повороту относительно бесконечно удаленной точки. Значит, отсортируем на самом деле точки каждой
      из половин по $x$-координате и запустим Грэма.
   4. Объединим верхнюю и нижнюю оболочки.

   *Корректность*

   Грэм корректен, а значит, верхняя и нижняя оболочки будут корректны. Тогда и вся оболочка корректна.

   *Асимптотика*

   Ровно такая же как у Грэма. Но на практике Эндрю чуть быстрее лишь потому, что сортировка идет
   по $x$-координате, а не по повороту, и это быстрее.
** 3 Чен
   CLOSED: [2016-01-07 Thu 17:12]
   Чен - это продукт классической методики улучшения каких-то алгоритмов:
   возьмем 2 известных алгоритма - один просто хороший, а другой - обладающий
   неким нужным свойством. Разобьем задачу на подзадачи, подзадачи решим одним
   алгоритмом, а объединим решения другим. Останется подобрать константу посерединке.

   Так и здесь - Чен объединяет просто хороший алгоритм Грэма с output-sensitive
   алгоритмом Джарвиса, получая хороший output-sensitive алгоритм с временем работы $O(n \log k)$,
   где $k$ - количество вершин выпуклой оболочки.

   *Алгоритм*

   Разобьем все точки на произвольные группы по $m$ (или меньше) штук в каждой.
   Тогда всего групп будет $r = \frac{n}{m}$

   1. Для каждой группы в отдельности найдем ее выпуклую оболочку Грэмом за $O(m \log m)$.
      Значит, всего на этот шаг уйдет
      $O(r) \cdot O(m \log m) = O(\frac{n}{m}) \cdot O(m \log m) = O(n \log m)$ времени.
   2. Теперь запустим на всех точках Джарвиса. Однако заметим, что среди точек, входящих в одну
      группу, мы можем выбрать самую левую по повороту бинпоиском - так как для группы построена
      выпуклая оболочка. (Бинпоиск - это вот эта прекольная тема с вложенными выпуклыми оболочками, например)

      Значит, на одном шаге Джарвисанам нужно перебрать все группы, среди которых подходящую точку мы ищем за $O(\log m)$.
      Итого - $O(r \log m) = O(\frac{n}{m} \log m)$. Всю выпуклую оболочку мы найдем за $O(\frac{kn}{m} \log m)$.

   Сложив асимптотики двух шагов, видим, что полное время работы - $O(n (1 + \frac{k}{m}) \log m)$. Из этого
   получится желанная асимптотика $O(n \log k)$, если мы с самого начала выберем $m = k$. Но как нам это сделать?

   Давайте просто перебирать m, начиная с маленького. Если вдруг во время выполнения на m + 1 шаге Джарвис
   еще не построил выпуклую оболочку, значит, $m < k$ и нам надо взять его побольше.

   Но как перебрать $m$ достаточно быстро, и при этом не переборщить на последнем шаге?
   Давайте возьмем начальный $m = 2$ и на каждом шаге перебора будем возводить его в квадрат.
   Иными словами, $m = 2^{2^t}$, и $t$ перебирается от 0 до $\lceil \log\log k \rceil$

   Докажем, что такой перебор не замедлит общее время работы:

   $\sum\limits_{t=0}^{\lceil \log\log k \rceil} O\left(n \log(2^{2^t})\right) = O(n) \sum\limits_{t=0}^{\lceil \log\log k \rceil} O(2^t) = O\left(n \cdot 2^{1+\lceil \log\log k \rceil}\right) = O(n \log k)$

   Итак, мы получили алгоритм с гарантированным временем работы $O(n \log k)$.

** 2 QuickHull
   Как QuickSort, только QuickHull.

   1. Возьмем крайние по иксу точки (они точно войдут в оболочку), обозначим их как $p_0$ и $p_1$
   2. Разобьем множество на точки, лежащие ниже и выше прямой $p_0 p_1$ (посвопаем 2 указателями, как в квиксорте)
   3. Для верхнего множества найдем самую удаленную от $p_0 p_1$ точку - $q_1$
   4. Выкинем все точки, лежащие внутри треугольника $p_0 p_1 q_1$
   5. Разделим оставшиеся точки на $S_1$ - лежащие выше $p_0 q_1$, и $S_2$ - лежащие выше $q_1 p_1$.
   6. Рекурсивно повторим пункт 3 для $S_1$ и $S_2$.
   7. Повторим пункт 3 для нижнего множества.
   8. Объединим верхнюю и нижнюю оболочки

   Утверждается, что для случайного набора точек этот алгоритм отработает за $O(n \log n)$
   Понятно, что в худшем случае алгоритм отработает за $O(n^2)$ - мы можем построить такой
   выпуклый многоугольник, что на шаге 4 никогда ничего не будет выкинуто, а на шаге 5
   в $S_1$ будут входить все оставшиеся точки.

   Докажем, что для случайно разбросанных точек алгоритм отработает за $O(n \log n)$

   *WARNING: ЭТО ГОВНО Я ПРИДУМЫВАЛ САМ (почти)*

   Пусть время, необходимое для нахождения оболочки над некой прямой и множеством точек
   $S$ есть $T(S)$
   Тогда $T(S) = O(|S|) + T(S_1 \in S) + T(S_2 \in S)$, где $S_1$ и $S_2$ из пункта 5.

   За $O(|S|)$ мы находим самую удаленную от прямой точку $q_1$. Заметим, что вообще все рассматриваемые точки
   находятся в прямоугольнике, ограниченном прямой $p_0 p_1$ снизу, и вершиной $q_1$ сверху.
   Заметим также, что треугольник $p_0 q_1 p_1$ занимает половину площади этого прямоугольника.
   Это значит, что при равномерном распределении точек внутрь треугольника попадет примерно половина всех точек.
   А значит, количество рассматриваемых точек на следующем шаге рекурсии будет меньше в 2 раза.
   Значит, всего шагов рекурсии будет $O(\log n)$, что в итоге дает оценку $O(n \log n)$.

** 0 Оболочка многоугольника
** 0 Оболочка полилинии
   \clearpage
* 3 6:  Динамическая выпуклая оболочка                              :volhovm:
  CLOSED: [2016-01-09 Sat 01:23]
  #+CAPTION: Иллюстрации к динамической выпуклой оболочке
  [[./figures/CH_DYN.jpg]]

** 3 Задача объединения двух верхних $CH$
   CLOSED: [2016-01-09 Sat 01:07]
   Начнем с подзадачи: пусть у нас есть две каких-то верхних оболочки в
   $\mathbb{R}^2$ , разделенных по иксу (~CH_DYN_1~). Мы хотим
   объединить эти верхних оболочки, проведя касательную сверху. Как
   такую касательную построить? (inb4 такая существует, потому что
   "палка сверху падает на холмики"). Как искать такую касательную за
   логарифм?

   Очевидно, что касательная не проходит по экстремальным точкам
   (нарисуем большой холмик и рядом маленький).

   Как добиться асимптотики $O(\log{n})$? Предположим, что есть пара
   точек на холмах. Будем типа пользоваться некоторым подобием
   бинпоиска на двух холмах сразу -- держать четыре границы
   одновременно. Ну, два массива -- это два множества точек для двух
   оболочек, отсортированных по иксу (См. ~CH_DYN_2~).

   (~CH_DYN_3~) описывает классификацию всех попаданий касательной к
   кускам выпуклой оболочки для левой и правой кучи. Эта классификация
   важна, так как по ней мы будем определять текущее состояние
   бинпоиска. Как эти состояния отличать, понятно -- считаем повороты
   касательной с ребром, куда она попала. Случаи с двумя точками по
   одну сторону классифицируются поворотом.Проверка на два случая
   делается за $2\times2 = 4$ поворота.

   Рассмотрим случай $A$ в ~CH_DYN_2~. Случай $A$ распознается так: это
   случай слева a), а справа г). Рассмотрим прямую $l$ и какую-то
   касательную к левой куче. Утверждается, что если мы будем
   поворачивать касательную вокруг точки касания, поворачивать вниз, то
   пересечение касательной и $l$ как точка, будет опускаться вниз
   (~CH_DYN_4~). Из этого следует, что можно отрезать нижние куски
   выпуклых оболочек.

   Рассмотрим остальные случаи, например $B$ в ~CH_DYN_2~. В этом
   случае мы можем откинуть нижнюю часть правой оболочки. Симметричный
   случай тоже очевиден.

   Случай с двумя касательными (случаи в), e) в диаграмме) тоже
   распознается однозначно и есть ответом бинпоиска.

   Пусть на правом холме у нас касательная, а на левом точка из случая
   a) -- случай $A$ в ~CH_DYN_5~. Тогда на левом холме мы можем
   откусить нижний кусок, а на правом -- левый нижний от
   касательной. Симметрично тоже. $B$ тоже так решается, то есть можно
   слева откусить нижний, а справа нижний левее точки касания.

   Теперь рассмотрим самый нетривиальный случай (~CH_DYN_6~): пусть
   слева б), а справа д). Рассмотрим пересечение прямых $l_1$ и
   $l_2$. Прямые проведем через текущие вершины и следующие
   выше. Проверим точку $L$ пересечения $l_2$ и $l_2$. Тогда если
   прямая $L$ лежит полностью в интервале между холмами, то можем
   выкинуть и у левого и у правого нижние куски. Если точка $L$ лежит в
   левом холме (левее самой правой точки левого холма), то мы
   выкидываем весь нижний кусок только левого холма вместе с этой
   точкой. Аналогично с правым холмом.

   Теперь мы умеем решать задачу найти касательную двух верхних
   полуоболочек.

   Задача поиска всех четырех касательных для двух выпуклых множеств
   сводится к этой: разобьем на несколько подмножеств (верхние и
   нижние) и решим алгоритмом выше.

   В реализации алгоритма удобно хранить две оболочки skip-листами и
   вместо бинпоиска просто спускаться на нижний уровень и продолжать
   алгоритм на нем. Вот мы идем по какому-то уровню, выбираем
   вершину. Пусть мы определили, что нам необходимо отрезать какую-то
   часть оболочки, к примеру, левую -- просто пойдем вправо по
   текущему уровню, пометив "отрезанную" вершину флагом. Спуск на
   нижний уровень будет происходить, если нужно пойти в какую-то
   сторону, а та вершина уже "отрезана".
** 3 Итеративный алгоритм
   CLOSED: [2016-01-09 Sat 01:23]
   Теперь мы хотим честного итеративного построения: есть некоторая
   структура, в которой мы храним верхнюю оболочку, и мы хотим ее
   быстро изменять (добавлять или удалять точки).

   Для начала вспомним, как мерджить skip-листы. Лист мы держим сверху
   за вершину самого высокого уровня, на каждом уровне мы можем
   распознать первую и терминальную вершины.
   * Сплит: дали нам вершинку, мы нашли ее в самом нижнем
     уровне. Запускаемся для левой стороны: удаляем вершину,
     обрезаем. Идем влево, пока не можем подняться наверх,
     поднимаемся, делаем вершинку терминальной на этом уровне, и так
     до верхнего уровня. Аналогично для правой стороны помечаем
     вершину первой, идем вправо, поднимаемся если можем, и так до
     самого высокого уровня.
   * Мердж делается так же, про доказательство асимптотики думать не
     надо (бернуллевость не испортится).

   Пусть есть оболочка, являющаяся общей частью двух оболочек
   подмножеств точек (~CH_DYN_7~). Есть также указатель на точку, по
   которой нужно разделиться. Причем у нас есть синяя и красная
   (карандашом) части. Тогда мы можем разделить нашу оболочку на две
   за $2*\log{n}$ на объединение двух скиплистов.

   ОБщая структура для хранения оболочки итеративно наивно
   представляется так: дерево, в котором листья -- наши точки, а
   другие узлы -- это верхняя оболочка сыновей. Это O(n\log{n})
   памяти. Такая структура имеет два недостатка -- памяти много и
   неочевидно, как делать удаление. Добавление реализуется
   прокидыванием вершины вниз и перестраиванием все оболочки вверх во
   время просеивания. Если дерево нужно балансировать, то во время
   поворотов нужно будет перестраивать узлы.

   Более удобная структура выглядит следующим образом: в самом верхнем
   узле будет храниться честная выпуклая оболочка всех точек. Не
   верхнем, будем хранить только ту часть выпуклой оболочки, которая
   не является общей с родителем. На ~CH_DYN_7~ "не общие части" как
   раз обозначены синим и серым цветом. Продавливание точки вниз
   становится существенно понятнее и проще: разбиваем текущую выпуклую
   оболочку (сначала корневую), объединяем за $\log{n}$ с
   детьми. Определяем, куда кидать точку -- влево или вправо. Ту
   часть, в которую не нужно добавлять, не трогаем. Так проходим вниз
   и добавляем вершинку. Заметим, что теперь уже не нужно хранить
   ничего в листах, так как два соседних листа однозначно определяются
   оболочкой в их родителе. Дальше строим оболочку и просеиваем
   вверх. При просеивании вверх берем двух детей, объединяем, отдаем
   родителю оболочку, себе оставляем только те части, которые не
   входят в парента. Удаление происходит аналогично.

   Итого конечный алгоритм поддерживает оболочку с удалением и
   добавлением за $\log^2{n}$.

   \clearpage
* 0 7:  Трехмерные выпуклые оболочки (CHN)                          :volhovm:
  Немножко модифицируем quickhull на плоскости, чтобы можно было
  очевидно его перенести в n-мерное пространство. Quickhull не
  работает хорошо с детерменированной прямой.

  Давайте выберем прямую $L_1L_2$. Зафиксируем в надмножестве случайную
  точку $A$. Все точки, которые попали в $L_1AL_2$
  выкидываем. Рассмотрим все точки, которые не попали
  внутрь. Подразобьем их лучами $L_1A$ и $L_2A$. Типа будем выбирать
  случайные точки вверху и продолжать выпуклую оболочку.

  Для каждого разбиения мы перебираем все точки и для каждой мы
  запоминаем грани, которые видно.

  Че делать в $n$-мерном пространстве? Возьмем произвольный
  тетраэдр. На самом деле лучше брать максимально большой
  тетраэдр. Потом для каждой новой случайной точки мы понимаем, к
  какой гране он принадлежит, какие грани эта точка видит.

  \clearpage
* 3 8:  Триангуляция (существование и ушная триангуляция)           :avbelyy:
** 3 Существование
   #+ATTR_LATEX: :options [Триангуляция]
   #+BEGIN_defn
   Разбиение многоугольника P на множество треугольников, чьи
   внутренние области попарно не пересекаются, а объединение дает
   многоугольник P.
   #+END_defn

   #+ATTR_LATEX: :options [простой многоугольник]
   #+BEGIN_defn
   Многоугольник без самопересечений.
   #+END_defn

   #+ATTR_LATEX: :options [О существовании триангуляции многоугольника]
   #+BEGIN_thm
   У любого простого многоугольника $P$ с $n$ вершинами всегда
   существует триангуляция, причем количество треугольников в ней
   равно $n-2$.
   #+END_thm

   #+BEGIN_proof
   Докажем оба утверждения по индукции.
   - *База* $n = 3$ -- у треугольника есть триангуляция, состоящая из 1
     треугольника))).
   - *Переход* Пусть для простых многоугольников с $k$ < $n$ вершинами
     существует триангуляция. Покажем, что и для $n$-угольников
     триангуляция существует.

     - Возьмем самую левую вершину многоугольника P, назовём её
       $v$. Тогда диагональю будет либо ребро:
       * между её соседями слева и справа;
       * между $v$ и вершиной $p$, наиболее удаленной от ребра между
         соседями и находящейся по одну сторону с $v$.
     - Диагональ поделит $P$ на многоугольники $P_1$ и $P_2$
       $(|P_1| + |P_2| = n + 2)$ меньшего размера, у которых по
       предположению существует триангуляция.
     - В триангуляции $P_1$ и $P_2$, также по предположению, будет
       соответственно $|P_1| - 2$ и $|P_2| - 2$ треугольника. Тогда в
       триангуляции $P$ будет $(|P_1| - 2) + (|P_2| - 2) = n - 2$
       треугольника.
   #+END_proof

** 3 Ушная триангуляция
   #+ATTR_LATEX: :options [Ухо]
   #+BEGIN_defn
   Вершина многоуольника $v_i$ называется ухом, если диагональ
   $v_{i-1}v_{i+1}$ лежит строго во внутренней области многоугольника.
   #+END_defn

   #+ATTR_LATEX: :options [О существовании двух ушей в многоугольнике]
   #+BEGIN_thm
   У любого простого многоугольника $P$ с $n$ вершинами всегда
   существует два не пересекающихся между собой уха.
   #+END_thm

   #+BEGIN_proof
   По индукции.

   - *База* $n = 4$ - всё ясно.
   - *Переход* Возьмём произвольную вершину $v$. Рассмотрим два случая:
     * $v$ -- ухо. Отрежем его, получим $n-1$-угольник, в котором, по
       предположению индукции, есть два непересекающихся уха. Они также являются
       ушами исходного $n$-угольника, поэтому теорема верна.
     * $v$ -- не ухо. Значит, треугольник $(prev(v); v; next(v))$
       содержит вершины $P$. Как и в теореме о существовании
       триангуляции, выберем наиболее ближнюю к $v$ вершину, поделим
       $P$ на $P_1$ и $P_2$ по диагонали, у $P_1$ и $P_2$ по индукции
       есть по два уха -- и вновь всё хорошо.
   #+END_proof

*** Алгоритм (ушная триангуляция)
   Будем перебирать вершины $n$-угольника, проверяя их на
   уховость. Когда найдем ухо -- вырежем его, и продолжим искать уши
   уже в $(n-1)$-угольнике.

   *Корректность* алгоритма следует из сущестования ушей в любом
   $n$-угольнике, доказанного выше.

   *Время работы* проверки на уховость -- $O(n)$. Всего проверяется
   $n - 3$ вершины. Значит, время работы всего алгоритма -- $O(n^2)$.

   \clearpage
* 3 9:  Триангуляция с заметающей прямой                            :avbelyy:
** 3 Идея и основные определения
   Заметим, что триангуляция выпуклого многоугольника делается очень
   просто за O(n). Однако побить произвольный P на выпуклые куски
   сложно. Придумаем что-то похожее, на что побить и что
   триангулировать будет несложно и недолго.

  #+ATTR_LATEX: :options [Монотонный многоугольник]
  #+BEGIN_defn
  Многоугольник P называется монотонным относительно прямой l, если
  любая l', ортогональная l, пересекает стороны P не более двух раз
  (то есть либо не пересекает P совсем, либо пересекает по
  точке или отрезку).
  #+END_defn

  #+ATTR_LATEX: :options [Y-монотонный многоугольник]
  #+BEGIN_defn
  Многоугольник, монотонный относительно оси Y.
  #+END_defn

  #+ATTR_LATEX: :options [start, end, split, merge и regular--вершины]
  #+BEGIN_defn
  Пусть \phi \--- внутренний угол при вершине в многоугольнике. Тогда
  назовем вершину:
  * Start \--- если два ее соседа лежат ниже ее самой и \phi < \pi.
  * Split \--- если два ее соседа лежат ниже ее самой и \phi > \pi.
  * End \--- если два ее соседа лежат выше ее самой и \phi < \pi.
  * Merge \--- если два ее соседа лежат выше ее самой и \phi > \pi.
  * Regular \--- если один сосед лежит выше, а другой ниже ее самой.
  #+END_defn

  #+ATTR_LATEX: :options [Достаточное условие y-монотонности]
  #+BEGIN_lemma
  Если в многоугольнике нет split-- и merge--вершин, то он y--монотонен.
  #+END_lemma

  #+BEGIN_proof
  Докажем контрапозицию этого утверждения: в любом y--немонотонном
  многоугольнике P имеется либо split--, либо merge--вершина.

  Поскольку P немонотен, есть горизонтальная прямая l, которая
  пересекает его больше двух раз. Возьмем ее так, чтобы первое
  пересечение проходило по отрезку [p; q]. Пройдемся наверх от вершины
  q, пока не упремся в точку r на прямой. Рассмотрим 2 случая:
  - (a) r $\neq$ p. Видно по рисунку, что самая высокая вершина на пути [q; r] будет split--вершиной.
  - (b) r = p. Пройдемся в другую сторону (на этот раз вниз) от p,
    снова пересечем прямую в точке r'. r' $\neq$ p, ведь это означало
    бы, что прямая пересекает многоугольник всего дважды. Значит, путь
    [q; r'] проходит под прямой l и самая нижняя вершина на этом пути
    будет merge--вершиной.
  #+END_proof

  #+ATTR_LATEX: :width 0.6\textwidth
  #+CAPTION: Два случая в лемме о достаточном условии.
  [[./figures/MONOTONE1.png]]
** 3 Алгоритм 1 (разбиение на монотонные части)
   В условиях предыдущей леммы становится понятен алгоритм разбиения
   многоугольника на монотонные куски: нужно избавиться от split-- и
   merge--вершин, проводя из них диагонали вниз и вверх
   соответственно.

   *Алгоритм:* пройдем заметающей прямой по всем вершинам
    многоугольника сверху вниз. Останавливаясь на split-- и
    merge--вершинах, будем проводить диагонали из них. Пусть $v_i$ --
    текущая вершина, $e_j$ и $e_k$ -- ближайшее слева и справа ребро
    от $v_i$ соответственно. Чтобы быстро получать левое ребро $e_j$
    для вершины, заведем бинарное дерево T на ребрах (типа упорядочим
    их слева направо). Ниже рассмотрим действия, предпринимаемые
    алгоритмом в разных типах вершин:
*** Split--вершина
    Мы хотим провести такую диагональ, которая точно будет лежать в P
    и не пересекать других ребер. Куда ее провести? Утверждается, что
    всегда подойдет *самая низкая вершина между $e_j$ и $e_k$ повыше
    l*. Заведем у ребер P дополнительное поле helper, куда будем
    записывать по ходу движения прямой вершины, видящее ребро слева от
    себя. Тогда в split--вершине просто посмотрим на helper($e_j$) --
    в нем и будет нужная нам вершина. Если helper($e_j$) == NULL,
    возьмем верхний конец $e_j$. Проведем диагональ [$v_i$;
    helper($e_j$)] и пойдем дальше.
    #+ATTR_LATEX: :width 0.3\textwidth
    #+CAPTION: Заметающая прямая l встретила split--вершину.
    [[./figures/MONOTONE2.png]]
*** Merge--вершина
    Merge--вершину мы встречаем раньше, чем ее диагональную пару,
    поэтому сразу диагональ из нее не можем. Но можем записать ее в
    helper($e_j$) и пойти дальше, а в следующей по ходу прямой вершине
    проверить, является ли helper($e_j$) merge--вершиной. Если
    является, незамедлительно проведем диагональ из нее. Если для
    merge--вершины не нашлось диагональной пары, соединим ее с нижним
    концом $e_j$.
    #+ATTR_LATEX: :width 0.3\textwidth
    #+CAPTION: Диагональ из merge--вершины проводится из вершины пониже.
    [[./figures/MONOTONE3.png]]
*** Start--вершина
    Вставим $e_i$ в T. Установим helper($e_i$) в $v_i$.
*** End--вершина
    Если в helper($e_{i-1}$) merge--вершина, то соединим ее диагональю
    с текущей. Удалим $e_{i-1}$ из T.
*** Regular--вершина
**** *P расположен справа от $v_i$.*
     Проделаем действия как бы для end-вершины ребра $e_{i-1}$ и
     start-вершины ребра $e_i$.
**** *P расположен слева от $v_i$.*
     Проведем ребро в helper($e_j$), если helper($e_j$) --
     merge--вершина. Установим helper($e_j$) в $v_i$.
** 3 Оценка времени работы алгоритма разбиения
   Оценим время работы такого алгоритма. События заметающей прямой --
   вершины многоугольника, их ровно n штук. Для каждой вершины
   выполняется константное количество манипуляций над деревом ребер T
   суммарной сложностью $O(\log{n})$ и, возможно, добавление диагоналей
   в P (это можно сделать за $O(1)$, если хранить многоугольник в
   двусвязном списке). Итоговая сложность -- $O(n \log{n})$,
   а занимаемая память -- $O(n)$.
** 3 Алгоритм 2 (триангуляция монотонного многоугольника)
   *Алгоритм:* пойдем сверху вниз по ребрам границы, добавляя
   диагонали пока это возможно.

   (1) Заведем дополнительно стек для вершин S, которые мы уже прошли,
   но которым все еще может понадобиться диагональ. Когда мы встречаем
   вершину, мы проводим максимально возможное количество диагоналей из
   нее в вершины стека.

   Заметим, что вершины в S имеют определенную форму: они образуют
   выпуклую воронку, все вершины которой представляют собой
   последовательную цепь вершин P и имеют внутренний угол > \pi.

   (2) Переберем вершины $v_i$, i=1..n-1. Посмотрим, какие ребра мы
   можем добавить к вершинам стека из текущей вершины $v_i$. Разберем
   два случая:
   - (a) Текущая вершина лежит напротив вершин S.

     Соединим диагоналями текущую вершину и все вершины стека. Кроме
     последней. Между последней и текущей, по инварианту, уже есть
     ребро (см. рис). Добавим вершину стека в стек обратно, потому что
     для нее еще не составлен треугольник, и сохраним инвариант воронки.
     #+ATTR_LATEX: :width 0.3\textwidth
     #+CAPTION: Случай (a): $v_i$ по разные стороны P.
     [[./figures/MONOTONE4.png]]

   - (b) Текущая вершина лежит на одной стороне с вершинами S.

     Вытащим и выкинем и стека первую вершину. С остальными проделаем
     следующее: вытащим и проверим, можем ли провести диагональ из нее
     в $v_i$. Если да - продолжим снимать со стека вершины, если нет -
     откатим стек до той вершины, до которой еще могли провести
     диагональ и остановимся. В конце положим еще $v_i$. Инвариант
     "выпуклой воронки" вновь сохраняется (см. рис).
     #+ATTR_LATEX: :width 0.7\textwidth
     #+CAPTION: Случай (b): $v_i$ по одну сторону P.
     [[./figures/MONOTONE5.png]]

  (3) Для последней вершины $v_n$ проведем диагонали ко всем вершинам
  стека, кроме первой и последней. После этого монотонная часть будет
  триангулирована.
** 3 Оценка времени работы алгоритма триангуляции
   - Шаг (1) занимает константное время.
   - Цикл на шаге (2) исполняется O(n) раз и каждая итерация может
     занять линейное время. Но заметим, что за итерацию в S положат не
     более 2х вершин, то есть суммарно O(n) push'ей и не больше
     pop'ов. Итого O(n).
   - Шаг (3) также занимает линейное время.

   Значит, справедливо следущее:
   #+BEGIN_lemma
   Алгоритм триангуляции монотонной части многоугольника работает за
   линейное время от числа вершин монотонной части.
   #+END_lemma

   #+BEGIN_thm
   Алгоритм монотонной триангуляции работает за $O(n \log{n})$ времени и использует $O(n)$ памяти.
   #+END_thm

   #+BEGIN_proof
   Алгоритм 1 работает за $O(n log{n})$ как доказано выше,
   алгоритм 2 работает за линейное от размера монотонной части
   время. Значит, суммарное время для всех частей P -- линейное от
   числа вершин P.

   Алгоритм 1 использовал двусвязный с вершин и двоичное дерево ребер,
   алгоритм 2 использовал стек вершин. Каждое ребро и вершина
   встречались в соответствующих структура не более 1 раза. Итого --
   $O(n)$ памяти.
   #+END_proof

   \clearpage

* 2 10: Полуплоскости и выпуклые оболочки                           :avbelyy:
  Задача: найти фигуру, образованную пересечением n полуплоскостей
  ($l_1$, $l_2$, ..., $l_n$), или сообщить, что оно пусто.

  Эту задачу можно решать разными способами, рассмотрим два из них.
** 3 Построение выпуклой оболочки
*** Сведение к двойственным задачам
   #+ATTR_LATEX: :options [Двойственные преобразования]
   #+BEGIN_defn
   Пусть точка $p = (a, b)$, прямая $l = (c, d)$.

   Тогда:
   * $p*$ -- двойственная прямая к p [p* = ax - b]
   * $l*$ -- двойственная точка к l [l* = (c, -d)].
   #+END_defn

   #+BEGIN_defn
   UH(P) -- верхняя выпуклая оболочка точек P.
   #+END_defn

   #+BEGIN_defn
   LE(L) -- граница фигуры, образованной пересечением полуплоскостей
   L, смотрящих вниз.
   #+END_defn

   Заметим, что найти фигуру -- это то же самое, что найти ее границу,
   поэтому поиск LE(L) -- то же самое, что исходная задача.

   #+BEGIN_thm
   Задача поиска LE(L) -- двойственная к задаче поиска UH(L*).
   #+END_thm

   #+ATTR_LATEX: :width 0.8\textwidth
   #+CAPTION: Пересечение полуплоскостей эквивалентно нахождению выпулкой оболочки.
   [[./figures/HALFPLANE.png]]

   #+BEGIN_proof
   Точка $p$ принадлежит $UH(P)$ $\Leftrightarrow$ \exists
   не-вертикальная прямая $l$, проходящая через $p$ так, что все
   остальные точки $P$ лежат ниже $l$.

   То же самое в двойственном пространстве: \exists точка $l*$,
   лежащая на прямой $p*$ так, что точка $l*$ лежит ниже всех
   остальных прямых из $P* \Leftrightarrow$ $l* \in LE(P*)$.

   Точки в P возрастают в UH(P) по x-координате. Прямые P* убывают в
   LE(P*) по углу наклона. Поскольку угол наклона прямой p* совпадает
   с x-координатой точки p, порядок UH(P) совпадает с порядком LE(P*).

   Следовательно, $UH(P) = LE(P*)$, или $UH(L*) = LE(L)$.
   #+END_proof

   *Замечание:* как можно догадаться, пересечение полуплоскостей,
    смотрящих вверх -- это задача, двойственная к поиску нижней
    выпуклой оболочки. Это нетрудно доказать, но мы оставим это в
    качестве упражнения читателю.
*** Алгоритм
    Для начала заметим, что получившаяся фигура будет выпуклой, поскольку:
    - полуплоскость выпукла;
    - пересечение выпуклых фигур выпукло.

    Учитывая вышедоказанное, алгоритм получается такой:
    1. Поделим плоскости на "смотрящие" вниз и вверх.
    2. Найдем пересечение плоскостей, смотрящих вниз.
    3. Найдем пересечение плоскостей, смотрящих вверх.
    4. Объединим фигуры, полученные на 2 и 3 шаге.

    #+BEGIN_thm
    Время работы алгоритма -- $O(n \log{n})$.
    #+END_thm

    #+BEGIN_proof
    Деление плоскостей по углу занимает $O(n)$ времени. Пересечение
    плоскостей, смотрящих вниз/вверх имеет ту же асимптотику, что и
    поиск выпуклой оболочки, то есть $O(n \log{n})$. Объединить
    выпуклые фигуры также можно за $O(n \log{n})$ (есть какой-то
    алгоритм).
    #+END_proof
** 2 Разрезание прямоугольника
   Пусть мы знаем, что, если фигура в пересечении существует и
   ограничена, то всегда принадлежит какому-то прямоугольнику
   $D_0$. Тогда задачу можно решить следующим способом:

   \begin{algorithm}[H]
   \SetKwFunction{CutPoly}{Cut-Polygon}%
   \func{\CutPoly{$D_0$, $\{l_i\}$}}{
     \KwData{Ограничивающий прямоугольник $D_0$\\
             Прямые, задающие полуплоскости $\{l_i\}$}
     \KwResult{Фигура $D_n \subset D_0$, образованная пересечением полуплоскостей}
     Перебираем $i$ с 1 до $n$\;
     \eIf{$D_{i-1} \cap l_i = \varnothing$}{
       $D_i \gets D_{i-1}$\;
     }{
       $D_i \gets $IntersectConvexPolygonAndLine$(D_{i-1}, l_i)$\;
     }
   }
   \caption{Алгоритм разрезания многоугольника}
   \end{algorithm}


   Тогда, если пересечение ограничено, то мы получим его в
   $D_n$. Иначе какая-то из сторон $D_n$ будет представлять из себя
   подотрезок стороны $D_0$. Проверка сторон $D_n$ осуществляется за
   O(n) (так как в $D_n$ не более n сторон), время работы
   ~IntersectConvexPolygonAndLine~ -- $O(\log{n})$, итоговое время --
   $O(n \log{n})$.
*** IntersectConvexPolygonAndLine(P, l)
    Алгоритм такой:
    1. Найдем точки пересечения прямой l и выпуклого многоугольника P за $O(log{n})$
    2. Посмотрим, куда смотрит полуплоскость hp, задаваемая прямой l, и сколько точек получилось в пересечении
      - Точек в пересечении 0 или 1, hp смотрит "на" P: return P
      - Точек в пересечении 0 или 1, hp смотрит "против" P: return \emptyset
      - Точек в пересечении 2.
          Разрежем P на 2 части, возьмем ту, на которую смотрит hp и склеим ее со стороной [p; q].
          Операцию разрезания и склеивания можно эффективно
        реализовать за $O(log(n))$ например с помощью декартова
        дерева.

    \clearpage
* 2 11: Пересечение множества отрезков                              :avbelyy:
  Задача: найти все точки, в которых пересекаются либо касаются точкой
  начала или конца какие-то два и более отрезков из множества P.

  Понятно, как это сделать за O(n^2), однако хочется придумать output-sensitive алгоритм.
** Идея
   *Не будем проверять на пересечение отрезки, которые находятся
   далеко друг от друга*. Что значит "далеко"? Рассмотрим ниже два
   разных подхода к определению "дальности", совмещение которых и
   позволит нам создать эффективный output-sensitive алгоритм.
** Подход 1. Близость вдоль оси Y
   #+ATTR_LATEX: :width 0.4\textwidth
   #+CAPTION: Иллюстрация к первому подходу.
   [[./figures/BO1.png]]

   Понятно, что прямые, чьи вертикальные проекции на ось Y не
   пересекаются, не пересекаются.  Тогда алгоритм, учитывающий это,
   звучит так: пройдемся заметающей прямой сверху вниз. При
   прохождении через начало отрезка добавляем отрезок в "статус" -
   список текущих отрезков и проверяем его на пересечение с другими
   уже добавленными отрезками. При достижении конца отрезка удаляем
   его из статуса.

   Что плохо: может быть много отрезков, пересекающих одну и ту же
   горизонтальную прямую (например, ось X). Они могут не пересекаться
   между собой, но все равно алгоритм отработает за квадрат в этом
   случае. Значит, он не output-sensitive.
** Подход 2. Близость вдоль оси X
   #+ATTR_LATEX: :width 0.6\textwidth
   #+CAPTION: Иллюстрация ко второму подходу.
   [[./figures/BO2.png]]

   Чтобы учитывать близость и по оси X, научим нашу заметающую прямую
   ходить также вдоль оси X. Для этого отрезки "статуса" будем хранить
   в том порядке, в котором их встретит заметающая прямая (например,
   слева направо). Проверять на пересечение будем только соседние
   отрезки. Как определять соседство? Первоначально - по близости
   x-координат точек начала отрезков, но в дальнейшем отрезки могут
   становиться соседями с другими отрезками.
** Алгоритм
   Все готово для того, чтобы окончательно сформулировать
   алгоритм. Сперва сделаем это, не учитывая некоторые вырожденные
   случаи, а именно:
   - Пересечение более двух отрезков в одной точке
   - Наличие горизонтальных отрезков
   - Пересечение отрезков в более чем одной точке

   Сначала докажем корректность наших идей. А именно то, что для
   любого пересечения двух отрезков существует событие, в котором
   обнаружится их пересечение.

   #+BEGIN_lemma
   Пусть $s_i$ и $s_j$ - два негоризонтальных отрезка, имеющих
   единственную точку пересечения p, которая лежит во внутренности
   каждого отрезка. Тогда во множестве Q существует событие, лежащее
   до p, во время которого $s_i$ и $s_j$ становятся соседями и
   проверяются на пересечение.
   #+END_lemma

   #+BEGIN_proof
   Рассмотрим заметающую прямую чуть повыше p. В этот момент отрезки
   $s_i$ и $s_j$ являются соседними в статусе.  С другой стороны, в
   самом начале работы алгоритма заметающая прямая не пересекала
   ничего и статус был пуст, то есть в этот момент $s_i$ и $s_j$ не
   были соседями. Значит, где-то между началом и "чуть повыше p"
   отрезки стали соседями и были проверены на пересечение.
   #+END_proof

   Теперь, когда мы убедились, что все работает, вновь последовательно
   изложим наш подход к решению:
   - Пройтись по всем отрезком горизонтальной прямой сверху вниз
   - Останавливаться на точках начала, конца и пересечения отрезков
   - Поддерживать список пересекающих прямую отрезков (статус)

   Опишем действия, которые необходимо выполнить в точках разного
   типа.
*** Начало отрезка
    Проверить пересечение отрезка и его соседей ниже заметающей
    прямой, если оно есть - добавить соответствующее событие в Q.
*** Конец отрезка
    Удалить отрезок из Q, также проверить его соседей и добавить новое
    событие, если нужно.
*** Пересечение отрезков
    Во время пересечения отрезки меняют взаимное направление, а
    значит, могут поменять своих соседей. Нужно посвопать
    пересекающиеся отрезки и проверить их на пересечение с новыми
    соседями, опять же, добавляя событие при необходимости.
** Структуры данных
   Введем порядок на точках из событий следующим образом: p < q если
   выполняется либо p.y > q.y, либо p.x == q.x и p.x < q.x (как бы
   пройдемся прямой сверху вниз слева направо). Во время работы
   алгоритма нам понадобится добавлять новые события и проверять
   наличие существующего события в очереди. Чтобы делать это быстро,
   используем для хранения Q любое сбалансированное дерево поиска.

   Для элементов статуса также введем порядок (=$x$-координата
   пересечения с $l$). Здесь нам понадобится быстро добавлять элемент
   во множество, а также находить соседей для уже
   добавленных. Опять-таки воспользуемся BST для хранения T.
** Время работы алгоритма
   #+BEGIN_thm
   Время работы алгоритма составляет $O((n + k) \log{n})$.
   #+END_thm

   #+BEGIN_proof
   Время инициализации очереди составляет $O(n \log{n})$. Количество событий в очереди O(n + k), а на каждое
   событие случается константное количество операций добавления и
   удаления в Q и T сложностью O(\log{n}). Итого -- $O((n + k) \log{n})$.
   #+END_proof

   \clearpage

* 1 12: PSLG и DCEL: построение PSLG множества отрезков         :flyingleafe:
  #+LATEX_OPTIONS: :option [PSLG]
  #+BEGIN_defn
  Planar straight line graph (ППЛГ -- планарный прямолинейный
  граф) -- плоская укладка планарного графа, в которой все ребра
  представлены отрезками прямой.
  #+END_defn

  #+LATEX_OPTIONS: :option [Фейс PSLG]
  #+BEGIN_defn
  Face (грань) PSLG - это максимальное связное подмножество плоскости,
  не содержащее точек ребер или вершин PSLG
  #+END_defn

  #+LATEX_OPTIONS: :option [DCEL]
  #+BEGIN_defn
  Doubly-connected edge list (РСДС -- реберный список с двойными
  связями) -- структура данных для представления PSLG. Состоит из
  записей трех типов: вершина, фейс и полуребро.
  #+END_defn

  #+CAPTION: Наглядная иллюстрация структуры DCEL
  [[./figures/DCEL4.png]]

  #+LATEX_OPTIONS: :option [Вершина]
  #+BEGIN_defn
  Вершина (в смысле DCEL) -- это структурка данных, представляющая
  собой вершину PSLG в DCEL. Хранит в себе координаты точки ($v.x$ и $v.y$)
  и указатель на инцидентное (исходящее из этой вершины) полуребро $v.incEdge$
  #+END_defn

  #+LATEX_OPTIONS: :option [Фейс]
  #+BEGIN_defn
  Фейс (в смысле DCEL) -- это структурка данных, представляющая
  собой фейс PSLG в DCEL. Хранит в себе указатель на какое-либо из
  своих внутренних полуребер $face.edge$, а так же список указателей на
  внешние полуребра 'дырок' (фейсов, лежащих целиком внутри данного и
  не связанных с остальными), если таковые имеются ($face.holes$).
  #+END_defn

  #+LATEX_OPTIONS: :option [Полуребро]
  #+BEGIN_defn
  Полуребро (в смысле DCEL) -- это структурка данных, представляющая
  собой направленное ребро PSLG в DCEL. Полу -- потому что для каждого
  неориентированного ребра в PSGL мы храним 2 разнонаправленных
  полуребра. Полуребра ориентированы так, чтобы каждый фейс обходился
  по ним против часовой стрелки.

  Полуребро содержит следующие поля:
  1) Указатель на следующее полуребро $e.next$
  2) Указатель на предыдущее полуребро $e.prev$
  3) Указатель на ребро-"близнеца" (полуребро соседнего фейса,
     направленное в другую сторону и соответствующее тому же ребру)
     $e.twin$
  4) Указатель на вершину, из которой исходит ребро $e.origin$
  5) Указатель на фейс, которому инцидентно ребро $e.face$
  #+END_defn

  Насчет восстановления DCEL из прямых -- см. в бонусных задачах
  (внезапно)

  \clearpage

* 0 13: PSLG overlaying                                             :avbelyy:
* 2 14: Локализация в PSLG                                      :flyingleafe:
  Весь билет супер-подробно в одной статье:
  [[http://www.link.cs.cmu.edu/15859-f07/papers/point-location.pdf]]
  (скорее всего, не нужно)

  У нас есть PSLG (представленная как DCEL). Идут запросы в виде
  точек. Нужно уметь быстро определять, в какой фейс (ребро?) попала
  точка.

** 3 Метод полос
   CLOSED: [2016-01-10 Sun 17:36]
   #+CAPTION: Разбиение PSLG на slabs
   [[./figures/SLABS.png]]

   Идея старая: давайте локализоваться сначала по $x$, потом по
   $y$. Как? Проведем через каждую вершину PSLG прямую, разбив ее на
   полоски (slabs), как на рисунке.

   Отсортируем теперь эти полоски по $x$ - координате левой
   границы. Теперь бинпоиском мы легко можем находить полоску, в
   которую попала наша точка. Заметим, что по построению ребра могут
   пересекаться только на границах полосок, а значит, в рамках 1
   полоски все ребра вертикально упорядочены. Давайте в каждой полоске
   построим на на ребрах дерево поиска по $y$ и будем радостно
   локализовать точку между ними за $O(\log n)$. Ура!

   Не так быстро. Такая структура данных в худшем случае занимает
   $O(n^2)$ памяти, что очень плохо. Однако, ее можно улучшить!

*** 3 Персистентные деревья
    CLOSED: [2016-01-10 Sun 17:35]
    Давайте рассмотрим $x$ - координату как *время*. Двигаясь вправо по
    $x$, мы двигаемся во времени. Пусть у нас есть дерево бинпоиска,
    изначально пустое. Когда мы встречаем начало отрезка, мы добавляем
    в его в дерево с текущей $y$ - координатой. Когда мы встречаем
    конец отрезка, удаляем его из дерева. (*NB*: если отрезок(ки)
    лежит(ат) на вертикальной прямой, события начала/конца сортируются
    по $y$, а если один отрезок заканчивается, а другой начинается в
    одной и той же точке, событие начала идет раньше (ну как в
    Бентли-Оттмане, понятно))

    #+CAPTION: Персистентное дерево с копированием путей
    [[./figures/PERS_TREE1.png]]

    Так как отрезков $n$, то всего событий (а значит, операций
    изменения дерева) всего $2n$. Вернемся к первоначальной
    задаче. Применяя к slabs метафору времени, один slab - это отрезок
    времени, когда ничего не происходило. То есть, на один slab
    приходится одна версия персистентного дерева (а не отдельное дерево
    бинпоиска, как раньше). С точки зрения операции поиска ничего не
    изменилось, а вот потребление памяти уменьшилось до $O(n \log n)$ -
    так как в персистентном дереве а-ля Хаскель при операции
    добавления/удаления прибавляется/освобождается $O(\log n)$ памяти
    (узлы на пути от корня до вставленной/удаленной вершины + $O(1)$ на
    перебалансировку), а всего таких операций $O(n)$

*** 3 Очень классные персистентные деревья!
    CLOSED: [2016-01-10 Sun 17:30]
    Можно сделать персистентные деревья, которые занимают $O(n)$
    памяти, невероятно! Как именно? Используем тот факт, что нам не
    нужна *полная* персистентность (возможность менять все ревизии),
    нам достаточно только *частичной* (можем менять и получать новые
    ревизии только из последней, но делать запросы можем по
    всем). Чтобы понять идею, попробуем сначала сделать что-нибудь
    попроще, но такое же модное - частично персистентный список, например.

    Давайте в узле списка хранить не один указатель на следующий
    элемент, а 2 - $\mathrm{next}$ и $\mathrm{next2}$. Дополнительно мы будем хранить номер
    *первой ревизии списка*, начиная с которой используется указатель
    $\mathrm{next2}$. Также мы будем поддерживать таблицу (хэшмап или
    массив) $revision \rightarrow root$.

    Пусть мы хотим вставить очередной элемент в такой список между
    элементами $i$ и $i+1$ -- создать новую ревизию под номером $k$. Мы
    начинаем идти от корня, соответствующего ревизии $k - 1$ до
    элемента $i$. Всякий раз мы выбираем соответствующий самой свежей
    ревизии указатель из двух (это всегда будет $\mathrm{next2}$, если
    он не $\mathrm{null}$). Пусть мы дошли до $i$ -го узла. Если его
    указатель $\mathrm{next2}$ пуст, мы создаем новую вершину,
    указатель $\mathrm{next}$ которой мы подвешиваем на $i+1$, а
    указатель $\mathrm{i.next2}$ подвешиваем к новой вершине. В
    противном случае нам придется скопировать $i$ и всех его предков до
    тех пор, пока мы не встретим предка со свободным указателем
    $\mathrm{next2}$.

    Такую же тактику применим в деревьях: добавим в каждый узел дерева
    по дополнительному указателю $\mathrm{next2}$ и номер ревизии +
    флажок направления: влево или вправо смотрит
    $\mathrm{next2}$. Балансировочную информацию (размер поддерева или
    там цвет вершины) мы будем нещадно перезаписывать -- мы все равно
    не собираемся менять старые ревизии.

    #+CAPTION: Частично персистентное дерево с limited node copying
    [[./figures/PERS_TREE2.png]]

    #+BEGIN_lemma
    Частично персистентное дерево с limited node copying занимает
    $O(n)$ памяти
    #+END_lemma

    #+BEGIN_proof
    В худшем случае, конечно же, нам придется копировать $O(\log n)$
    узлов. Но мы самортизируем эту оценку. Заметим, что копируем мы
    только те узлы, в которых уже занят указатель
    $\mathrm{next2}$. Давайте будем платить 2 монетки за обновление
    указателя $\mathrm{next2}$ и ревизии в узле: одну за саму операцию,
    а другую отложим в узел про запас. Таким образом, в каждом
    заполненном узле будет лежать запасенная монетка. Когда нам нужно
    будет скопировать этот узел, мы потратим только уже отложенные
    монетки.

    Таким образом, амортизированная оценка для дополнительной памяти на
    операцию изменения в дереве -- $O(1)$, а так как операций изменения
    $O(n)$, то и памяти всего требуется $O(n)$
    #+END_proof

** 1 Киркпатрик
   Алгоритм Киркпатрика работает с PSLG, представляющими собой
   триангуляцию (вообще говоря, за $O(n \log n)$ заметающей прямой
   можно триангулировать любой PSLG, так что все ок)

   Идея: давайте сделаем последовательность триангуляций, где первая
   триангуляция совсем простая, а каждая следующая -- посложнее, но
   ненамного. Каждый треугольник в простой триангуляции знает, какие
   треугольники в более сложной он пересекает. Локализовавшись в
   простой триангуляции, мы сможем спускаясь все ниже и ниже уровнем
   дойти до искомой триангуляции и локализоваться в ней.

   Вопрос только в том, как строить эти уровни так, чтобы их было не
   слишком много и чтобы переходить от уровня к уровню было не слишком
   сложно.

   *Алгоритм*

   Пусть $S_1$ -- данная триангуляция с $n$ вершинами (Мы
   предполагаем, что ее внешняя грань представляет собой треугольник,
   если это не так, охватывающий треугольник мы можем построить
   сами). Построим последовательность $S_1, S_2, ..., S_{h(n)}$
   упрощающихся триангуляций, переходя от $S_{i-1}$ к $S_i$ таким
   образом:

   1) Удалим из $S_{i-1}$ некоторое множество попарно несмежных
      вершин, лежащих не на границе, вместе с инцидентными
      ребрами. Какие именно вершины удалять -- в этом тонкость.
   2) Триангулируем оставшие многоугольники.

   #+CAPTION: Последовательность упрощающихся триангуляций.
   [[./figures/KIRK.png]]

   Поисковая структура представляет из себя ациклический
   ориентированный граф, состоящий из 'слоев'. Каждый слой
   соответствует некоему $S_k$. Узел из слоя $S_i$ имеет ссылки на те
   треугольники в $S_{i+1}$, которые она пересекает.

   \begin{figure}[htb]
   \centering
   \includegraphics[width=0.6\textwidth]{./figures/KIRK1.png}
   \caption{Поисковая структура данных для алгоритма Киркпатрика.}
   \end{figure}

   Но как правильно выбирать удаляемые вершины? Пусть мы умеем удалять
   вершины так, что для любого $i > 1$ выполняются следующие свойства:
   1) $|S_i| = a_i|S_{i-1}|$, где $a_i \leqslant a < 1$
   2) Каждый треугольник в $S_i$ пересекается не более чем с H
      треугольниками в $S_{i-1}$ и наоборот.

   Первое свойство означает, что количество треугольников всякий раз
   уменьшается не менее чем в $a$ раз, что влечет логарифмическую
   оценку на количество слоев: $h(n) = O(\log n)$. Второе же свойство
   означает $O(1)$ на перебор всех треугольников более богатого слоя,
   пересекающихся с текущим. Кроме того, это ограничивает используемый
   объем памяти до $O(n)$:

   $\sum\limits_{i=1}^{h(n)} |S_i| \leqslant |S_1| \cdot (1 + a +
   a^2 + ... + a^{h(n) - 1}) \leqslant |S_1| \cdot \frac{1}{1 - a} =
   O(n);$

   так как число граней ($|S_1|$) линейно по отношению к числу вершин,
   а $\frac{1}{1 - a}$ -- это константа. Нужно еще учесть, что в
   каждом узле содержится сколько-то указателей, но их не больше, чем
   $H$ -- константное число, поэтому оценка не портится.

   Как поддержать такие свойства? Докажем следующую теорему:

   #+BEGIN_thm
   Если при построении очередного слоя триангуляции удалять несмежные
   вершины со степенью меньше некоторого $K$, то эти свойства будут выполняться.
   #+END_thm

   #+BEGIN_proof
   *Какие-то сложные доказательства*
   Число вершин -- $n$, значит, по формуле Эйлера, с учетом того, что
   все грани имеют по 3 ребра, верно $E = 3n - 6$. Так как каждое
   ребро инцидентно ровно 2 вершинам, и к степени каждой из них оно
   добавит единичку, то сумма степеней всех вершин $\leqslant 6n$. Это
   значит, что количество вершин, степень которых не меньше 12, не
   может быть больше $\frac{n}{2}$, а значит, количество вершин со
   степенью меньше 12 не меньше, чем $\frac{n}{2}$.

   Пусть мы хотим выбрать для удаления все несмежные вершины со
   степенью меньше $K = 12$. Обозначим число выбранных вершин как
   $v$. Поскольку мы выбираем несмежные вершины, каждая выбранная
   вершина исключает из дальнейшего рассмотрения максимум 11 вершин,
   смежных с ней. Таким образом, в худшем случае мы сможем выбрать
   одну вершину из 12 подходящих (то есть имеющих степень меньше
   $K$). Кроме того, мы не можем выбрать 3 граничные вершины. Поэтому
   можем оценить $v$ снизу так: $v \geqslant \left \lfloor
   \frac{1}{12}(\frac{N}{2} - 3) \right \rfloor$. Получается,
   коэффициент уменьшения $a \approx 1 - \frac{1}{24} < 1$, что
   подтверждает первое свойство.

   Второе свойство выводится тоже просто: при удалении вершины
   степенью меньше $K$ и всех инцидентных ей ребер получится
   многоугольник с числом ребер меньше $K$, который будет
   триангулирован на менее чем $K - 2$ треугольника. Таким образом,
   любой новый треугольник (из триангуляции этого многоугольника)
   будет пересекать не более $K$ старых, и наоборот.
   #+END_proof

   #+BEGIN_thm
   Алгоритм Киркпатрика требует $O(\log n)$ времени на запрос, $O(n)$
   памяти и $O(n \log n)$ времени на препроцессинг.
   #+END_thm

   #+BEGIN_proof
   Оценки на память и время запроса мы доказали выше. Чтобы доказать
   оценку на препроцессинг, нужно доказать, что построение очередного
   слоя работает за $O(n)$: так как всего слоев $O(\log n)$, это
   повлечет за собой искомую оценку.

   Выбрать все вершины для удаления мы можем, очевидно, за
   $O(n)$. После удаления вершин останется $v$ многоугольников,
   которые нужно триангулировать. Однако заметим, что все эти
   треугольники - "звездные", поэтому каждый из них можно
   триангулировать за $O(m)$, где $m$ - число вершин в
   многоугольнике. Суммарное число вершин в многоугольниках - $O(n)$,
   поэтому они все будут триангулированы за $O(n)$
   #+END_proof

   \clearpage
* 3 15: Трапецоидная карта                                      :flyingleafe:
  CLOSED: [2016-01-11 Mon 04:03]
** 3 Определение и основные свойства
   CLOSED: [2016-01-10 Sun 19:30]
   Трапецоидная карта - это структурка данных, позволяющая локализовать
   точку в PSLG (вообще - просто в куче непересекающихся отрезков) за
   $O(\log n)$ и занимающая $O(n)$ памяти.

   \begin{wrapfigure}{r}{0.35\textwidth}
   \centering
   \includegraphics[width=0.35\textwidth]{./figures/TRAP_MAP1.png}
   \caption{Трапецоидная карта.}
   \end{wrapfigure}

   Что собой представляет трапецоидная карта? Из каждой вершины PSLG
   выпустим вверх и вниз вертикальные лучи до тех пор, пока не упремся
   в какое-нибудь ребро. Чтобы лучи не получились бесконечными, окружим
   все PSLG большим прямоугольником $R$. Получится трапецоидная карта.

   Здесь и далее мы допускаем, что в PSLG не встречается вершин,
   лежащих строго вертикально друг над другом. Далее мы покажем, как
   избавиться от этого допущения.

   #+BEGIN_lemma
   Любой face трапецоидной карты ограничен 1 отрезком сверху, одним
   снизу и 1 или 2мя вертикальными -- по бокам. (То есть, face трапецоидной карты -
   это трапеция или прямоугольник)
   #+END_lemma

   #+BEGIN_proof
   Пусть фейс ограничен сверху более чем 1 невертикальным отрезком. Но
   отрезки изначально не пересекаются, значит, они встречаются в
   вершине. Тогда из вершины должен был по построению опущен луч,
   разделивший бы рассматриваемый фейс. Значит, и сверху и снизу есть
   только 1 ограничивающий отрезок. Ну а с вертикальными сторонами
   (лучами) все и так ясно.
   #+END_proof

   #+BEGIN_lemma
   Трапецоидная карта на $n$ отрезках содержит максимум $6n + 4$
   вершины и $3n + 1$ трапецоид.
   #+END_lemma

   #+BEGIN_proof
   Вершины карты - это вершины отрезков ($2n$) плюс вершины
   охватывающего прямоугольника $R$ (4), плюс вершины, получившиеся в
   результате пересечения вертикальных лучей с отрезками ($2 \cdot 2n =
   4n$, так как есть 2 луча из каждой вершины, каждый из которых
   оборвется на первом пересечении с отрезком). Итого $6n$.

   Теперь подсчитаем количество трапецоидов (фейсов). Заметим, что
   каждому трапецоиду $\Delta$ можно сопоставить точку $leftp(\Delta)$,
   определяющую его левую границу. Эта точка может быть либо левым
   нижним углом $R$, либо концом какого-либо отрезка. Левый нижний угол
   $R$ относится только к одному трапецоиду. Правый конец какого-либо
   отрезка может быть $leftp(\Delta)$ только для одного трапецоида, а
   левый конец - максимум для двух. (Чтобы понять, почему это так,
   посмотрите на иллюстрацию со всеми возможными расположениями
   $leftp(\Delta)$. Итого $3n + 1$ трапецоид.
   #+END_proof

   #+CAPTION: Всевозможные конфигурации левой границы трапецоида
   [[./figures/TRAP_LEFTP.png]]

   В структуре данных для трапецоида $\Delta$ будем хранить следующие
   поля:
   1) Указатели на вершины, определяющие левую и правую границы
      трапецоида: $leftp(\Delta), \ rightp(\Delta)$
   2) Указатели на ребра, являющиеся верхней и нижней границами
      трапецоида: $top(\Delta), \ bottom(\Delta)$
   3) Указатели на всех соседей: $prev(\Delta), \ next(\Delta), \
      up(\Delta), \ down(\Delta)$

   Вся карта - это просто список таких трапецоидов.

   Для эффективной локализации точки в карте мы будем строить
   специальную структуру, которая представляет из себя 'почти
   дерево' -- ациклический ориентированный граф, где у каждой вершины
   2 исходящих ребра, кроме листьев, которые являются трапецоидами.

   #+CAPTION: Поисковая структура для трапецоидной карты
   [[./figures/TRAP_SEARCH1.png]]

   Внутренние узлы графа могут быть 'вершинами' или
   'ребрами'. Узел-'вершина' разделяет множество трапецоидов по $x$,
   'ребро' -- по $y$. Уже понятно, как локализовать точку в такой
   структуре: топаем, начиная от корня, в ту сторону, с какой стороны
   точка запроса лежит от соответствующей вершины или ребра. Такой
   запрос отработает за $O(h)$, где $h$ - глубина графа.

   Однако, глубина этого графа может быть самой разной, вплоть до
   $O(n)$, в зависимости от того, в каком порядке его строить. В
   следующем подразделе мы с этим разберемся.
** 3 Алгоритм построения карты и поисковой структуры
   CLOSED: [2016-01-11 Mon 04:03]
   Нам нужно как-то минимизировать глубину поисковой структуры для
   трапецоидной карты. Для этого мы помахаем руками и докажем, что для
   случайного набора отрезков в случайном порядке глубина так и так
   выйдет небольшой.

*** Алгоритм
    Будем строить карту и поисковой граф инкрементально: с самого
    начала карта состоит из одного трапецоида -- $R$, а граф состоит из
    одного листа. Будем добавлять отрезки по одному, предварительно
    рандомно их перемешав.

    Чтобы добавить отрезок, надо предварительно определить, какие
    трапецоиды он пересек. Делаем это так:

    \begin{algorithm}[H]
    \SetKwFunction{IntSeg}{IntersectSegment}%
    \func{\IntSeg{T, D, s}}{
    \KwData{Трапецоидная карта $T$, поисковая структура для нее $D$, отрезок $s$}
    \KwResult{Список трапецоидов, пересекаемых отрезком}
    $p, q \gets \ $ левый и правый концы $s$, соответственно\;
    $\Delta_0 \gets \ $ трапецоид, в котором мы локализовали $p$ (с помощью $D$)\;
    $j \gets 0$\;
    \While{$q$ находится справа от $rightp(\Delta_j)$}{
    \eIf{$s$ выше $rightp(\Delta_j)$}{
    $\Delta_{j+1} \gets \ $ правый верхний сосед $\Delta_j$
    }{
    $\Delta_{j+1} \gets \ $ правый нижний сосед $\Delta_j$
    }
    $j \gets j + 1$\;
    }
    return $\Delta_0, ..., \Delta_j$
    }
    \caption{Нахождение трапецоидов, пересекающихся с данным отрезком}
    \end{algorithm}

    #+BEGIN_lemma
    Этот алгоритм работает за $O(h + k)$, где $h$ -- глубина $D$, $k$
    -- размер ответа.
    #+END_lemma

    #+BEGIN_proof
    Очевидно: мы локализуем $p$ за $O(h)$ и переходим к каждому
    следующему трепецоиду за $O(1)$.
    #+END_proof

    После того, как мы нашли трапецоиды, их нужно удалить и на их место
    поставить новые, как в $T$, так и в $D$.

    Сначала рассмотрим простой случай: отрезок полностью содержится в 1
    трапецоиде $\Delta$. Тогда нам нужно сделать из этого трапецоида 4,
    проставить в них и в отрезке соответствующие указатели на соседей,
    обновить в соседях указатели, которые раньше ссылались на $\Delta$,
    и заменить в $D$ лист, соответствующий $\Delta$ на поддерево, как
    показано на рисунке. Это делается, очевидно, за $O(1)$

    \begin{figure}[htb]
    \centering
    \includegraphics[width=0.5\textwidth]{./figures/TRAP_UPDATE1.png}
    \caption{Обновление трапецоидной карты и поискового графа в простом случае}
    \end{figure}

    В случае пересечения с несколькими трапецоидами, на самом деле, все
    примерно так же, надо только по-разному обработать 3 случая:
    1) левый конец отрезка лежит в трапецоиде
    2) правый конец отрезка лежит в трапецоиде
    3) отрезок полностью пересекает трапецоид

    Кроме того, так как отрезок $s$ обрубит некоторые вертикальные
    лучи, придется померджить какие-то трапецоиды вдоль него. Смотрим
    картинку.

    \begin{figure}[htb]
    \centering
    \includegraphics[width=0.5\textwidth]{./figures/TRAP_UPDATE2.png}
    \caption{Обновление трапецоидной карты и поискового графа в сложном случае}
    \end{figure}

    Чтобы правильно мерджить трапецоиды вдоль отрезка в один,
    определим, с какой стороны от $s$ лежит
    $rightp(\Delta_0)$. Н. у. о. она лежит сверху, поэтому снизу
    остается трапецоид, который продолжится вдоль отрезка. Расставим
    корректно все ссылки, за исключением того, что у нижнего трапецоида
    оставим $rightp(\Delta_{low}) = \mathrm{null}$. Запомним его. При
    обработке следующего трапецоида будем знать, что снизу лежит
    $\Delta_{low}$, и расставим ссылки соответствующе. Будем повторять
    так, пока не встретим $rightp(\Delta_j)$, лежащую снизу от $s$ --
    она определит правую границу $\Delta_{low}$. С трапецоидами,
    тянущимися сверху, поступаем аналогично.

    В $D$ же листы, соответствующие пересеченным трапецоидам, заменим
    на 'поддеревья': если $\Delta_j$ разбился на 2 трапецоида $A$ и
    $B$, то заменим его лист реберным узлом, относящимся к $s$ и
    ссылающимся на листы $A$ и $B$. Если на три -- $A$, $B$, $C$ -- то
    заменим на деревце из вершинного и реберного узлов (см. картинку).

    Все это делается за $O(k)$. Итого, процедура локализации нового
    отрезка и его вставки займет $O(h + k)$ времени.

    Так мы построим корректную карту и граф поиска, потому что на
    каждом шаге они корректны для текущего подмножества. Замечательно,
    осталось доказать, что это будет не слишком долго.

*** Асимптотика
    В худшем случае все это работает очень плохо: при добавлении
    каждого отрезка глубина $D$ можем увеличится максимум на 3 (в
    случае попадания отрезка целиком в трапецоид), поэтому worst-case
    оценкой на глубину $D$ является $3n$, что влечет $O(n)$ на запрос и
    $O(n^2)$ на построение. Отвратительно. Но если включить теорвер, то
    выяснится, что в большинстве случаев все гораздо лучше.

    Давайте зафиксируем множество отрезков $S$ и некую точку запроса
    $q$. Обозначим за $S_1, ..., S_n$ все префиксы списка
    $S$. Обозначим за $X_i$ количество вершин на пути поиска $q$,
    созданных на итерации $i$ алгоритма построения трапецоидной
    карты. $X_i, ..., X_n$ -- это случайные величины, и матожидание
    длины пути через них можно выразить так:

    $E[\sum\limits^{n}_{i=1}X_i] = \sum\limits^{n}_{i=1}E[X_i]$

    Мы знаем, что при добавлении отрезка глубина $D$ увеличивается не
    более, чем на 3, следовательно, $X_i \leqslant 3$. Значит, если мы
    обозначим за $P_i$ вероятность встретить на пути поиска вершину,
    созданную на $i$ -ой итерации, будет верно следующее:

    $E[X_i] \leqslant 3P_i$

    Нам осталось как-то оценить $P_i$. Подумаем, в каком случае
    вершина, созданная на $i$ -ой итерации, попадет в путь поиска точки
    $q$. Рассмотрим частичную трапецоидную карту $T(S_{i-1})$. Пусть
    точка $q$ в ней локализуется в трапецоиде $\Delta_q(S_{i-1})$. В
    каком случае на $i$ -ой итерации путь поиска точки $q$ изменится?
    В том и только в том, если трапецоид $\Delta_q(S_{i-1})$ будет
    подразбит на этой итерации, и точка попадет в новый трапецоид
    $\Delta_q(S_i)$, поменьше.

    Так какова вероятность того, что трапецоид $\Delta_q(S_i)$ был
    создан именно на $i$ -ой итерации? Применим анализ 'задом-наперед':
    пусть дана трапецоидная карта, построенная на множестве отрезков
    $S_i$ и удаляется случайный отрезок $s_i$. Какова вероятность того, что
    $\Delta_q(S_i)$ при этом исчезнет?

    Он может исчезнуть в 4 случаях:
    1) $s_i = top(\Delta_q(S_i))$
    2) $s_i = bottom(\Delta_q(S_i))$
    3) $leftp(\Delta_q(S_i))$ - конец $s_i$
    4) $rightp(\Delta_q(S_i))$ - конец $s_i$

    Значит, существуют 4 отрезка, удаление которых приведет к
    исчезновению $\Delta_q(S_i)$, а значит, вероятность его
    исчезновения ($ = P_i$) -- $\frac{4}{i}$.

    Таким образом, если ожидаемую длину пути поиска обозначить за
    $L_q$, верно следующее:

    $L_q \leqslant \sum\limits_{i=1}^n 3P_i = \sum\limits_{i=1}^n
    \frac{12}{i} \approx 12 \cdot \ln n = O(\log n)$

    Последний переход основан на том, что суммы гармонического ряда
    сверху и снизу ограничены логарифмом (известный факт из матана, вы
    что, его не ботали?).

    Ура! Мы доказали, что ожидаемая глубина графа поиска, а значит, и
    время запроса -- $O(\log n)$!

    *Память*

    Осталось доказать, что эта структура данных весит не очень
    много. Сама трапецоидная карта $T$ занимает $O(n)$ памяти, потому
    что трапецоидов $O(n)$. А вот с графом поиска $D$ все чуть
    сложнее. Если нам не повезет, и на каждой итерации мы будем
    отрезком пересекать все имеющиеся трапецоиды, то мы на этой
    итерации будем создавать $O(n)$ узлов, что выльется в $O(n^2)$ по
    памяти. Но это худший случай, интересна ожидаемая оценка.

    Обозначим количество вершин в $D$, добавленных на $i$ -ой итерации
    построения, как $k_i$. Тогда ожидаемый объем памяти для хранения
    $D$ составит $O(n) + \sum\limits_{i=1}^n E[k_i]$.

    Для нахождения $E[k_i]$ опять применим мышление
    задом-наперед. Введем следующую функцию:

    $\delta(\Delta, s) = \begin{cases}
    1, & \textrm{if } \Delta \textrm{ disappears when } s \textrm{
    is removed}  \\
    0, & \textrm{otherwise}
    \end{cases}$

    Известно, что для любого $\Delta$ $\delta(\Delta, s) = 1$ не более,
    чем для 4 отрезков $s$ (соседних с этим трапецоидом с одной из 4
    сторон). Значит,

    $\sum\limits_{s \in S_i} \sum\limits_{\Delta \in T(S_i)}
    \delta(\Delta, s) \leqslant 4|T(S_i)| = O(i)$

    Теперь запишем формулу для $E[k_i]$, зная, что вероятность
    удаления любого отрезка - $\frac{1}{i}$:

    $E[k_i] = \sum\limits_{s \in S_i} \frac{1}{i} \sum\limits {\Delta
    \in T(S_i)} \delta(\Delta, s) = \frac{1}{i} \cdot O(i) = O(1)$

    Таким образом, в среднем за 1 итерацию мы увеличим потребление
    памяти на $O(1)$, а значит, всего структура займет $O(n)$ памяти.

    Здесь же мы можем дать ожидаемую оценку на время построения. Мы
    знаем, что добавление одного отрезка в карту происходит за $O(h +
    k)$. Но теперь мы знаем, что в большинстве случаев $O(h) \approx
    O(\log n)$, а $O(k) \approx O(1)$, а значит, в среднем добавление
    нового отрезка произойдет за $O(\log n)$, что дает $O(n \log n)$ на
    построение всей структуры данных.

    *Замечание*

    В начале мы сделали допущение (довольно нереалистичное), что в PSGL
    нет вершин, имеющих одинаковую $x$ -координату. От него можно
    избавиться, представив, что мы всю плоскость немножко скосили на
    эпсилон. Смоделировать такое поведение можно просто упорядочив
    точки не просто по $x$, а лексикографически: точка $(x, y_1)$
    считается правее $(x, y_2)$, если $y_1 > y_2$. Из за этого
    частенько будут возникать вырожденные трапецоиды, ну и ладно, зато
    ничего не будет ломаться.

    \clearpage

* 3 16: Вращающиеся калиперы                                        :volhovm:
  CLOSED: [2016-01-09 Sat 14:23]
  Вращающиеся калиперы -- это несложный паттерн проектирования
  различных алгоритмом, требующих последовательного обхождения
  выпуклых многоугольников в $\R^2$. Рассмотрим применение метода
  сразу на практической задаче.

  Пусть дано некоторое множество точек. Определим его диаметр как
  максимальное расстояние между какими-либо двумя точками. Покажем,
  как можно найти диаметр этого множества.

  #+BEGIN_lemma
  Диаметр множества лежит на выпуклой оболочке этого множества
  #+END_lemma
  #+BEGIN_proof
  Очевидно от противного: пусть мы нашли диаметр множства $P$ -- $ab$,
  причем, не теряя общности, $b \notin CH(P)$. Тогда утверждается, что
  можно пустить луч $ab$ и посмотреть, в какой точке он пересечет
  выпуклую оболочку. Легко показать, что как минимум одна точка,
  формирующая ребро выпуклой оболочки, пересеченное лучем, имеет
  дистанцию до $a$ больше $dist(a,b)$.
  #+END_proof

  # очень жаль, что нельзя сделать этого с помощью org-тегов
  \begin{wrapfigure}{l}{0.3\textwidth}
  \centering
  \includegraphics[width=0.3\textwidth]{./figures/CALIPERS_DIAMETER.png}
  \caption{Поиск диаметра множества точек с помощью вращающихся калиперов}
  \end{wrapfigure}

  Алгоритм поиска таков: для начала найдем минимальную и максимальную
  точку среди точек выпуклой оболочки (лексикографически) $A$ и
  $B$. Мысленно создадим две вертикальных параллельных прямых,
  проходящих через соответствующие точки -- $l_1$, $l_2$. Будем
  заворачивать калиперы по часовой стрелке, поэтому условимся, что
  $l_1$ смотрит вверх, а $l_2$ вниз. Добавим текущие точки, на которых
  стоят параллельные прямые, в список ребер ответа ($\langle A,
  B\rangle$). Сравним угол между $l_1$ и $AC$ с углом между $l_2$ и
  $BD$. Выберем меньший и перейдем к следующей точке относительно
  выбранной, повернув при этом соответствующую прямую на величину
  углу, так, чтобы прямая теперь совпадала с $AC$. Будем всегда
  поддерживать параллельность калиперов (прямых), поэтому вторую
  прямую тоже мысленно повернем. Получим две новые прямые $l_3$,
  $l_4$. Перейдем в начало процесса, добавив $\langle C, B\rangle$ в
  список ребер ответа. Когда алгоритм придет в начальное положение, на
  выходе получим список ребер, среди которых будет искомое. Переберем
  их за линию и найдем максимальное (можно делать это in-place во
  время алгоритма, формируя один большой fold).

  В реализации углы сравниваются поворотами, и функция хранит только
  одно доминирующее ребро, на котором калипер "лежит" полностью, а
  второй калипер параллелен первому и соответствует некоторой
  точке. Исключение составляет первый шаг, на котором калиперы могут
  лежать исключительно на точках -- можно добавить фиктивное ребро с
  координатами $(x, y+1)$ относительно минимальной или максимальной
  точки.

  #+BEGIN_lemma
  Алгоритм поиска диаметра работает корректно, среди найденных ребер
  найдется диаметр.
  #+END_lemma
  #+BEGIN_proof
  Докажем от противного. Пусть среди всех пар точек, формирующих
  ребра, нет нужной. Отметим, что метод выдает все ребра, для которых
  верно, что сущетствует пара параллельных прямых, не пересекающих
  многоугольник, проходящих через эти точки. Очевидно, что если для
  двух точек такие прямые не построить, то и диаметр на них лежать не
  может -- легко показать, что взяв соседнюю, мы увеличим расстояние
  между ними (следует из непараллельности, надо аккуратно посмотреть
  углы).

  Отсюда диаметр лежит в классе пар точек, на которых прямые
  строятся. Поскольку алгоритм просматривает все такие (несложно
  показать), то диаметр будет лежать среди ребер ответа.
  #+END_proof

  Кроме уже рассмотренной, метод вращающихся калиперов может быть
  использован для решения следующих задач:
  1. Поиск расстояния между двумя многоугольниками. Абсолютно
     аналогично проводим алгоритм для поиска диаметра (в инициализации
     у более левого/нижнего берем минимальную точку, а у другого
     максимальную), но добавляем в список ответа пару
     $\langle доминирующее ребро, вершина \rangle$.
  2. Поиск двух общих касательных у выпуклых многоугольников. В
     инициализации у обоих полигонов берем минимальные точки, калиперы
     сонаправлены. В момент, когда калиперы меняются местами (один
     становится выше другого), мы проходим точку касания.

     #+ATTR_LATEX: :width 0.7\textwidth
     #+CAPTION: Момент смены положения калиперов в поиске общих касательных
     [[./figures/CALIPERS_BRIDGE.png]]
  3. Поиск суммы Минковского двух объектов.

  \clearpage
* 2 17: Сумма Минковского                                           :volhovm:
  Для решения проблемы планирования движения для неточечного объекта
  (скажем, выпуклого полигона) используется подход расширения
  препятствий. Более формально: пусть $A$ -- агент с выделенной точкой
  внутри, а $C$ -- препятствие. Пусть $A(x,y)$ -- это многоугольник,
  полученный параллельным переносом агента так, чтобы его центр
  находился в $(x,y)$. Тогда расширенное препятствие формализуется
  так: \[\{(x,y) : A(x, y) \cap C \neq \emptyset\}\]

  #+ATTR_LATEX: :options [Сумма Минковского]
  #+BEGIN_defn
  Сумма Минковского двух многоугольников $A$ и $B$ есть \[ A \oplus B
  \equiv \{p + q : p \in A, q \in B\} \], где сумма точек в привычном
  понимании покоординатна.
  #+END_defn

  #+BEGIN_lemma
  Пусть $A$ -- агент (выпуклый многоугольник), $P$ --
  препятствие. Тогда раздутое препятствие для $P$ есть $P \oplus
  (-A(0,0))$
  #+END_lemma
  #+BEGIN_proof
  Покажем, что $A(x,y) \cap P \neq \emptyset \Leftrightarrow (x, y)
  \in P \oplus (-A(0,0))$.

  Пусть $A(x,y) \cap P \neq \emptyset$, рассмотрим точку $q$ в
  пересечении. По определению пересечения, $q \in A(x,y)$, а значит
  $(q_x - x, q_y - y) \in A(0,0)$, что эквивалентно $(x - q_x, y -
  q_y) \in -A(0,0)$. Также из пересечения следует $q \in P$, а значит
  следствие вправо доказано.

  Обратно: пусть $(x, y) \in P \oplus (-A(0,0))$. Тогда существуют
  такие точки $(r_x, r_y) \in A(0,0)$, $(p_x, p_y) \in P$, что $(x,y)
  = (p_x - r_x, p_y - r_y)$. Тогда по определению есть пересечение.
  #+END_proof

  #+ATTR_LATEX: :options [Свойства суммы Минковского выпуклых многоугольников]
  #+BEGIN_thm
  Пусть $P$, $Q$ -- выпуклые полигоны, имеющие $n$ и $m$ ребер
  соответственно. Тогда многоугольник $P \oplus Q$ выпуклый и имеет
  максимум $n+m$ ребер.
  #+END_thm
  #+BEGIN_proof
  Выпуклость доказывается напрямую из определения. Для любого отрезка
  $seg \in P \oplus Q$, для каждой точки $s = (x,y)$, которая ему
  принадлежит, верно, что $s = p + q$, где $p \in P$, $q \in
  Q$. Найдем точки $p_1, q_1 : p_1 + q_1 = seg.start$, и $p_2, q_2 :
  p_2 + q_2 = seg.end$ (они найдутся по определению). Заметим, что
  сумма Минковского двух сегментов есть сегмент, а значит из того, что
  $[p_1,p_2] \in P$ и $[q_1, q_2] \in Q$ следует $[seg.start,seg.end]
  = seg \in P \oplus Q$.

  Для доказательства линейности суммы рассмотрим произвольное ребро $e
  \in P \oplus Q$. У него есть внешняя нормаль $\vect{n}$, и из
  выпуклости $P$ следует, что ребро $e$ экстремально в направлении
  $\vect{n}$. Значит, оно должно быть сгенерировано какими-то точками
  из $P$ и $Q$, которые тоже экстремальны в этом же направлении. Более
  того, как минимум один многоугольник из $P$, $Q$ должен иметь ребро
  $e'$, которое экстремально в этом направлении (потому что получить
  ребро нельзя из двух точек). Установим соответствие $e
  \Leftrightarrow e$, и такое соответствие для каждого ребра
  единственно в силу единственности нормали. Итого, имеем максимум
  $n+m$ ребер в сумме Минковского (ровно, если у двух многоугольников
  нету параллельных ребер).
  #+END_proof

  #+ATTR_LATEX: :options [Псевдодиск]
  #+BEGIN_defn
  Будем говорить, что пара планарных объектов (в частности полигонов)
  $(A, B)$ называется парой псевдодисков, если $A \ B$ связно и $B \
  A$ связно.
  #+END_defn

  #+ATTR_LATEX: :options [Набор псевдодисков]
  #+BEGIN_defn
  Будем называть набором псевдодисков такое множетсво планарных
  объектов $\{P_i\}$, что каждая пара элементов в нем является
  псевдодисками.
  #+END_defn

  К примеру, любые два прямоугольника со сторонами, параллельными
  осям, являются псевдодисками.

  #+BEGIN_note
  Границы двух псевдодисков могут пересекаться максимум в двух точках.
  #+END_note

  Немного расшарим также понятие экстремальности точки или ребра,
  перенеся его на многоугольник в общем.
  #+ATTR_LATEX: :option [Экстремальность многоугольника]
  #+BEGIN_defn
  Будем говорить, что многоугольник $A$ более экстремален, чем
  многоугольник $B$ в направлении $\vect{n}$, если для движущейся
  прямой, перпендикулярной $\vect{n}$, движущейся в направлении
  $\vect{n}$, последняя точка, которую она пересекает при движении,
  принадлежит $A$.

  Если в последний момент, когда прямая что-то пересекает, она
  пересекает оба многоугольника сразу, то будем говорить что в этом
  направлении экстремальность многоугольников равна.
  #+END_defn

  Поскольку экстремальность характеризуется вектором, то будем
  говорить, что $P$ более экстремален $Q$ в направлениях от
  $\vect{n_1}$ до $\vect{n_2}$, если это верно для любого направления от
  $angle(\vect{n_1})$ до $angle(\vect{n_2})$ (против часовой стрелки).

  #+BEGIN_note
  #+BEGIN_center
  #+ATTR_LATEX: :width 0.8\textwidth
  [[./figures/MINKOWSKI_EXTREME.png]]
  #+END_center

  Пусть $P_1$ и $P_2$ -- выпуклые многоугольники с непересекающимися
  внутренностями, причем $P$ более экстремален чем $Q$ в направлениях
  $\vect{n_1}$ и $\vect{n_2}$. Тогда $P$ экстремальнее $Q$ во всех
  направлениях либо от $\vect{n_1}$ до $\vect{n_2}$, либо от $\vect{n_2}$
  до $\vect{n_1}$.

  Другими словами, сектор угла, соответствующий экстремальности
  многоугольника, единственен и непрерывен.
  #+END_note

  #+BEGIN_thm
  Пусть $P$ и $Q$ -- два непересекающихся выпуклых многоугольника, а
  $A$ -- другой выпуклый полигон. Тогда суммы Минковского $P \oplus A$
  и $Q \oplus A$ являются псевдодисками.
  #+END_thm
  #+BEGIN_proof
  Обозначим $CP := P \oplus A$, $CQ := Q \oplus A$. Докажем из
  определения псевдодисков, что $CP \ CQ$ связно (достаточно только
  этого, из симметричности).

  #+ATTR_LATEX: :width 0.6\textwidth
  #+CAPTION: Первая пара не являются псевдодисками, вторая -- является
  [[./figures/MINKOWSKI_PSEUDODISCS.png]]

  По выше доказанной теореме $CP$ и $CQ$ -- выпуклые полигоны. Докажем
  от противного: пускай $CP \ CQ$ несвязно. Заметим, что для выпуклых
  многоугольников есть только один возможный вариант пересекаться и не
  быть псевдодисками -- это иметь 4 точки пересечения на границе
  (см. иллюстрацию).

  Заметим, что по выпуклости $CP$ должен иметь две точки на границе
  выпуклой оболочки $CP \cup CQ$. Также он должен иметь два
  направления $\vect{n_1}$, $\vect{n_2}$, в которых он более экстремален
  чем $CP$. По замечанию выше полигон не может иметь два разрывных
  промежутка экстремальности, значит компонента связности
  одна. Протворечие с предположением.
  #+END_proof

  #+BEGIN_thm
  Пусть $S$ -- набор псевдодисков, имеющий суммарно $n$ ребер. Тогда
  объединение элементов из $S$ имеет $O(n)$ ребер.
  #+END_thm

  #+BEGIN_proof
  Поскольку объединение полигонов -- полигон, то мы можем доказать
  теорему, используя стандартный метод амортизационного анализа:
  раздадим каждой вершине из набора по 2 монеты и покажем, что для
  каждой вершины объединения за нее кто-то заплатит. Таким образом мы
  ограничим количество вершин величиной $2n$.

  #+BEGIN_center
  #+ATTR_LATEX: :width 0.3\textwidth
  [[./figures/MINKOWSKI_THM0.png]]
  #+END_center

  В объединии будет 2 вида вершин -- вершины, которые принадлежат
  границе какого-то псевдодиска и вершины, образованные пересечением
  двух псевдодисков.

  За каждую вершину первого типа заплатим одной монетой из нее самой
  же.

  Вторые вершины из объединения делятся на две категории. Рассмотрим
  точку $v$, являющуюся пересечением ребер $e_1 \in S_1$ и $e_2 \in
  S_2$. Ребро $e_1$ может пересечь псевдодиск $S_2$ либо единажды,
  либо два раза (в этом случае выйдет, что весь полигон $P_2$ проходит
  через это ребро и заканчивается внутри полигона $P_1$).

  В первом случае заплатим за вершину пересечения точкой ребра $e_1$,
  лежащей внутри $P_2$.

  Во втором случае есть вторая точка на границе $P_2$, в которой
  граница $P_2$ пересекается с $e_1$. Очевидно, что ребро $e_2$ имеет
  точку внутри $P_1$, иначе у нас полигоны пересекаются в 4х точках,
  что портит свойство псевдодиска. Тогда заплатим за пересечение $v$
  точкой на конце $e_2$, лежащей внутри $P_1$. Если так оказалось, что
  внутри $P_1$ лежит всего одна точка из $P_2$, то у нас на ней две
  монетки -- мы можем покрыть оплату обоих пересечений $e_1$ с $P_2$.
  #+END_proof

  Покажем два алгоритма для получения суммы Минковского двух
  полигонов.

  \begin{algorithm}[H]
  \KwData{Два выпуклых полигона $P$, $Q$}
  \KwResult{$P \oplus Q$}
  $points \gets$ new vector of points\;
  \For{$p_1 \gets P$}{
    \For{$p_2 \gets P$}{
      $points.insert(p_1 + p_2)$\;
    }
  }
  return $ConvexHull(points)$\;
  \caption{Наивный алгоритм нахождения суммы Минковского двух многоугольников}
  \end{algorithm}

  \begin{algorithm}[H]
  \KwData{Выпуклый полигон $P$ с точками $p_1$,...,$p_n$ \\
          выпуклый полигон $Q$ с точками $q_1$,...,$q_m$ }
  \KwResult{$P \oplus Q$}
  $i \gets 1; j \gets 1$\;
  $p_{n+1} \gets p_1$\;
  $q_{m+1} \gets q_1$\;
  \Repeat{$i = n+1$ and $j = m+1$}{
    Добавить $p_i + q_j$ в сумму $P \oplus Q$\;
    $bool_1 \gets angle(p_ip_{i+1}) < angle(q_jq_{j+1})$\;
    $bool_2 \gets angle(p_ip_{i+1}) > angle(q_jq_{j+1})$\;
    \If{$\neg bool_1$ and $\neg bool_2$}{
      $i++; j++$\;
    }
    \If{$bool_1$ and $\neg bool_2$}{
      $i++$\;
    }
    \If{$\neg bool_1$ and $bool_2$}{
      $j++$\;
    }
  }
  \caption{Поиск суммы Минковского методом вращающихся калиперов}
  \end{algorithm}

  Первый алгоритм работает достаточно плохо на больших множествах
  (нужно перебирать все пары точек), а второй за линейное время, так
  как используется метод калиперов.

  #+BEGIN_thm
  Сумма Минковского двух выпуклых тел с $n$ и $m$ вершинами
  соответственно, считается за $O(n+m)$ времени.
  #+END_thm
  #+BEGIN_proof
  Алгоритм подсчета калиперами представлен выше.
  #+END_proof

  #+BEGIN_thm
  Пусть $P$ -- невыпуклый многоугольник с $n$ вершинами, а $Q$ --
  выпуклый с $m$. Тогда количество вершин в $P \oplus Q$ есть $O(nm)$.
  #+END_thm
  #+BEGIN_proof
  Заметим, что следующее равенство верно: \[ S_1 \oplus (S_2 \cup S_3)
  = (S_1 \oplus S_2) \cup (S_1 \oplus S_3) \]

  Возьмем триангуляцию $P$, для каждого $P_i$ посчитаем его сумму и
  объединим. Более формально: \[ P \oplus Q = \bigcup_{i=1}^{n-2}{P_i
  \oplus Q} \]

  Исходя из оценки сложности суммы двух выпуклых полигонов, каждое
  объединение $P_i \oplus Q$ будет иметь максимум $m + 3$
  ребер. Поскольку треугольники триангуляции не пересекаются, то ${P_i
  \oplus Q}$ есть набор псевдодисков. Объединение псевдодисков линейно
  по вершинам/ребрам, значит общая сложность $P \oplus Q$ есть
  $O(nm)$.
  #+END_proof

  #+BEGIN_thm
  Пусть $P$ и Q$ -- невыпуклые многоугольники с $n$ и $m$ вершинами
  соответственно. Тогда сложность $P \oplus Q$ есть $O(n^2m^2)$.
  #+END_thm
  #+BEGIN_proof
  Найдем триангуляции данных многоугольников $\{P_i\}$ и $\{Q_i\}$.
  Сложность каждого объединения $P_j \cup Q_i$ константна, а значит $P
  \oplus Q$ есть объединение $(n-2)(m-2)$ многоугольников константной
  сложности (каждой пары). Отсюда следует, что сложность объединения
  есть $O(n^2m^2)$ (обычная оценка, нет свойства псевдодисков).
  #+END_proof

  \clearpage
* 3 18: Вероятностный алгоритм мин.охв.окружности               :flyingleafe:
  CLOSED: [2016-01-10 Sun 18:15]
  Рассмотрим задачу: у нас есть множество $P = \{p_1, ..., p_n\}$
  точек на плоскости. Нужно построить окружность такую, чтобы все
  точки из $P$ лежали бы внутри нее или на границе, причем из таких
  окружностей надо выбрать минимальную.

  *Идея*: строим окружность итеративно, рассматривая точки по одной. В
  этом нам очень поможет следующая лемма.

  #+ATTR_LATEX: :options [О добавлении точки в минимальную окружность]
  #+BEGIN_lemma
  Определим $P_i = \{p_1, ..., p_i\}$, а $D_i$ -
  мин. охват. окружность для $P_i$. Рассмотрим точку $p_i$. Верно
  следующее:
  1) Если $p_i \in D_{i-1}$, то $D_i = D_{i-1}$
  2) Иначе $p_i$ лежит на границе $D_i$
  #+END_lemma

  #+BEGIN_proof
  Докажем эту лемму, как следствие следующей (по сути, следующая --
  это переформулировка этой)
  #+END_proof

  #+ATTR_LATEX: :options [О точках, лежащих внутри и на границе]
  #+BEGIN_lemma
  Пусть $P$ -- множество точек на плоскости, $R$ -- тоже (возможно,
  пустое) Обозначим как $md(P, R)$ наименьшую окружность, охватывающую
  $P$ и имеющую все точки $R$ на границе.  Пусть $p \in P$. Тогда:
  1) Если $md(P, R)$ существует, то он единственен.
  2) Если $p \in md(P \setminus \{p\}, R)$, то $md(P, R) = md(P
     \setminus \{p\}, R)$
  3) Если $p \notin md(P \setminus \{p\}, R)$, то $md(P, R) = md(P
     \setminus \{p\}, R \cup \{p\})$
  #+END_lemma

  #+BEGIN_proof
  1) Если $|R| > 2$, то это очевидно невозможно -- потому что по 3
     точкам окружность строится единственным образом. Пусть тогда $|R|
     > 2$ и существуют 2 минимальные окружности $D_0$ и $D_1$ с
     радиусом $r$ и центрами $x_0$ и $x_1$ соответственно.

     Тогда $P \subset D_0 \cap D_1$, $q_0$ и $q_1$ -- точки
     пересечения $D_0$ и $D_1$, и $R \subset \{q_0, q_1\}$.  Но если
     мы построим окружность с центром точно посередине $q_0$ и $q_1$,
     она будет включать в себя $D_0 \cap D_1$ и на ее границе будет
     лежать $R$ И по построению ее радиус будет меньше, чем
     $r$. Значит, $D_0$ и $D_1$ не являются минимальными охватывающими
     окружностями.
  2) Очевидно.
  3) Обозначим $D_0 = md(P \setminus \{p\}, R)$ и $D_1 = md(P,
     R)$. Это две окружности, очевидно, гомотопически эквивалентны.
     Обозначим их центры и радиусы как $x_0$, $r_0$, $x_1$ и $r_1$
     соответственно.

     Построим между ними кратчайшую гомотопию следующим образом:
     \begin{align*}
     D(\lambda) &= \{x(\lambda), r(\lambda)\}\\
     x(\lambda) &= (1 - \lambda)x_0 + \lambda x_1\\
     r(\lambda) &= \|z - x(\lambda)\|
     \end{align*}
     Тут $z$ -- одна из точек пересечения $D_0$ с $D_1$.

     Замечание: точки пересечения всегда есть, когда $R$ непусто, а
     если оно пусто, то они должны быть из соображений минимальности.

     Очевидно, что $\forall \lambda \in [0, 1] : P \subset D(\lambda),
     R \subset \partial D(\lambda)$, ведь это верно для пересечения
     $D_0$ и $D_1$, которое по построению в себя включает каждая из
     $D(\lambda)$. Тогда существует некая $\lambda*$, $0 < \lambda*
     \leqslant 1$, такая, что $p \in \partial D(\lambda)$ Но по
     построению $r(\lambda) \leqslant r_1$, и если $\lambda* < 1$, то
     $D_1$ не является $md(P, R)$, так как ей является
     $D(\lambda)$. Противоречие! Значит, $\lambda* = 1$, из чего
     следует, что $p \in \partial D_1$, что и требовалось доказать.
  #+END_proof

  \begin{algorithm}[H]
  \SetKwFunction{makeA}{make0}%
  \SetKwFunction{makeB}{make1}%
  \SetKwFunction{makeC}{make2}%
  \func{\makeA{$n$}}{
    \KwResult{Возвращает минимальную охватывающую окружность множстева точек}
    $D_2 \gets $ окружность на диаметре между точками $p_1$ и $p_2$\;
    Перебираем точки с $p_3$ по $p_n$\;
    \eIf{$p_i \in D_{i-1}$}{
      $D_i = D_{i-1}$\;
    }{
      $D_i = make1(i, p_i)$\;
    }
  }
  \func{\makeB{$k$, $p$}}{
    \KwResult{$md(\{p_1, ..., p_k\}, \{p\})$}
    $D_1 \gets $ окружность на диаметре между точками $p_1$ и $p$\;
    Перебираем точки с $p_2$ по $p_k$\;
    \eIf{$p_i \in D_{i-1}$}{
      $D_i = D_{i-1}$\;
    }{
      $D_i = make2(i, p, p_i)$\;
    }
  }
  \func{\makeC{$k$, $p$, $q$}}{
    \KwResult{$md(\{p_1, ..., p_k\}, \{p, q\})$}
    $D_0 \gets $ окружность на диаметре между точками $p$ и $q$\;
    Перебираем точки с $p_1$ по $p_k$\;
    \eIf{$p_i \in D_{i-1}$}{
      $D_i = D_{i-1}$\;
    }{
      $D_i$ строится единственным образом по трем точкам -- $p$, $q$ и $p_i$\;
    }
  }
  \caption{Алгоритм поиска минимальной охватывающей окружности}
  \end{algorithm}

  \begin{wrapfigure}{l}{0.3\textwidth}
    \centering
    \includegraphics[width=0.3\textwidth]{./figures/CIRCLES.png}
    \caption{Иллюстрация к доказательству единственности}
    \end{wrapfigure}

  *Корректность*

  Доказанная лемма гарантирует, что окружность, которая ищется при
  вызове $make1$ и $make2$, всегда существует. Кроме того, она
  показывает, что построенная на каждом шаге $make0$ окружность
  является корректной. Значит, и весь алгоритмм корректен.

  *Асимптотика*

  $make2(n, p, q)$ всегда работает за $O(n)$.

  $make0(n)$ и $make1(n, p)$ работают тоже за $O(n)$, если не
  учитывать вызовы нижележащих функций. Но их нужно учитывать! Из
  этого можно заключить, что верхней оценкой на время выполнения
  является $O(n^3)$. На практике же (на случайных точках) алгоритм
  работает существенно быстрее.

  Разберемся, почему. Для этого рассмотрим работу алгоритма "задом
  наперед". Сначала рассмотрим функцию $make1(n, p)$

  Пусть у нас есть результирующая окружность. Начнем удалять из
  множества точки в обратном порядке и сжимать окружность, когда это
  возможно.

  Вероятность того, что на каком-то шаге окружность сожмется, равна
  вероятности того, что на этом шаге при обычном исполнении будет
  вызвана $make2(i, p, p_i)$. Какова эта вероятность? Окружность может
  "опираться" на 2, 3 или более точек, одна из которых всегда $q$
  (которую мы удалить не можем) В первом случае удаление только 1
  точки может спровоцировать сжатие окружности, во втором - одной из
  2, в третьем - окружность не сожмется в любом случае. Итого, на
  каждом шаге есть не более 2 точек, удаление одной из которых
  приведет к вызову $make2$. Вероятность удаления одной из этих
  точек - $\frac{2}{i}$.

  Итого, ожидаемое время работы функции $make1(n, p)$:

  $O(n) + \sum\limits_{i=2}^n {O(i) \frac{2}{i}} = O(n)$

  Применив аналогичные рассуждения, докажем линейное ожидаемое время
  работы для функции $make0$.

  \clearpage
* 2 19: Граф видимости и планирование движения                      :volhovm:
  Задача поставлена следующим образом: есть объект, точечный или нет,
  нужно провести его через полигональные препятствия (все в
  $\R^2$). Известность карты -- тоже входной параметр.

  #+CAPTION: Иллюстрации к теме про Motion Planning
  [[./figures/MOT_PL.jpg]]
** 2 Точечный объект
   Решим задачу для точечных объектов. Пусть у нас есть поле, точки $A$
   и $B$. Нужно попасть из первой во вторую, не пересекаясь с
   препятствиями.
*** 2 Граф видимости
    Первая тривиальная идея, которая приходит в голову -- это построить
    граф, в котором узлы -- это вершины полигонов, составляющих карту,
    а ребра между двумя вершинами $u$, $v$ строим в том случае, если
    $uv$ не пересекается ни с одним полигоном из данных. Такой граф
    называется картой видимости. Можно его обойти дейкстрой. Получаем
    $O(n^2)$ и памяти и времени на запрос (если использовать дейкстру
    без кучи). Предподсчет будет занимать втупую $O(n^3)$, то есть для
    каждой пары точек проверить пересечение со всеми отрезками
    полигонов (их $n$ штук).

    Подумаем, что с этим можно сделать:
    * Не хранить ребра, а создавать их только когда мы пришли в вершину.
    * Оптимальный путь -- ломаная (доказательство от противного, пусть
      есть какая-то кривая, огибающая препятствие, тогда спрямим ее,
      получим прямую меньшей длины) -- см. ~MOT_PL_1~. Более того,
      кратчайший путь между двумя точками в поле с полигональными
      препятствиями содержит только начало, старт и точки полигонов в
      качестве своих точек.
    * Если рассмотреть вершину полигона $P$, то путь из двух ребер
      (входящее в нее $aP$ и исходящее $Pb$) неоптимален, если угол
      $aPb < 180°$. См. ~MOT_PL_2~. Доказательство простое --
      рассмотрим такой угол. Тогда возьмем две любые точки $c \in aP$, $d
      \in Pb$ (можно взять их как точки пересечения окружности с центром
      в $P$ с прямыми $aP$ и $Pb$, при этом окружность взять радиуса
      меньше чем каждый из отрезков), получим по неравенству
      треугольника что путь $acdb$ короче чем $aPb$. Такие ребра в
      общем можно не добавлять. Алсо такая оптимизация не понижает
      асимптотику, а только уменьшает константу.
    * Препроцессинг можно уменьшить с $O(n^3)$ до $O(n^{?}\log{n})$ с
      помощью алгоритма Бентли-Оттмана (заметающая прямая). Мы будем
      использовать следующую модификацию (см. ~MOT_PL_3~):

      Для очередной точки $P$ найдем, какие отрезки из нее исходят
      вправо (предполагаем, что все отрезки влево уже были добавлены на
      предыдущем шаге). Для этого рассмотрим все ребра, которые
      пересекают прямые, начиная от $P$ и вниз и вправо против часовой
      стрелки вверх на $180°$. Типа рассмотрели зону видимости
      "вправо". Формально мы все отрезки, которые заканчиваются правее
      нашей точки берем, раскладываем на события (стандартные Б-О
      ивенты типа начало отрезка, пересечение, конец отрезка) и сортим
      по углу поворота относительно $P$. Дальше перебираем их всех
      против часовой стрелки и храним стейт всех отрезков, которые
      пересекает наша прямая. Первый отрезок в стейте будет отрезком,
      который "виден" из $P$ -- будем по ходу дела добавлять концы
      видимых отрезков в ответ.

      Сам Б-О работает за $O((n+k)\log{n})$, где $n$ -- количество
      отрезков, а $k$ -- количество пересечений.  Таким образом для всех
      точек оцениваем сверху препроцессинг до $O(n^2\log{n})$.
    * Препроцессинг на самом деле уменьшается до $O(n^2)$, но это
      древняя магия (есть какие-то статьи).
    * Динамически отвечать на запросы, чтобы снизить память. Я так
      понимаю, это когда мы минимум выбираем (за $O(n)$), то ищем
      вершины, потом релаксируем, храним предка чтобы знать путь. Вот
      короче динамически так будем строить граф.
    * Есть много других интересных подходов, в том числе алгоритм
      Митчелла, который снижает память до $O(n\log{n})$, причем на
      запрос времени $O(n + \log^2{n})$, где логарифм от локализации в
      планарном графе. Общая идея там похожа на принцип
      Гюйгенса-Френеля, если я все правильно понимаю: мы запускаем из
      очередной точки сферические волны и смотрим на те точки
      плоскости, где в $\alpha-\varepsilon$ волна остановилась, а в
      $\alpha+\varepsilon$ она идет, типа границы видимости. И запускаемся
      дальше от таких (бесполезное знание)
*** 2 Сомнительной полезности квант знания
    Есть также похожая задача, суть которой состоит в разбиении
    плоскости на зоны возможной скорости объекта. Там закон Снеллиуса
    о преломлении и решение работает за $O(n^8\log{n})$.
*** 1 Приближенное решение с помощью триангуляции
    Можно попробовать сократить память до $O(n)$, триангулировав
    множество вершин полигонов с учетом видимости. Потом рассмотрим
    двоственный триангуляции граф (взяв в качестве точек центры
    треугольников).
    * Путь получается достаточно плохой, необходимо сгладить ребра:
      * Жадным способом их позаменять.
      * На используемых вершинах подобавлять, типа уточнить путь на графе.
      * Подразбивать ребра, добавить вершины и провести их них еще
        какие-нибудь другие ребра.
    * Мы умеем бросать из точки отрезок и смотреть что он пересекает
      (препятствие или нет). Количество пересеченных треугольников
      будет $O(\sqrt{n})$.
    * Добавляем еще сетку и дополнительно триангулируем по ней, это
      уменьшает длины ребер треугольников (это хорошо почему-то)
    * Зная среднюю и максимальную длину ребра, можем кидать отрезки,
      кратные ей и таким образом ограничивать количество
      просматриваемых треугольников.
*** 2 Трапецоидная карта, наивное решение
    Воспользуемся трапецоидной картой для решения этой
    задачи.

    Построим сначала обычную трапецоидную карту для набора точек $S$,
    которые формируют полигоны, а затем удалим те трапецоиды, которые
    лежат внутри полигонов (можно пройтись по DCEL'у, полагаю, и
    удалить). Для каждого трапецоида из результата добавим в набор
    точек пути его центр и для каждого соседнего левого или правого
    трапецоида добавим точку на середине вертикального ребра, которое
    их соединяет (~MOT_PL_4~, × -- середина трапецоида, \cdot --
    середина соединяющего соседние трапецоиды ребра). Для каждого
    трапецоида соединим его середину с серединами соседних
    ребер. Назовем получившийся граф дорожной картой.

    Как реализовывать запросы с трапецоидной картой? Пусть имеются
    точки $A$, $B$:
    1. Принадлежат одному трапецоиду -- проведем прямую между точками.
    2. Иначе определим трапецоиды $\Delta_{A}$, $\Delta_{B}$,
       содержащие точки $A$ и $B$ соответственно, пойдем от $A$ к
       центру $\Delta_{A}$, потом по дорожной карте дойдем до центра
       $\Delta{B}$, а дальше проведем прямую от центра к $B$.

    Корректность пути относительно предиката "нет столкновений"
    очевидна -- для путей внутри трапецоидов это верно по построению,
    для каждого элемента дорожной карты тоже.

    Оценка времени такова: поиск трапецоидов, в которых содержатся $A$
    и $B$ занимает $O(\log{n})$ с помощью структуры точечной
    локализации, но можно проверить и за $O(n)$, так как весь алгоритм
    работает за $O(n)$. Будем находить путь между трапецоидами поиском
    в глубину, что займет $O(n)$ шагов, так как в графе и число
    трапецоидов (а значит и их центров) линейно, и число соединений
    между двумя трапецоидами линейно (следует из планарности). Итого
    $O(n\log{n})$ на препроцессинг, $O(n)$ на запрос и мы не можем
    гарантировать оптимальность. Чтобы это сделать, нам необходимы
    более сложные структуры данных.
*** 2 Слепой жук: точечный объект, нет знания карты
    Задача сформулирована так же, как предыдущие, но в этом случае у
    нас нету возможности заранее что-либо предподсчитать.

    Рассмотрим наивное *нерабочее* решение: ~BUG_FAIL~. Пусть наш жук
    будет обходить препятствие до первого поворота, а дальше
    направляться в сторону конца. Контпример изображен на
    (~MOT_PL_BUG_FAIL~): в этом случае мы зациклимся и не достигнем
    финиша.

    Рассмотрим два несложных решения.
    * ~BUG0~: Зафиксируем прямую из начальной в конечную точку
      $l$. Будем придерживаться этой прямой. При встрече с препятсвием
      фиксируем положение обходим его в одну фиксированную сторону до
      тех пор, пока не окажемся снова на этой линии (~MOT_PL_BUG_0~).
    * ~BUG1~: Пусть зафиксирована прямая движения $l_1$. Будем следовать
      ей, а при встрече с препятствием обойдем и отметим ситуацию,
      когда мы находимся ближе всего к точке $B$. В этот момент
      сформируем прямую $l_2 = pB$, где $p$ -- текущее положение
      жука, и пойдем по l_2 дальше, следуя алгоритму (~MOT_PL_BUG_1~).

    В некоторых случаях ~BUG1~ значительно лучше ~BUG0~: представим
    себе спираль, в центре которой финиш. Начав вне спирали с
    алгоритмом ~BUG1~ мы после первого шага будем идти внутрь спирали,
    уменьшая расстояние до финиша. С ~BUG0~ алгоритм будет часто
    делать лишние шаги по спирали и покажет себя значительно хуже.

    Вот еще забавный алгоритм: ~CBUG~. Выбираем любой алгоритм из
    предыдущих двух и дополняем его таким образом: на старте и на
    финише строим эллипс как на центрах. Добавляем его в список
    преград, то есть. При первом столкновении с какой-либо
    поверхностью запоминаем точку. Может произойти так, что мы
    пройдемся по ограничивающему эллипсу и вернемся назад. Если такое
    произошло, увеличим эллипс в два раза.

    Есть еще уйма классных алго для роботов. К примеру, есть
    модификация для робота со зрением. Это примерно аналогично роботу
    без зрения, только "прощупывание" стены визуальное.
** 1 Неточечный объект
   Для неточечног объекта чаще всего задача сводится к какому-то
   расширению препятствий и сведению к предыдущей задаче с точечным
   объектом.

   В общем случае задача делится на две по критерию "можно ли
   поворачивать объект". Для круга этот вопрос не имеет смысла,
   поэтому он вынесен в отдельную подзадачу.

*** X Задача для круга
    Эта задача делится на две:

    Пусть полигоны выпуклые. Расширим прямые полигонов вовне на
    радиус круга. Свяжем расширенные прямые в узлах разрыва каким-то
    приближением кругов (выставим некоторое количество точек, образовав
    вписанный многоугольник). См. ~MOT_PL_5~. Потом, если не будем
    пользоваться графом видимости, новые полигоны объединим. Если же
    решение с трапец. картой или триангуляцией, то это нужно сделать,
    чтобы не связывать лишние вершины.

    Если полигоны невыпуклые -- тоже хотим расширить, но возникают
    проблемы с самопересечнием (~MOT_PL_6~ -- у нас внутри полигона
    может поместиться круг, хотя туда нельзя его провести извне). Есть
    два варианта -- не учитывать буферную зону пересечения
    (более-менее просто) или строить честный straight-skeleton (уже
    нетривиально, хотя и были лекции, но нет в программе экзамена).
    Утверждается, что первое решается за $O(n^2)$ с помощью priority
    queue, на уровне "добавляем события и аккуратно смотрим за
    пересечениями". Надо еще подумать *!!!*.
*** 2 Задача для полигона без вращения
    Пусть мы проводим через поле невращающийся полигональный выпуклый
    объект. Выберем некоторую точку в полигоне и будем думать в
    сторону построения суммы Минковского полигонов поля относительно
    нашего агента с зафиксированной точкой.

    На этом этапе предполагается, что все рассуждения о том, как нужно
    строить сумму Минковского, относятся к соответствующей теме,
    поэтому просто выпишем некоторые тезисы:

    Для выпуклого многоугольника с $n$ точками построение суммы
    минковского с агентом из $m$ точек занимает $O(nm)$, а если
    пользоваться методом калиперов, то $O(n+m)$.

    Для невыпуклых многоугольников их можно разбить на выпуклые
    (триангулировать), для каждого построить сумму Минковского, а
    затем их объединить.

    Асимптотика объединения невыпуклого полигона с выпуклым $O(nm)$,
    невыпуклого в невыпуклым $O(n^2m^2)$. На триангуляцию
    многоугольника с $m$ вершинами уходит $O(m\log{m})$ сложности
    (можно и за $O(m)$ с очень сложным алгоритмом). Тогда для всех
    многоугольников это можно сделать за $n\log{n}$ (тут надо раскрыть
    сумму).

    Асимптотика мерджа расширенных суммой Минковского агентов с
    треугольниками триангуляции составляет $O(n\log^2{n})$: выбирать
    какие треугольники мерджитьможно с помощью divide-and-conquer (это
    $O(\log{n})$ операций, а один шаг мерджа занимает $O(n\log{n})$ по
    линейности количества треугольников.

    Запрос будет реализовываться все так же за $O(n)$.
*** 2 Задача для полигона с вращенем
    Хорошая практика в этом вопросе решать его неточно (точные решения
    занимают $O(n^4)$ памяти. Определим некоторый дискретный набор
    углов, на которые мы будем поворачивать нашего агента. Построим
    много карт для разных углов.

    Имея некоторое количество карт, хочется понять, как
    локализовываться в них. Для локализации хочется получить какую-то
    общую структуру. Хорошее предложение -- для каждой карты
    нарисовать трапецоидную карту и как-то слинковать каждые соседние
    слои. Делать мы это будем просто: для каждых двух соседних карт
    будем смотреть их пересечение. Для двух пересекающихся трапецоидов
    из разных уровней добавляем в граф еще одну вершину как центр
    пересечения трапецоидов и соединяем ее с центрами двух
    пересекаемых трапецоидов. Так прошивая каждые два соседние слоя мы
    получим карту, в которой можно будет локализовываться, как и
    раньше.

    Памяти всего будет $O(n+m)$ на слой если все выпуклое и
    $O(n^2m^2)$, если невыпуклое. Суммарно еще умножить на количество
    слоев по дискретизации угла, которых обычно берут $O(n^2)$.

    Поправка: такой алгоритм не всегда верен, как можно
    догадаться. Можно увеличить количество углов поворота, но и это не
    будет гарантировать корректность. Чтобы превратить все true
    negative в false positive, мы можем считать карту для слоя для
    модифицированного робота: зафиксируем у него точку, повернем его
    на ~+angle~ и ~-angle~, возьмем выпуклую оболочку получившегося
    робота вместо него самого.
   \clearpage
* 2 20: Триангуляция Делоне                                         :volhovm:
** 2 Оптимальная триангуляция
   Пусть поставлена задача интерполировать множество точек в
   $\R^2$. Для каждой точки определено значение функции (скажем, высота
   ландшафта), и по множеству хочется восстановить значение функции в
   каждой другой точке плоскости. В этом случае нам поможет
   триангуляция, но какая именно?

   #+LATEX_ATTR: :options [Вектор уголов]
   #+BEGIN_defn
   Для триангуляции $T$ с $m$ треугольниками будем называть
   отсортированный по возрастанию вектор всех углов во всех
   треугольниках $A(T) = \alpha_1...\alpha_{3n}$ вектором углов
   триангуляции.

   Отношение $<$ на вектор-углах определяется лексикографически.
   #+END_defn

   #+LATEX_ATTR: :options [Оптимальная триангуляция]
   #+BEGIN_defn
   Будем говорить, что триангуляция $T$ множества точек $G$ оптимальна
   относительно углов, если для каждой другой триангуляции $T'$ верно
   $A(T) \ge A(T')$.
   #+END_defn

   Для задачи с интерполяцией множества точек лучше всего подходит
   именно оптимальная с точки зрения углов (дальше просто
   "оптимальная") триангуляция, так как она соединяет близкие точки и
   не допускает слишком "вытянутых" треугольников.

   #+BEGIN_thm
   Пусть $C$ -- окружность, $l$ -- прямая, пересекающая $C$ в точках
   $a$, $b$. Точки $p$, $q$, $r$, $s$ лежат по одну сторону $l$, причем
   $p$, $q$ лежат на окружности, $r$ внутри нее, а $s$ -- вне
   окружности. Тогда верно: \[\measuredangle{arb} > \measuredangle{apb}
   = \measuredangle{aqb} > \measuredangle{asb}\]

   #+BEGIN_center
   #+ATTR_LATEX: :width 0.3\textwidth
   [[./figures/DELAUNAY_CIRC0.png]]
   #+END_center
   #+END_thm

   Рассмотрим флип -- операцию на двух соседних треугольниках, меняющую
   одну диагональ на другую. Будем называть ребро плохим, если при
   флипе мы уменьшаем минимум среди всех шести углов. Очевидно, что
   последовательно находя плохие ребра и флипая их, мы будем
   увеличивать оптимальность триангуляции (так как мы увеличиваем
   лексикографический порядок, избавляясь от малых углов).

   #+ATTR_LATEX: :width 0.6\textwidth
   #+CAPTION: Замена плохого ребра $p_i p_j$ с помощью флипа.
   [[./figures/DELAUNAY_FLIP.png]]

   #+BEGIN_thm
   Пусть дан треугольник, и вокруг него описана окружность. Если
   существует другая точка, лежащая внутри этой окружности так, что ее
   от треугольника отграничивает ребро $e$, то такое ребро -- плохое.

   #+ATTR_LATEX: :width 0.3\textwidth
   #+CAPTION: Ребро $p_ip_j$ -- плохое.
   [[./figures/DELAUNAY_NOPOINT.png]]

   Более того, если четыре точки не лежат на одной окружности и
   формируют четыхеругольник, то ровно одна из двух диагоналей плохая.
   #+END_thm

#  На лекции это через какие-то грабли и левые определения,
#  в которые я не верю
#  * Пусть обе диагонали хорошие. Тогда $a \notin C(\vartriangle bcd)$
#    (из симметричности свойства также $c \notin C(\vartriangle
#    dab)$). Аналогично $b \notin C(\vartriangle cda)$, $d \notin
#    C(\vartriangle abc)$. Для каждых двух точек каждой диагонали можно
#    показать, что сумма их углов $< 180\degree$. Тогда сумма всех
#    углов $< 360\degree$ что противоречит построению.

   #+BEGIN_proof
   Поймем, что из второго утверждение следует первое.

   Второе можно показать с помощью матана и какого-нибудь
   деформирующего непрерывного преобразования квадрата. Вроде того:
   возьмем квадрат $abcd$, опишем возле него окружность. Покажем, что
   двигая одну из точек в любом направлении, хотя бы одна окружность
   смещается и необходимая диагональ становится плохой.

   В деБерге доказательства нету.
   #+END_proof
** 2 Триангуляция Делоне
   #+ATTR_LATEX: :options [Триангуляция Делоне]
   #+BEGIN_defn
   Триангуляция Делоне -- это такое разбиение множества точек на
   треугольники, что в описанной вокруг каждого окружности нету других
   точек из этого множества.
   #+END_defn

   Становится ясно, что триангуляция Делоне есть оптимальная, то есть
   может быть получена в результате применения флипов на все плохие
   ребра к любой триангуляции, при условии конечности процесса
   флипов. Последнее, кстати, требует отдельного внимания. Перед тем,
   как показать конечность числа флипов и существование триангуляции
   Делоне, представим один удобный механизм работы с триангуляциями.

   Рассмотрим четыре точки $a$, $b$, $c$, $d$. Как проверить,
   принадлежит ли $d$ окружности? Введем фукнцию \[\phi((p_x,p_y)) =
   (p_x,p_y,\sqrt{p_x^2+p_y^2})\]. Эта функция "поднимает" точку на
   параболоид в нуле. Тогда заметим, что $\phi(a), \phi(b), \phi(c)$
   образуют плоский треугольник в $\R^3$, такой, что плоскость через
   него проходящая, отсекает от параболоида ровно поднятие круга
   описанного вокруг $\vartriangle abc$ на параболоид. Отсюда
   становится понятно, что для проверки принадлежности точки $d$
   окружности достаточно проверить знак определителя (поворот в
   $\R^3$):

   \begin{align*}
   D =
    \begin{vmatrix}
    a_x & a_y & \sqrt{a_x^2+a_y^2} & 1 \\
    b_x & b_y & \sqrt{b_x^2+b_y^2} & 1 \\
    c_x & c_y & \sqrt{c_x^2+c_y^2} & 1 \\
    d_x & d_y & \sqrt{d_x^2+d_y^2} & 1 \\
    \end{vmatrix}
   \end{align*}

   #+LATEX_ATTR: :options [Существование триангуляции Делоне]
   #+BEGIN_thm
   Алгоритм, флипающий все плохие ребра, терминируется.
   #+END_thm
   #+BEGIN_proof
   Несложно показать, что происходит при флипе на проекции
   триангуляции на параболоид. Плохое ребро на параболоиде выглядит
   как "долина" в оригами -- диагональ четырехугольника вдавливается
   внутрь параболоида. Флип же меняет "долину" на "гору", тем самым
   уменьшая объем подграфика параболоида, ограниченного подъемом
   точек, смежных бесконечно большой грани триангуляции (на
   параболоиде они самые высокие). Уменьшение строгое, поэтому каждый
   раз объем строго уменьшается. Значит значение объема как функции
   имеет минимум. Алгоритм не может уменьшить это значение до нуля,
   потому что это противоречит физическому устройству флипов --
   невозможно получить сколь угодно малый объем подграфика. Значит,
   алгоритм терминируется и триангуляция Делоне существует.
   #+END_proof

   #+LATTEX_ATTR: :options [Глобальность локальной оптимальности]
   #+BEGIN_thm
   Алгоритм, флипающий ребра, строит триангуляцию Делоне (из
   локальнольной оптимальности следует глобальная).
   #+END_thm
   #+BEGIN_proof
   Напомним, что в оптимальности ничего не говорится о *всех* точках,
   лишь только о тех, что формируют смежный четырехугольник. Покажем,
   что если $T$ -- триангуляция без "плохих" ребер, то это
   триангуляция Делоне.

   #+BEGIN_center
   #+ATTR_LATEX: :width 0.3\textwidth
   [[./figures/DELAUNAY_GLOBAL.png]]
   #+END_center

   Докажем от противного. Пусть все ребра хорошие, но триангуляция не
   обладает свойством Делоне. Значит, есть треугольник $\vartriangle
   p_ip_jp_k$ такой, что в его описанной окружности $C_1$ есть точка
   $p_l$. Назовем хорошее ребро $p_ip_j$ (такое, что треугольник
   $p_ip_lp_j$ не пересекается с первоначальным) $e$. Теперь выберем
   среди всех таких треугольников и неправильных точек $p_l$ такую
   пару, которая максимизирует $\measuredangle p_ip_lp_j$. Рассмотрим
   треугольник $\vartriangle p_ip_jp_m$, смежный с выбранным по ребру
   $e$. По оптимальности $T$ ребро $e$ правильное, значит $p_m$ не
   лежит в описанной вокруг $p_ip_jp_k$ окружности.

   Заметим, что $p_l$ также лежит в окружности, описанной вокруг
   $p_ip_jp_m$ ($C(p_ip_jp_m)$ содержит полностью часть окружности
   $C(p_ip_jp_k)$, которая лежит с внешней стороны $e$).

   Пусть, без потери общности, точка $p_l$ лежит по внешнюю сторону
   ребра $p_mp_j$ треугольника $\vartriangle p_ip_jp_m$. Тогда
   $\measuredangle p_mp_lp_j > \measuredangle p_ip_lp_j$, поскольку
   $p_mp_j$ опирается на большую дугу окружности. Последнее
   утверждение противоречит тому, что угол максимален.
   #+END_proof
** 3 Использование триангуляции Делоне
   CLOSED: [2016-01-11 Mon 18:58]
   Триангуляция Делоне помогает решать некоторые практические
   задачи. Кроме уже упомянутой интерполяции, решим задачу поиска
   минимального остовного дерева в евклидовом пространстве.

   Задача: построить минимальное остовное дерево для набора точек, где
   вес ребра -- расстояние по евклидовой метрике между точками.

   #+BEGIN_lemma
   Все ребра евклидового МСТ лежат в триангуляции Делоне.
   #+END_lemma
   #+BEGIN_proof
   От противного: пусть это не так. Рассмотрим ребро $e = pq$, не
   принадлежащее триангуляции Делоне. Поскольку $e$ -- не ребро
   Делоне, то в окружности его охватывающей есть другие точки (пусть
   $r$).

   #+BEGIN_center
   #+ATTR_LATEX: :width 0.2\textwidth
   [[./figures/DELAUNAY_EMST.png]]
   #+END_center

   Тогда пусть без потери общности $r$ принадлежит части остова по
   сторону точки $q$. Тогда заменив $e$ на $pr$, мы не уменьшим
   количество ребер, но уменьшим длину ребра, поэтому МСТ -- не
   минимально.
   #+END_proof

   Воспользуемся системой непересекающихся множеств. Будем действовать
   согласно алгоритму, очень похожему на алгоритм Крускала: добавим
   все точки в СНМ, будем обходить ребра Делоне (отсортированные) и
   добавлять, если для очередного ребра $e$ верно $get(e.start) \neq
   get(e.end)$.
* 1 21: Делоне: алгоритм + корректность                             :volhovm:
  Существуют следующие алгоритмы построения триангуляции Делоне:
  1. Итеритивнами флипами из произвольной триангуляции.
  2. Построением выпуклой оболочки поднятия точек на параболоид.
  3. Инкрементальное добавление точек в трjиангуляцию (рандомизированное).
  4. Конвертирование из диаграммы Вороного.

  Первые два алгоритма были рассмотрены в теоретическом билете. Этот
  билет целиком о третьем алгоритме. Четвертый способ будет рассмотрен
  в билете про диаграмму Вороного.

  Частично этот билет есть в деБерге, частично [[http://www.cs.berkeley.edu/~jrs/meshpapers/Devillers.pdf][тут]]. [[https://hal.inria.fr/inria-00166711/file/hal.pdf][И тут.]]
** 2 Изменение статической триангуляции
   Для начала решим подзадачу -- поймем, как, имея триангуляцию Делоне,
   добавить точку внутрь. Предположим, что точка всегда находится
   внутри триангуляции (этого легко достичь, зная ограничения на
   точки: первоначально построить треугольник, охватывающий все поле,
   а в конце удалить).

   У нас всего есть два варианта, куда может попасть точка при
   локализации -- внутрь треугольника или на ребро. Добавим три ребра,
   если точка попала внутрь треугольника, и два, если на ребро
   (см. иллюстрацию). Осталось только нормализовать ребра, которые
   могли стать плохими. Потенциально для случая с тремя вершинами нам
   нужно нормализовать $p_ip_j$, $p_jp_k$, $p_kp_i$ -- все три ребра
   треугольника, в который мы вставили вершину. Для случая с ребром --
   это все четыре стороны четырехугольника.

   #+ATTR_LATEX: :width 0.6\textwidth
   #+CAPTION: Возможные варианты положения точки $q$ относительно триангуляции
   [[./figures/DELAUNAY_LOCALISATION_2.png]]

   Нормализовать ребро -- значит заменить его флипом. Разберемся,
   какие конкретно флипы следует делать. Заметим, что ребро $e$ может
   стать плохим только в том случае, если изменился один из
   треугольников, который на $e$ опирался. поэтому будем проверять
   только ребра новых треугольников.

   Алгоритм нормализации ребра таков: пусть новая точка -- $q$ а мы
   должны нормализовать $e$. Найти четырехугольник $qabc$, такой что
   $e = ac$ и флипнуть это ребро, заменив его на $qb$. Повторить
   процедуру относительно ребер $bc$ и $cd$, так как для них
   изменились внешние треугольники. Ребра $qa$ и $qc$ -- новые,
   добавленные при первоначальной вставке, поэтому мы их не трогаем.
   Несложно показать, что не нужно будет никогда больше трогать и
   новое ребро $qb$.

   Корректность алгоритма следует напрямую из леммы о том, что
   проверять и флипать следует лишь ребра, у которых изменились
   смежные треугольники.
** 2 Алгоритм
   Пусть дан набор точек $S$. Наша задача -- построить триангуляцию
   Делоне $DT(S)$ и эффективно поддеживать ее относительно операций
   удаления или вставки. Отметим, что

   Будем использовать локализационную структуру, используя подход
   Бернуллевских множеств:

   \begin{align*}
   S = S_0 \subseteq S_1 \subseteq S_2 \subseteq ... \subseteq S_k\\
   Probability(p \in S_{i+1} | p \in S_i) = \frac{1}{\alpha} \in [0,1]
   \end{align*}

   Структура данных достаточно простая. Будем отсылаться к $S_i$ как к
   $i$-му уровню структуры. Треугольник как структура данных будет
   знать о своих смежных треугольниках и вершинах, а каждая вершина --
   свой треугольник. Число уровней структуры не фиксируется и зависит
   исключительно от $\alpha$.

   Чтобы локализовать точку $q$ в триангуляции, будем начинать
   локализовываться на $k$-м уровне от точки $v_{k+1}$, находящейся
   на $k+1$-м. Далее найдем точку $v_k$, ближайшую к q точку из
   $DT_k$. Поскольку все точки на $k$-м уровне есть и на $k-1$-м, то
   найдя $v_i$ остается только спуститься вниз и продолжить
   поиск. Так будем спускаться до нулевого уровня, на котором найдем
   нужный треугольник.

   #+ATTR_LATEX: :width 0.8\textewidth
   #+CAPTION: Иллюстрации к локализации в $i$-ом уровне структуры
   [[./figures/DELAUNAY_LOCALISATION.png]]

   На уровне $i$ поиск проходит в три этапа:
   1. Рассматривается треугольник, который содержит вершину
      $v_{i+1}$, все смежные ему треугольники проверяются на наличие
      отрезка $v_{i+1}q$.
   2. Посещаются по очереди все треугольники в $DT_i$, которые
      пересекает отрезок $v_{i+1}q$. Находим треугольник $t_i$,
      содержащий точку $q$.
   3. Найдем жадно точку, ближайшую к q: посетим соседей треугольника
      $t_i$ по следующему алгоритму. Пусть $t_i = vv'v''$, и, без
      потери общности, ближайшая вершина к $q$ есть $v$. Тогда либо
      $v_i$ и есть $v$, либо $v_i$ находится внутри круга с центром в
      $q$ и радиусом $qv$. Следовательно, следует проверить только
      смежных ребрам $vv'$ и $vv''$ треугольники, не проверяя тот,
      что смежен $v'v''$ (окружность его не пересекает ввиду того,
      что $v$ -- ближайшая к $q$). См. иллюстрацию пункт $a$. Для
      каждого такого треугольника будем запоминать ближайшую к $q$
      точку $w$ и переходить к следующему треугольнику, смежному по
      ребру $ww'$, только если угол $\measuredangle qww' <
      \frac{\pi}{2}$. На иллюстрации пункт $b$ изображает выбор ребра
      $ww''$ и отбрасывает переход по $ww'$.

   Алгоритм локализации целиком изображен на иллюстрации пункт $c$.
   После локализации в структуре будем изменять ребра так, как это
   делалось в статическом алгоритме, а затем с вероятностью
   $\frac{1}{\alpha}$ пробрасыввать вершину наверх и добавлять ее
   там так же.
** 1 Асимптотика
   #+BEGIN_thm
   В графе Делоне с $n$ точками верхняя оценка на количество ребер
   $3n-6$, а на количество граней $2n-5$.
   #+END_thm
   #+BEGIN_proof
   Воспользуемся теоремой Эйлера для планарного графа: $m_v - m_e +
   m_f = 2$. Для графа Делоне эта формула выглядит так: \[n - n_e +
   n_f = 2\]

   Заметим также, что каждая грань имеет степень хотя бы три, а
   каждое ребро связывает между собой всегда две грани: \[2n_e \geq
   3n_f\]

   Вместе с предыдущим утверждением решение системы доказывает
   утверждение теоремы.
   #+END_proof

   Сначала оценим количества новых треугольников, создаваемых при
   добавлении точки.

   #+BEGIN_lemma
   На каждом шаге алгоритма для статической триангуляции с $k$ при
   добавлении точки $p_r$ создается максимум 9 треугольников.
   #+END_lemma
   #+BEGIN_proof
   В начале добавления точки мы создаем либо 3 (в случае попадания
   внутрь треугольника) либо 4 (попали на ребро) треугольника. Каждый
   последующий флип при нормализации создает 2 новых
   треугольника. Напомним, что такой флип создает ребро, смежное с
   вершиной $p_r$. То есть, если степень вершины $p_r$ после вставки
   есть $k$, то максимум может создаться $2(k-3)+3=2k-3$ новых
   треугольников. Степень вершины -- количество ребер ей инцендентных,
   назовем это число $\deg(q,DG_q)$, где
   $DG_q={p_1,p_2,...p_r}\cup{a,b,c}$ (второе -- это внешние три
   точки, которые ограничиваают все остальные). Из теоремы об оценке
   количества ребер графа Делоне, количество ребер в $D_r$ есть
   $3(r+3)-6$. Три ребра из этих принадлежат самому внешнему
   треугольнику, тогда общая степень вершин в графе меньше чем
   $2[3(r+3)-9] = 6r]$. Это значит, что средняя ожидаемая степень
   новой вершины -- 6.

   Оценим тогда количество треугольников, создаваемых на шаге $r$:
   \[
   EX \leq E[2\deg(p_r, DG_r) - 3]
   = 2E[\deg(p_r, DG_r)] - 3
   \leq 2\dot6 - 3 = 9
   \]
   #+END_proof

   #+BEGIN_note
   Для простого алгоритма без использования ступенчатой структуры
   локализации количество созданных треугольников есть $1+9n$.
   #+END_note

   Оценим теперь время локализации, так как в него упирается весь
   алгоритм (мы уже поняли, что на каждая вставка -- это
   $O(1)$). Пусть $S$ -- это множество вершин текущей триангуляции,
   $q$ -- вставляемая вершина. В силу рандомизированности $q$ --
   случайный элемент $S \cup q$. Будем называть $n_i = |S_i|$ (где
   $S_i$ -- набор точек на уровне $i$), $R_i = S_i \cup q$. В силу
   рандомизированности тут $q$ -- случайный элемент $R_i$, а само
   $R_i$ -- случайное множество размера $n_i + 1$. Можно думать об
   $R_i$ как об случайном подмножестве $R_{i-1}$: Будем использовать
   нотацию $E(X)$ для обозначения матожидания.

   Напомним, что в алгоритме локализации есть три фазы. Стоимость
   первой фазы, то есть посещения всех смежных $v_{i+1}$ треугольников,
   есть степень $v_{i+1}$ в $DG_i$. Стоимость второй фазы равна
   количеству ребер, пересекаемых отрезком $v_{i+1}q$. Стоимость
   третьей фазы -- количество вершин-кандидатов на роль ближайшей во
   время поиска $v_i$ после нахождения $t_i$.

   #+BEGIN_lemma
   Ожидаемая степень $v_i$ в $DT_{i-1}$ есть $O(1)$.
   #+END_lemma
   #+BEGIN_proof
   Пусть $NN$ -- nearest-neighbor граф $R_i$, то есть граф, в котором
   вершины -- точки $R_i$, а ребро между $v$ и $q$ есть тогда и
   только, если $v = NN(q)$, то есть $v$ -- ближайшая вершина к $q$
   или $q = NN(v)$.

   $NN$ есть подграф $DT(R_i)$ (следует из оптимальности триангуляции,
   т.к. она максимизирует углы, делая все ребра равномерными по
   длине), а максимальная степень $NN$ есть 6. Последнее доказывается
   достаточно просто. Cледует лишь нарисовать 7 точек -- правильный
   шестиугольник с центром, и предположить, что максимальная степень
   центральной вершины больше 6. Далее несложно показать, что седьмая
   ближайшая к центру точка на самом деле окажется ближе всего к
   соседу, так как в правильном шестиугольнике треугольники вида
   $OAB$, где $O$ -- центр, а $A$ и $B$ -- соседние вершины,
   равносторонние.

   Будем называть $\deg_{G}(v)$ степенью вершины $v$ в графе
   $G$. Напомним также, что точка $q$ -- случайная в $R_i$.

   Сложность доказательства состоит в том, что вероятность получения
   $NN(q)$ не равномерна, даже если это верно для самой $q$.

   \begin{align*}
   E(\deg_{DT_{i-1}}(NN(q)))
   &= E\left(\frac{1}{|R_i|}\sum_{q \in R_i} \deg_{DT_{i-1}}(NN(q))\right)\\
   &= \frac{1}{|R_i|}E\left(\sum_{v \in R_i} \sum_{q \in \{r : v = NN(r)\}}
      \deg_{DT_{i-1}}(v)\right)\\
   &\leq \frac{1}{|R_i|}E\left(\sum_{v \in R_i} 6 \times \deg_{DT_{i-1}}(v)\right)\\
   &\leq 36
   \end{align*}
   #+END_proof

   #+BEGIN_lemma
   Пусть $w \in R_i$, тогда ожидаемое количество вершин $q$ из $R_i$,
   таких что $w$ принадлежит кругу с центром в $q$, проходящему через
   $NN(q)$ в $R_{i+1}$, меньше чем $6\alpha$.
   #+END_lemma
   #+BEGIN_proof
   Пусть $w \in R_i$. Рассмотрим $Q = q_1...q_k$ -- точки $R_i$,
   лежащие в любом секторе с центром $w$ шириной $\frac{\pi}{3}$,
   отсортированные по возрастанию расстояния от $w$. Очевидно, что
   окружность с центром в $q_l$, проходящая через $q_j$ не может
   содержать $w$, если $j < l$. Тогда если $q = q_l$, необходимое
   условие для того, чтобы $w$ содержалась в диске между $q$ и $NN(q)$
   в $R_{i+1}$, есть то, что ни одна из точек $\{q_1...q_{l-1}\}$ не
   содержится в уровне выше, то есть в $R_{i+1}$. Вероятность такого
   события $\left(1 - \frac{1}{\alpha}\right)^l$.

   #+CAPTION: Иллюстрация к доказательству леммы 3
   #+ATTR_LATEX: :width 0.4\textwidth
   [[./figures/DELAUNAY_ASYMP0.png]]

   Просуммируем результат по всем шести секторам и по всем $q \in
   R_i$, получим результат $6\alpha$ (я просидел полчаса и не смог
   это показать, и нигда не нашел, извините $\frownie$).

   Отметим также, что окружность с центром в $q$ проходящий через $NN(q)$
   содержит внутри себя окружность диаметром $qNN(q)$. Отсюда
   ожидаемое количество вершин $q \in R_i$ в окружности с диаметром
   $qNN(q)$, меньше $6\alpha$.
   #+END_proof

   #+BEGIN_lemma
   Ожидаемое количество ребер $DT_i$, пересекаемое отрезком
   $v_{i+1}q$, есть $O(\alpha)$.
   #+END_lemma
   #+BEGIN_proof
   Пусть $e$ -- ребро $DT_i$, которое пересекает отрезок
   $v_{i+1}q$. Если $e$ не существует в $DT_{R_i}$, значит $e$ --
   внутреннее ребро, исчезнувшее после триангуляции, которую алгоритм
   совершает при вставке $q$. Матожидание количества таких ребер 3,
   поскольку $q$ -- случайная точка в $R_{i}$, а число равно средней
   степени вершины (6) минус 3.

   Если $e$ принадлежит $DT_{R_i}$, один его конец $w$ должен
   принадлежать окружности диаметром $qv_{i+1} =:
   disk[qv_{i+1}]$. Иначе любая окружность проходящая через концы $e$
   должна содержать $q$ или $v_{i+1}$, что противоречит критерию
   Делоне $DT_{R_i}$.

   Ожидаемое количество ребер $DT_{R_i}$, пересекающей
   $disk[qv_{i+1}]$ ограничено сверху суммой степеней вершин внутри
   этой окружности. В матожидании мы должны просуммировать по всем
   $q$, а внутри по всем $w$ внутри $disk[qv_{i+1}]$ степень вершин.
   Но можем переставить местами суммы и раскрыть внутреннюю по
   предыдущей лемме, тогда остается сумма по всем $w \in R_i$ степени
   вершины умноженной на $6\alpha$, что в свою очередь меньше
   $36\alpha$, как средняя степень вершины в графе Делоне.

   Итого мы ограничили количество ребер, просматриваемых во втором
   этапе, числом $36\alpha$.
   #+END_proof

   #+BEGIN_lemma
   Ожидаемое количество треугольников, которые просматриваются во
   время поиска $v_i$ из треугольника $t_i$, есть $O(\alpha)$.
   #+END_lemma
   #+BEGIN_proof
   Все треугольники $t$, просматриваемые алгоритмом, имеют вершину в
   круге с центром в $q$ проходящим через $v_{i+1}$. Поэтому для них
   оценка тоже верна: используя предыдущую лемму, можно показать, что
   матожидание $\le 36\alpha$.
   #+END_proof

   #+BEGIN_thm
   Время вставки $n$-той точки в структуру есть
   $O(\alpha\log_{\alpha}n)$. Суммарно алгоритм создания триангуляции
   Делоне из $n$ точек работает за $O(\alpha\log_{\alpha}n)$ при
   рандомизированной вставке, не учитывая распределение точек на
   плоскости.
   #+END_thm
   #+BEGIN_proof
   Из лемм выше следует, что локализация на каждом уровне занимает
   $O(\alpha)$ времени. Уровней в среднем $\log_{\alpha}{n}$. Вставка
   точки занимает $O(1)$, что было доказано в самом начале
   параграфа. Прокидывание точек на верхние уровни дает нам
   дополнительную асимптотику, но в среднем меньшую, чем
   $\log_{\alpha}{n}$.

   Второе утверждение является следствием первого.
   #+END_proof
** 2 Удаление
   Задача стоит удалить из триангуляции внутреннюю точку $q$. После
   удаления точки и смежных ей ребер многоугольник останется
   звездным. Но это нам (я так понял) не очень помогает, замечание в
   никуда.

   Отметим, что мы хотим флипать ребра в особенном порядке. И этот
   порядок -- обратный порядку при добавлении точки $q$ (не
   единственный этот, конечно). Подумаем, как можно его восстановить.

   Пусть после удаления $q$ остался многоугольник $ABCDE$. Тогда
   спроектируем его на параболоид. Предположим, что его триангуляция
   существует. Тогда, поднимаясь из точки $(q_x, q_y, -\inf)$ в $(q_x,
   q_y, q_x^2 + q_y^2)$ (назовем этот луч $l$), мы будем переставить
   видеть грани в порядке удаления, вместе с приближением точки к
   верхней границе $l$.

   Отсюда алгоритм: возьмем очередь с приоритетом, запихнем туда все
   уши с $\alpha < 180\degree$, компаратор -- пересечение с прямой
   $l$. Будем брать, пока берутся. Отметим, что уши, которые плохие,
   смотрят внутрь параболоида, поэтому они не исчезнут до того
   момента, как $l$ пересечет параболоид.
* 2 22: Диаграмма Вороного                                          :volhovm:
  [[http://neerc.ifmo.ru/wiki/index.php?title=Диаграмма_Вороного][Статья на викиконспектах]]
** Алгоритм и асимптотика
   Антону больше нравится инкрементальный алгоритм построения диаграммы
   Вороного, так как он похож на Делоне.

   Типа вот есть бакеты, мы там чето меняем, проводим $O(1)$ времени на
   каждом уровне, суммарно получается $O(n)$.

   У нас есть $O(log(n))$ уровней, где есть какие-то сабсеты, для
   каждого мы можем построить за $O(1)$ новую диаграмму.

   Как локализоваться в диаграмме Вороного, где точек $O(1)$? Тупо
   найти ближайшую точку, посчитав метрику.

   ~VOR_0~
   Как с помощью $n+1$ уровня найти ближайшую точку на $n$-м уровне?
   $X$ --- ближайшая точка на $n+1$ уровне. $A$ --- точка, которую мы хотим
   вернуть, то есть ближайшая к $q$ на $n$-м уровне. Проведем отрезок $XA$ и
   проверим все соседние грани точки $X$, выберем ту, которую пересекает
   $XA$. $XA$ также может пересекать какую-то точку триангуляции. Тогда
   нужно перебрать все соседние прямые, исходящие из этой точки и
   выбрать такие две, между которыми проходит $XA$.

   Как достроить диаграмму Вороного, если мы уже локализовались?
   Построим между q и A серединный перпендикуляр, пересечь его с фейсом
   вершины A. Будем дальше идти по соседним DCEL'ам и заворачивать,
   строя серединные перпендикуляры, прямые вокруг $q$. Таким образом,
   построим грань для вершины q.

   Асимптотика (inb4 можно это делать, строя двойственную триангуляцию):
   * Вставка: посчитаем среднюю степень, проведем регрессионный анализ,
     как в алгоритме Делоне.
   * Локализация: пересечем $O(1)$ ребер. Это доказательство тоже
     копируется с Делоне. Можно сказать, что мы пройдем по количеству
     DCEL'ов которые не добавились на более высокий уровень. Поскольку
     слои диаграммы --- это множество Бернулли, то на каждом шаге мы
     добавим не больше чем сколько-то точек, а они экспоненциально
     убывают.
** Удаление из диаграммы Вороного
   ~VOR_2~

   Возьмем сайт, его фейс. Будем строить типа straight skeleton,
   двигая стороны внутрь по серединным перепендикулярам. Тогда в
   какой-то момент схлопнется.
** Построение из триангуляции диаграмму
   ~VOR_1~

   Как построить из триангуляции Делоне диаграмму Вороного?  Возьмем
   диаграмму, выделим какую-то точку $A$. Построим серединные
   перпендикуляры для каждого ребра, исходяшего из $A$, пересечем их
   всех. Поймем, что получившееся пересечение сер. перпендикуляров
   образует ячейку Вороного.

   Покажем, что такая ячейка конечна. Рассмотрим треугольник $ABC$. По
   определению, этот треугольник --- треугольник Делоне, поэтому точка
   пересечение серединных перпендикуляров лежит внутри, и расстояние
   от $S$ до точек прямоугольника минимально, если точка есть
   пересечение серединных перпендикуляров. Более того, по свойству
   Делоне, в окружности не лежит никаких других точек.

   Любой отрезок ячейки Вороного принадлежит ей, потому что ячейки
   диаграммы Вороного выпуклые. Отсюда, поскольку точки отрезка лежат в
   ячейке, отрезок тоже лежит. Типа сама точка A лежит ближе всего к
   себе. Точка пересечения сер. перпендикуляров тоже лежит в ячейке,
   тогда для каждых двух соседних точек прямая между ними тоже лежит,
   т.к. ячейка вороного --- выпуклый многугольник.
** Построение из диаграммы триангуляции
   Возьмем диаграмму Вороного и построим *разбиение* Делоне --- то есть
   могут получиться не треугольники. В этом случае можно показать, что
   любой такой многоугольник можно триангулировать любым образом, при
   этом свойство Делоне останется.

   Почему в общем случае граф, в котором мы соединили сайты соседних
   граней, получится разбиением Делоне? Ну типа, возьмем в DCEL'е
   узел, который соединяет три грани. Берем их сайты, соединяем. Это
   получится треугольник. Прогоним обратное следствие в нужную
   сторону.
** Высшие порядки
   Диаграмма Вороного второго порядка $VD^2$ это: $P_1, P_2 \in
   V_{q_1q_2} \Leftrightarrow d(p_1, q_1) = min_1, d(p_1,q_2) = min_2$.

   Аналогично строим $VD^k$ --- диаграмму Вороного $k$-го порядка.

   Диаграмма Вороного $n-1$-го порядка --- это набор таких сайтов, что
   для каждого есть $n-1$ точка, и для всех точек от них есть какая-то
   одна самая далекая.

   Как строить инеркментально? Нужно проводить алгоритм удаления
   точек, но не удаляя прямые, которые мы двигаем, до самого конца.

   Для каждого фейса мы делаем это за: $klogk$, но \[\sum{k\log{k}}
   \le \sum{k\log{n}} = \log{n}\sum{k} = O(n\log{n})\]

   Сколько будет вершин в диаграмме вороного второго порядка? Столько
   же, сколько и ребер, вернее удвоенное количество.

   *ЧИТАТЬ НА ВИКИ*
** Диаграмма минус первого порядка
   Граф Делоне двойственный диаграмме $-1$ порядка --- это верхняя крышка
   проекции диаграммы на параболоид.

   Типа возьмем треугольник, тогда в окружности должны находиться все
   точки множества. Количество вершин в такой диаграмме Вороного ---
   это количество вершин выпуклой оболочки.
   \clearpage
* Бонусные задачи и нетронутые темы
** Из множества прямых произвольных восстановить DCEL
   Можно делать инкрементально. Для трех понятно, как строить. Дальше
   кидаем прямую. Берем первое пересечение, локализуем точку на прямой
   за $O(n)$, дальше обходим соседние фейсы DCEL'а пока не найдем
   точку пересечения нашей прямой с какой-то другой. И так пока все не
   пересечем. Можно показать, что асимптотика будет норм -- $O(n^2)$.

   Рассмотрим ~BON-0~. $l$ -- наша прямая. Утверждается, что от
   пересечения нашей прямой с какой-то другой до следующего
   пересечения нужно пробежать не более чем $O(n)$ ребер.

   В среднем заметим, что у нас $O(n^2)$ ребер и $O(n^2)$ фейсов. Тем не
   менее, из этого не следует, что на каждый фейс приходится $O(1)$
   ребер, может быть так, что какие-то фейсы жирные, а какие-то нет.

   Мы всегда знаем направление, в котором мы будем двигаться от
   точки.

   Рассмотрим все Покрасим точки с положительным наклоном
   относительно прямой синим цветом, а серым -- с
   отрицательным. Будем считать только те ребра, которые лежат в
   DCEL'ах, которые пересекает наша прямая $l$.

   Посчитаем, сколько таких цветных ребер есть (кстати, синих и серых
   ребер будет одинаковое количество).

   Прямая l прйдет через O(n) ребер. Выкинем самую правую прямую,
   которая имеет синий отрезок. Тут типа индукция. Тогда есть
   $\exists{c}$, что прямая пересекает не более $c*(n-1)$. Попробуем ее
   заново добавить. Пусть прямая имеет серый наклон вправо. Тогда
   такая прямая подразобьет не более чем $O(1)$ ребер.
** Поиск касательной точки и многоугольника
   Тут Славик рассказал способ найти касательную точки и
   многоугольника с помощью подразбиения многоугольника на
   подмногоугольники (каждый вложенный берет точки предыдущего через
   одну). Потом он типа ищет для самого вложенного треугольника
   касательную, а потом передвигается к более богатым многоугольникам,
   сдвигая касательную влево или вправо на одну вершину. Тоже алгоритм
   за log(n). Типа на каждом шаге есть step, мы рассматриваем текущего
   кандидата на касательную + step и -step. Выбираем лучшего,
   переходим к нему и делим шаг на два.
** Масшатбирование дорог
   #+CAPTION: Пример решения задачи о масштабировании дороги
   [[./figures/ROAD_SCALING.png]]

   Задача поставлена так: существует некоторый масштаб карты, в
   условиях которого выражена дорога, представляющая собой
   полилинию. Требуется выразить эту дорогу в более мелком масштабе,
   то есть так сократить количество точек, чтобы новая полилиния в
   некотором смысле была похожа на старую. Сглаженность определяется
   рациональным числом \varepsilon: необходимо, чтобы новая прямая не
   выходила из \varepsilon-коридора старой прямой. Пример показан на
   изображении, в нашем случае красная прямая -- решение.

   Предлагается два решения этой задачи:
   1. Будем использовать сумму Минковского и уже разобранные алгоритмы
      планирования движения. С помощью суммы расширим прямую
      правильным многоугольником, выбрав радиус описанной окружности
      соответствующий нужному масштабу, а затем решим задачу об
      оптимальном прохождении роботом коридора, который и представляет
      собой расширение. Напомним, что в этом случае при использовании,
      например, графа видимости, асимптотика решения составит
      $O(n^2\log{n})$ на препроцессинг и $O(n)$ на решение.
   2. Применим стандартную тактику "разделяй и властвуй" и решим
      задачу за амортизированное $O(n\log{n})$ ($O(n^2)$ в худшем
      случае, алгоритм Дугласа-Пекера):

      \begin{algorithm}[H]
      \SetKwFunction{DougPeuck}{Douglas-Peucker}%
      \func{\DougPeuck{points, $\varepsilon$}}{
        \KwData{Набор точек, задающих полилинию $\{p_i\}$\\
                Коэффициент расширения $\varepsilon$}
        \KwResult{Набор точек, задающих решение (полилинию)}
        $range \gets [1, n]$\;
        \While{$range.length > 0$}{
          $segment \gets \langle points[range.start],
                                 points[range.end]
                         \rangle$\;
          $p_{max} \gets min(points[range.start],
            points[range.end],$ компаратор по дистанции до $seg)$\;
          \eIf{$dist(p_{max}, segment) < \varepsilon$}{
            return $(segment.start, segment.end)$\;
          }{
            $p_1 \gets $Douglas-Peucker$(points[0..p_{max}], \varepsilon)$\;
            $p_2 \gets $Douglas-Peucker$(points[p_{max}..n], \varepsilon)$\;
            return $union(p_1, p_2)$\;
          }
        }
      }
      \caption{Алгоритм Дугласа-Пекера для масштабирования полилинии}
      \end{algorithm}
** Звездные многоугольники
   #+ATTR_LATEX: :options [Звездный многоугольник]
   #+BEGIN_defn
   Многоугольник звездный, если существует точка $q$, что для любой
   вершины многоугольника $a$ отрезок $qa$ не пересекает ни одного
   ребра многоугольника. То есть из точки $q$ "видно" все остальные
   вершины.
   #+END_defn

   #+ATTR_LATEX: :options [Ядро звездного многоугольника]
   #+BEGIN_defn
   Ядром звездного многоугольника -- это множество точек, из которого
   видны все вершины многоугольника.
   #+END_defn

   Заметим, что ядро всегда выпукло, так как является пересечением
   полуплоскостей всех ребер многоугольника. Отсюда и алгоритм поиска
   (за $O(n)$).

   Умеем триангулировать звездный многоугольник.
   1. Если есть ядро, выберем любую точку, соединим ее со всеми
      вершинами и флипами будем менять, пока $q$ нельзя будет
      убрать.

      Можно также отрезать уши по очереди, отрезая немного от
      ядра. Уши нужно выбирать только "выпуклые", то есть те, которые
      имеют внутренний угол $< 180\degree$. Можно отрезать все уши,
      избегая отрезания того, в котором $q$. Отрезать его последним.
   2. Если нет ядра, то можно построить за $O(n)$. Если не искать, то
      можно /как-то/ за $O(n)$ или $O(n\log{n})$.
